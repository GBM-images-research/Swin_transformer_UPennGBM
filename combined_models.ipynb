{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading functions\n",
    "import os\n",
    "import time\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "\n",
    "from src.get_data import CustomDataset, CustomDatasetSeg\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from types import SimpleNamespace\n",
    "import wandb\n",
    "import logging\n",
    "\n",
    "#####\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    "    MapTransform,\n",
    "    Transform,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai import data\n",
    "\n",
    "# from monai.data import decollate_batch\n",
    "from functools import partial\n",
    "from src.custom_transforms import (ConvertToMultiChannelBasedOnN_Froi, \n",
    "                                   ConvertToMultiChannelBasedOnAnotatedInfiltration, \n",
    "                                   masked, ConvertToMultiChannelBasedOnBratsClassesdI)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trasnformaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigo/anaconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "roi = (128, 128, 128) # (220, 220, 155) (128, 128, 64)\n",
    "source_k=\"label\"\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # ConvertToMultiChannelBasedOnN_Froi(keys=\"label\"),\n",
    "        # masked(keys=\"image\"),\n",
    "        ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        # ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            source_key=source_k,\n",
    "            k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[roi[0], roi[1], roi[2]],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # ConvertToMultiChannelBasedOnN_Froi(keys=\"label\"),\n",
    "        # masked(keys=\"image\"),\n",
    "        ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        # ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[-1, -1, -1], #[224, 224, 128],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################\n",
    "# Crear el modelo\n",
    "######################\n",
    "\n",
    "### Hyperparameter\n",
    "roi = (128, 128, 128)  # (128, 128, 128)\n",
    "\n",
    "# Create Swin transformer\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def define_model(model_path):\n",
    "    model = SwinUNETR(\n",
    "        img_size=roi,\n",
    "        in_channels=11, # 11\n",
    "        out_channels=2,  # mdificar con edema\n",
    "        feature_size=48, #48\n",
    "        drop_rate=0.0,\n",
    "        attn_drop_rate=0.0,\n",
    "        dropout_path_rate=0.0,\n",
    "        use_checkpoint=True,\n",
    "    )\n",
    "\n",
    "    loaded_model = torch.load(model_path, map_location=torch.device('cuda:0'), weights_only=False)[\"state_dict\"]\n",
    "\n",
    "    # Load the state dictionary into the model\n",
    "    model.load_state_dict(loaded_model)\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "run = wandb.init()\n",
    "artifact = run.use_artifact('mlops-team89/Swin_UPENN_10cases/gffqpzjv_best_model:v0', type='model')\n",
    "artifact_dir = artifact.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigo/anaconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SwinUNETR(\n",
       "  (swinViT): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(11, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers1): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers2): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers3): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers4): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(11, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(11, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder10): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 384, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(768, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(768, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder1): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(48, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Modelo TC+Edema\n",
    "model1=define_model(\"artifacts/vtzpbajf_best_model:v0/model.pt\") # o9kppyr5\n",
    "# model1=define_model(\"artifacts/gffqpzjv_best_model:v0/model.pt\") # gffqpzjv \n",
    "model1.to(device)\n",
    "model1.eval()\n",
    "\n",
    "# Modelo Infitracion+Edema\n",
    "model2=define_model(\"artifacts/1dhzmigz_best_model:v0/model.pt\") # uixfayrn - rvu24jip\n",
    "# model2=define_model(\"artifacts/8exzvcui_best_model:v0/model.pt\") # 8exzvcui\n",
    "model2.to(device)\n",
    "model2.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crear imagen con ceros para anular canales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Iniciando el proceso de reemplazo ---\n",
      "Directorio a procesar: Dataset/Dataset_30_6/test_6_1out/images\n",
      "Modalidad a reemplazar (sufijo): '_DTI_TR.nii.gz'\n",
      "Usando imagen de reemplazo: Dataset/Dataset_30_6/test_6_1out/black_image.nii.gz\n",
      "--------------------\n",
      "Encontrado: Dataset/Dataset_30_6/test_6_1out/images/images_DTI/UPENN-GBM-00285_11/UPENN-GBM-00285_11_DTI_TR.nii.gz\n",
      "  -> Reemplazado exitosamente.\n",
      "Encontrado: Dataset/Dataset_30_6/test_6_1out/images/images_DTI/UPENN-GBM-00134_11/UPENN-GBM-00134_11_DTI_TR.nii.gz\n",
      "  -> Reemplazado exitosamente.\n",
      "Encontrado: Dataset/Dataset_30_6/test_6_1out/images/images_DTI/UPENN-GBM-00307_11/UPENN-GBM-00307_11_DTI_TR.nii.gz\n",
      "  -> Reemplazado exitosamente.\n",
      "Encontrado: Dataset/Dataset_30_6/test_6_1out/images/images_DTI/UPENN-GBM-00086_11/UPENN-GBM-00086_11_DTI_TR.nii.gz\n",
      "  -> Reemplazado exitosamente.\n",
      "Encontrado: Dataset/Dataset_30_6/test_6_1out/images/images_DTI/UPENN-GBM-00055_11/UPENN-GBM-00055_11_DTI_TR.nii.gz\n",
      "  -> Reemplazado exitosamente.\n",
      "Encontrado: Dataset/Dataset_30_6/test_6_1out/images/images_DTI/UPENN-GBM-00141_11/UPENN-GBM-00141_11_DTI_TR.nii.gz\n",
      "  -> Reemplazado exitosamente.\n",
      "--------------------\n",
      "Proceso completado. Se han reemplazado 6 archivos.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "# --- Incluimos la función del paso anterior para crear la imagen en negro ---\n",
    "# (Puedes omitir esta parte si ya tienes la imagen creada)\n",
    "def create_black_image(reference_path, output_path):\n",
    "    \"\"\"Crea una imagen NIfTI de ceros a partir de una referencia.\"\"\"\n",
    "    try:\n",
    "        print(f\"Creando imagen en negro de referencia desde: {reference_path}\")\n",
    "        ref_img = nib.load(reference_path)\n",
    "        \n",
    "        zero_array = np.zeros(ref_img.shape, dtype=ref_img.get_data_dtype())\n",
    "        \n",
    "        black_nifti = nib.nifti1.Nifti1Image(zero_array, ref_img.affine, ref_img.header)\n",
    "        \n",
    "        nib.save(black_nifti, output_path)\n",
    "        print(f\"Imagen en negro guardada en: {output_path}\")\n",
    "        return True\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: No se encontró la imagen de referencia en {reference_path}\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"Ocurrió un error al crear la imagen en negro: {e}\")\n",
    "        return False\n",
    "\n",
    "# --- Función principal para reemplazar la modalidad ---\n",
    "def replace_modality_with_black(dataset_dir, black_image_path, modality_suffix):\n",
    "    \"\"\"\n",
    "    Busca recursivamente en un dataset y reemplaza todos los archivos de una\n",
    "    modalidad específica con una imagen en negro.\n",
    "\n",
    "    Args:\n",
    "        dataset_dir (str): La ruta al directorio raíz del dataset (ej. './images').\n",
    "        black_image_path (str): La ruta a la imagen .nii.gz de ceros.\n",
    "        modality_suffix (str): El sufijo del nombre de archivo que identifica la \n",
    "                               modalidad a reemplazar (ej. '_FLAIR.nii.gz').\n",
    "    \"\"\"\n",
    "    # --- Verificaciones iniciales ---\n",
    "    if not os.path.isdir(dataset_dir):\n",
    "        print(f\"Error: El directorio del dataset no existe: {dataset_dir}\")\n",
    "        return\n",
    "\n",
    "    if not os.path.isfile(black_image_path):\n",
    "        print(f\"Error: La imagen en negro no se encuentra en: {black_image_path}\")\n",
    "        return\n",
    "\n",
    "    if not modality_suffix:\n",
    "        print(\"Error: El sufijo de la modalidad no puede estar vacío.\")\n",
    "        return\n",
    "\n",
    "    print(\"--- Iniciando el proceso de reemplazo ---\")\n",
    "    print(f\"Directorio a procesar: {dataset_dir}\")\n",
    "    print(f\"Modalidad a reemplazar (sufijo): '{modality_suffix}'\")\n",
    "    print(f\"Usando imagen de reemplazo: {black_image_path}\")\n",
    "    print(\"-\" * 20)\n",
    "\n",
    "    # --- Búsqueda y reemplazo ---\n",
    "    files_replaced_count = 0\n",
    "    # os.walk recorre todos los directorios y subdirectorios\n",
    "    for root, dirs, files in os.walk(dataset_dir):\n",
    "        for filename in files:\n",
    "            # Comprobamos si el nombre del archivo termina con el sufijo deseado\n",
    "            if filename.endswith(modality_suffix):\n",
    "                target_file_path = os.path.join(root, filename)\n",
    "                \n",
    "                print(f\"Encontrado: {target_file_path}\")\n",
    "                \n",
    "                try:\n",
    "                    # shutil.copy SOBREESCRIBE el archivo de destino\n",
    "                    shutil.copy(black_image_path, target_file_path)\n",
    "                    print(f\"  -> Reemplazado exitosamente.\")\n",
    "                    files_replaced_count += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"  -> ERROR al reemplazar el archivo: {e}\")\n",
    "\n",
    "    # --- Resumen final ---\n",
    "    print(\"-\" * 20)\n",
    "    if files_replaced_count > 0:\n",
    "        print(f\"Proceso completado. Se han reemplazado {files_replaced_count} archivos.\")\n",
    "    else:\n",
    "        print(f\"Proceso completado. No se encontraron archivos con el sufijo '{modality_suffix}'.\")\n",
    "\n",
    "\n",
    "# --- EJEMPLO DE USO ---\n",
    "if True:\n",
    "\n",
    "    # ¡ADVERTENCIA IMPORTANTE! \n",
    "    # Esta operación SOBREESCRIBE archivos de forma permanente.\n",
    "    # Se recomienda hacer una copia de seguridad de tu dataset antes de ejecutarla.\n",
    "    \n",
    "    # 1. Configura tus rutas\n",
    "    DATASET_ROOT_DIR = \"Dataset/Dataset_30_6/test_6_1out\"  # Directorio raíz que contiene 'images' y 'labels'\n",
    "    IMAGES_DIR = os.path.join(DATASET_ROOT_DIR, \"images\")\n",
    "    \n",
    "    # Ruta para guardar la imagen en negro temporal.\n",
    "    # Se crea una vez y luego se reutiliza.\n",
    "    BLACK_IMAGE_OUTPUT_PATH = os.path.join(DATASET_ROOT_DIR, \"black_image.nii.gz\")\n",
    "\n",
    "    # Ruta a una imagen cualquiera de tu dataset para usarla como referencia de tamaño/espacio.\n",
    "    # ¡Asegúrate de que esta ruta sea correcta!\n",
    "    REFERENCE_IMAGE_FOR_BLACK = os.path.join(\n",
    "        IMAGES_DIR, \n",
    "        \"images_structural/UPENN-GBM-00055_11/UPENN-GBM-00055_11_T1.nii.gz\"\n",
    "    )\n",
    "\n",
    "    # 2. Crea la imagen en negro si no existe\n",
    "    if not os.path.exists(BLACK_IMAGE_OUTPUT_PATH):\n",
    "        success = create_black_image(REFERENCE_IMAGE_FOR_BLACK, BLACK_IMAGE_OUTPUT_PATH)\n",
    "        if not success:\n",
    "            print(\"\\nNo se pudo crear la imagen en negro. Abortando el script.\")\n",
    "            exit() # Detiene la ejecución si no se puede crear la imagen base\n",
    "\n",
    "    # 3. Define la modalidad que quieres \"apagar\"\n",
    "    #    Ejemplos de sufijos:\n",
    "    #    '_FLAIR.nii.gz'\n",
    "    #    '_T1.nii.gz'\n",
    "    #    '_T1GD.nii.gz'\n",
    "    #    '_T2.nii.gz'\n",
    "    #    '_DTI_FA.nii.gz'\n",
    "    #    '_DSC_ap-rCBV.nii.gz'\n",
    "\n",
    "    MODALITY_TO_REPLACE_SUFFIX = '_DTI_TR.nii.gz'\n",
    "\n",
    "    # 4. Llama a la función para realizar el reemplazo\n",
    "    replace_modality_with_black(\n",
    "        dataset_dir=IMAGES_DIR,\n",
    "        black_image_path=BLACK_IMAGE_OUTPUT_PATH,\n",
    "        modality_suffix=MODALITY_TO_REPLACE_SUFFIX\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtener embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images and 6 labels.\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features_model1: torch.Size([1, 48, 128, 128, 128])\n",
      "decoder_features_model2: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 0\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features_model1: torch.Size([1, 48, 128, 128, 128])\n",
      "decoder_features_model2: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 1\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features_model1: torch.Size([1, 48, 128, 128, 128])\n",
      "decoder_features_model2: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 2\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features_model1: torch.Size([1, 48, 128, 128, 128])\n",
      "decoder_features_model2: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 3\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features_model1: torch.Size([1, 48, 128, 128, 128])\n",
      "decoder_features_model2: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 4\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features_model1: torch.Size([1, 48, 128, 128, 128])\n",
      "decoder_features_model2: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 5\n"
     ]
    }
   ],
   "source": [
    "# Create dataset data loader\n",
    "# dataset_path='./Dataset/Dataset_recurrence'\n",
    "dataset_path='./Dataset/Dataset_30_6'\n",
    "train_set=CustomDataset(dataset_path, section=\"test_6\", transform=train_transform) # v_transform / test_6_1out\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "# Directorios para embeddings de cada modelo\n",
    "embedding_dir_model1 = \"Dataset/contrastive_voxel_wise/embeddings_model1\"\n",
    "embedding_dir_model2 = \"Dataset/contrastive_voxel_wise/embeddings_model2\"\n",
    "label_output_dir = \"Dataset/contrastive_voxel_wise/labels\"\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "os.makedirs(embedding_dir_model1, exist_ok=True)\n",
    "os.makedirs(embedding_dir_model2, exist_ok=True)\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# Variables para las características de los decoders de ambos modelos\n",
    "decoder_features_model1 = None\n",
    "decoder_features_model2 = None\n",
    "\n",
    "# Funciones hook para cada modelo\n",
    "def decoder_hook_fn_model1(module, input, output):\n",
    "    global decoder_features_model1\n",
    "    decoder_features_model1 = output\n",
    "\n",
    "def decoder_hook_fn_model2(module, input, output):\n",
    "    global decoder_features_model2\n",
    "    decoder_features_model2 = output\n",
    "\n",
    "# Registrar los hooks en los decoders de ambos modelos\n",
    "hook_handle_decoder1 = model1.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model1)\n",
    "hook_handle_decoder2 = model2.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model2)\n",
    "\n",
    "# Extraer y guardar\n",
    "with torch.no_grad():\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        image, label = batch_data[\"image\"], batch_data[\"label\"]\n",
    "        print(\"Image\", image.shape)  # [1, 11, 128, 128, 128]\n",
    "        print(\"label before squeeze\", label.shape)  # [1, 2, 128, 128, 128]\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.squeeze(0)  # [2, 128, 128, 128]\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas\n",
    "        label_sum = label.sum(dim=0)  # [128, 128, 128], suma de canales\n",
    "        label_class = torch.zeros_like(label_sum, dtype=torch.long)  # [128, 128, 128]\n",
    "        \n",
    "        # Asignar clases:\n",
    "        # - Fondo (0, 0) -> 0\n",
    "        # - Vasogénico (1, 0) -> 1\n",
    "        # - Infiltrado (0, 1) -> 2\n",
    "        label_class[label[1] == 1] = 2  # Infiltrado\n",
    "        label_class[(label[0] == 1) & (label[1] == 0)] = 1  # Vasogénico\n",
    "        # Donde label_sum == 0, ya es fondo (0)\n",
    "        \n",
    "        label = label_class.cpu().numpy()  # [128, 128, 128]\n",
    "        print(\"label\", label.shape)\n",
    "        \n",
    "        # Obtener embeddings de ambos modelos\n",
    "        _ = model1(image)  # Forward para model1\n",
    "        print(\"decoder_features_model1:\", decoder_features_model1.shape)  # [1, 48, 128, 128, 128]\n",
    "        \n",
    "        _ = model2(image)  # Forward para model2\n",
    "        print(\"decoder_features_model2:\", decoder_features_model2.shape)  # [1, 48, 128, 128, 128]\n",
    "        \n",
    "        # Guardar embeddings y etiquetas\n",
    "        np.save(f\"{embedding_dir_model1}/case_{idx}.npy\", decoder_features_model1.cpu().numpy())\n",
    "        np.save(f\"{embedding_dir_model2}/case_{idx}.npy\", decoder_features_model2.cpu().numpy())\n",
    "        np.save(f\"{label_output_dir}/case_{idx}.npy\", label)\n",
    "        \n",
    "        print(f\"Guardado embeddings y etiquetas para caso {idx}\")\n",
    "\n",
    "# Remover los hooks\n",
    "hook_handle_decoder1.remove()\n",
    "hook_handle_decoder2.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import nibabel as nib\n",
    "from sklearn.metrics import roc_auc_score, roc_curve, accuracy_score, f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset (ya lo tienes)\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embedding_dir, label_dir):\n",
    "        self.embedding_dir = embedding_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.case_files = [f for f in os.listdir(embedding_dir) if f.endswith(\".npy\")]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.case_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embedding_path = os.path.join(self.embedding_dir, f\"case_{idx}.npy\")\n",
    "        label_path = os.path.join(self.label_dir, f\"case_{idx}.npy\")\n",
    "        \n",
    "        embeddings = np.load(embedding_path)  # [1, 48, 128, 128, 128]\n",
    "        labels = np.load(label_path)  # [128, 128, 128]\n",
    "        \n",
    "        embeddings = torch.tensor(embeddings, dtype=torch.float32).squeeze(0)  # [48, 128, 128, 128]\n",
    "        labels = torch.tensor(labels, dtype=torch.long)  # [128, 128, 128]\n",
    "        \n",
    "        return embeddings, labels\n",
    "\n",
    "# # Modelo de proyección\n",
    "# class ProjectionHead(nn.Module):\n",
    "#     def __init__(self, input_dim=48, hidden_dim=128, output_dim=128):\n",
    "#         super(ProjectionHead, self).__init__()\n",
    "#         self.net = nn.Sequential(\n",
    "#             nn.Linear(input_dim, hidden_dim),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(hidden_dim, output_dim)\n",
    "#         )\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.net(x)\n",
    "\n",
    "# Modelo de proyección (MLP más profundo)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim1=256, hidden_dim2=128, output_dim=128, dropout_p=0.3):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# # Clasificador supervisado\n",
    "# class Classifier(nn.Module):\n",
    "#     def __init__(self, input_dim=128, num_classes=3):\n",
    "#         super(Classifier, self).__init__()\n",
    "#         self.fc = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "#     def forward(self, x):\n",
    "#         return self.fc(x)\n",
    "\n",
    "# Clasificador supervisado (MLP)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=256, hidden_dim2=128, num_classes=3, dropout_p=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Configuración para ambos modelos\n",
    "embedding_dir_model1 = \"Dataset/contrastive_voxel_wise/embeddings_model1\"\n",
    "embedding_dir_model2 = \"Dataset/contrastive_voxel_wise/embeddings_model2\"\n",
    "label_dir = \"Dataset/contrastive_voxel_wise/labels\"\n",
    "batch_size = 1\n",
    "\n",
    "# Cargar datasets y DataLoaders para ambos modelos\n",
    "dataset_model1 = EmbeddingDataset(embedding_dir_model1, label_dir)\n",
    "dataset_model2 = EmbeddingDataset(embedding_dir_model2, label_dir)\n",
    "loader_model1 = DataLoader(dataset_model1, batch_size=batch_size, shuffle=False)\n",
    "loader_model2 = DataLoader(dataset_model2, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Cargar modelos contrastivos preentrenados\n",
    "projection_head1 = ProjectionHead(input_dim=48).to(device)\n",
    "projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe1_v01_m1.pth\", map_location=device))\n",
    "# projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_gffqpzjv.pth\", map_location=device))\n",
    "projection_head1.eval()\n",
    "\n",
    "projection_head2 = ProjectionHead(input_dim=48).to(device)\n",
    "projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "# projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_8exzvcui.pth\", map_location=device))\n",
    "projection_head2.eval()\n",
    "\n",
    "# Cargar clasificadores preentrenados\n",
    "classifier1 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe1_v01_m1.pth\", map_location=device))\n",
    "# classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_gffqpzjv.pth\", map_location=device))\n",
    "classifier1.eval()\n",
    "\n",
    "classifier2 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "# classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_8exzvcui.pth\", map_location=device))\n",
    "classifier2.eval()\n",
    "\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device):\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.to(device).squeeze(0).permute(1, 2, 3, 0)\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)\n",
    "        \n",
    "        z = projection_head(embeddings_flat)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        \n",
    "        logits = classifier(z)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        probs = probs.view(128, 128, 128, 3).permute(3, 0, 1, 2)\n",
    "        return probs\n",
    "\n",
    "# Funciones para calcular métricas\n",
    "def calculate_metrics(pred, true,prob_maps=None, num_classes=3):\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    # Calcular Accuracy global\n",
    "    accuracy = accuracy_score(true.flatten(), pred.flatten())\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "\n",
    "        # F1 Score\n",
    "        f1 = f1_score(true_cls.flatten(), pred_cls.flatten(), zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "\n",
    "        # AUC-ROC (requiere mapas de probabilidad)\n",
    "        if prob_maps is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(true_cls.flatten(), prob_maps[cls].flatten())\n",
    "                auc_scores.append(auc)\n",
    "            except ValueError:\n",
    "                auc_scores.append(np.nan)  # Manejar casos donde AUC no se puede calcular\n",
    "        else:\n",
    "            auc_scores.append(np.nan)  # Si no se proporcionan mapas de probabilidad\n",
    "    \n",
    "    return dice_scores, sensitivity_scores, precision_scores, auc_scores, accuracy, f1_scores\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir = \"trained_models/mapas_combinados_temp_cube8_train_6_roi\" # mapas_combinados_pipe1_v01_pipe2_1dhzmigz_DTI\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejecutar calculo y guardar mapas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_0.png\n",
      "Caso 0 - Dice: [0.9965283923911065, 0.7510680249547851, 0.6373010934163637], Sensitivity: [0.9930846555431584, 0.8135382059318024, 0.8550301150423382], Precision: [0.9999960961608186, 0.6975076296695062, 0.5079533779534505], AUC-ROC: [0.9996141114101421, 0.9982643866435265, 0.9963533700744492], Accuracy: 0.9905, F1 Score: [0.9965283923913486, 0.7510680249753533, 0.6373010934305271]\n",
      "Guardado mapa de probabilidad en trained_models/mapas_combinados_temp_cube8_train_6_roi/probability_maps_case_0.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas_combinados_temp_cube8_train_6_roi/labels_case_0.nii.gz\n",
      "Guardada segmentación en trained_models/mapas_combinados_temp_cube8_train_6_roi/segmentation_case_0.nii.gz\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_1.png\n",
      "Caso 1 - Dice: [0.9961935453906653, 0.7573853989491772, 0.7093959615693377], Sensitivity: [0.9927675296776536, 0.8805763915435673, 0.8735349073860398], Precision: [0.9996432891758518, 0.6644325289943079, 0.597183916371108], AUC-ROC: [0.9991617817349431, 0.9987704145558074, 0.9967639233460344], Accuracy: 0.9909, F1 Score: [0.9961935453909074, 0.7573853989813244, 0.7093959615815701]\n",
      "Guardado mapa de probabilidad en trained_models/mapas_combinados_temp_cube8_train_6_roi/probability_maps_case_1.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas_combinados_temp_cube8_train_6_roi/labels_case_1.nii.gz\n",
      "Guardada segmentación en trained_models/mapas_combinados_temp_cube8_train_6_roi/segmentation_case_1.nii.gz\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_2.png\n",
      "Caso 2 - Dice: [0.9946951829942254, 0.6495593571237637, 0.38712302292663575], Sensitivity: [0.9896216869328199, 0.5427375107503988, 0.9631785396731395], Precision: [0.9998209677344074, 0.8087349395850397, 0.242242943059471], AUC-ROC: [0.9983193080957244, 0.9983511234241773, 0.9961696443027749], Accuracy: 0.9880, F1 Score: [0.9946951829944655, 0.649559357179886, 0.3871230229364797]\n",
      "Guardado mapa de probabilidad en trained_models/mapas_combinados_temp_cube8_train_6_roi/probability_maps_case_2.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas_combinados_temp_cube8_train_6_roi/labels_case_2.nii.gz\n",
      "Guardada segmentación en trained_models/mapas_combinados_temp_cube8_train_6_roi/segmentation_case_2.nii.gz\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_3.png\n",
      "Caso 3 - Dice: [0.9954219978265414, 0.7141616310605658, 0.811558219618579], Sensitivity: [0.9918490399207767, 0.9249993951340334, 0.7700595378837428], Precision: [0.9990207906749385, 0.5815966412032372, 0.8577844146908767], AUC-ROC: [0.9994691997128966, 0.9964043076918432, 0.996059979177656], Accuracy: 0.9798, F1 Score: [0.9954219978267969, 0.7141616310672357, 0.8115582196227943]\n",
      "Guardado mapa de probabilidad en trained_models/mapas_combinados_temp_cube8_train_6_roi/probability_maps_case_3.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas_combinados_temp_cube8_train_6_roi/labels_case_3.nii.gz\n",
      "Guardada segmentación en trained_models/mapas_combinados_temp_cube8_train_6_roi/segmentation_case_3.nii.gz\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_4.png\n",
      "Caso 4 - Dice: [0.9969358873437536, 0.7873751193027378, 0.6544701763724506], Sensitivity: [0.9939041744676321, 0.7655793693816368, 0.8678748381525744], Precision: [0.9999861521184785, 0.8104482695168737, 0.525301920932502], AUC-ROC: [0.9998924453048137, 0.9978815325961464, 0.9962206831555617], Accuracy: 0.9882, F1 Score: [0.9969358873439993, 0.7873751193127584, 0.6544701763834657]\n",
      "Guardado mapa de probabilidad en trained_models/mapas_combinados_temp_cube8_train_6_roi/probability_maps_case_4.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas_combinados_temp_cube8_train_6_roi/labels_case_4.nii.gz\n",
      "Guardada segmentación en trained_models/mapas_combinados_temp_cube8_train_6_roi/segmentation_case_4.nii.gz\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_5.png\n",
      "Caso 5 - Dice: [0.9970043186948825, 0.5201514861183869, 0.6986450945139275], Sensitivity: [0.9941744317759829, 0.46502252785115744, 0.8572993125746872], Precision: [0.9998503619738852, 0.5901096696338736, 0.5895426721695103], AUC-ROC: [0.9997574719368248, 0.9910903903079956, 0.993121674198418], Accuracy: 0.9818, F1 Score: [0.9970043186951304, 0.5201514861260519, 0.698645094520561]\n",
      "Guardado mapa de probabilidad en trained_models/mapas_combinados_temp_cube8_train_6_roi/probability_maps_case_5.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas_combinados_temp_cube8_train_6_roi/labels_case_5.nii.gz\n",
      "Guardada segmentación en trained_models/mapas_combinados_temp_cube8_train_6_roi/segmentation_case_5.nii.gz\n",
      "Guardada curva ROC promedio en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_average.png\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9961 ± 0.0008\n",
      "  Sensibilidad: 0.9926 ± 0.0015\n",
      "  Precisión: 0.9997 ± 0.0003\n",
      "  AUC-ROC: 0.9994 ± 0.0005\n",
      "  F1 Score: 0.9961 ± 0.0008\n",
      "\n",
      "Clase 1 (Vasogénico):\n",
      "  Dice: 0.6966 ± 0.0900\n",
      "  Sensibilidad: 0.7321 ± 0.1704\n",
      "  Precisión: 0.6921 ± 0.0922\n",
      "  AUC-ROC: 0.9968 ± 0.0027\n",
      "  F1 Score: 0.6966 ± 0.0900\n",
      "\n",
      "Clase 2 (Infiltrado):\n",
      "  Dice: 0.6497 ± 0.1299\n",
      "  Sensibilidad: 0.8645 ± 0.0561\n",
      "  Precisión: 0.5533 ± 0.1805\n",
      "  AUC-ROC: 0.9958 ± 0.0012\n",
      "  F1 Score: 0.6497 ± 0.1299\n",
      "\n",
      "Accuracy Global: 0.9865 ± 0.0042\n"
     ]
    }
   ],
   "source": [
    "# Listas para métricas\n",
    "all_dice = {0: [], 1: [], 2: []}\n",
    "all_sensitivity = {0: [], 1: [], 2: []}\n",
    "all_precision = {0: [], 1: [], 2: []}\n",
    "all_auc = {0: [], 1: [], 2: []}  # Lista para AUC-ROC\n",
    "all_accuracy = []  # Lista para Accuracy global\n",
    "all_f1 = {0: [], 1: [], 2: []}  # Lista para F1 Score\n",
    "# Listas para almacenar FPR y TPR de todos los casos\n",
    "all_fpr = {0: [], 1: [], 2: []}\n",
    "all_tpr = {0: [], 1: [], 2: []}\n",
    "\n",
    "\n",
    "# Procesar y combinar\n",
    "for idx, ((embeddings1, labels1), (embeddings2, labels2)) in enumerate(zip(loader_model1, loader_model2)):\n",
    "    # Generar mapas de probabilidad para ambos modelos\n",
    "    prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "    prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "    \n",
    "    # Combinar mapas: (Pipe1 y Pipe2)\n",
    "    # - Clase 0: del modelo 1\n",
    "    # - Clase 1: máximo entre ambos modelos\n",
    "    # - Clase 2: del modelo 2\n",
    "    combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "    combined_prob_maps[0] = prob_maps1[0]  # Clase 0 del modelo 1\n",
    "    combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Clase 1 máximo entre ambos\n",
    "    combined_prob_maps[2] = prob_maps2[2]  # Clase 2 del modelo 2\n",
    "    # Normalizar probabilidades para que sumen 1 en cada vóxel\n",
    "    combined_prob_maps = combined_prob_maps / combined_prob_maps.sum(dim=0, keepdim=True)\n",
    "\n",
    "    # # Solo Pipe1\n",
    "    # combined_prob_maps = prob_maps1\n",
    "\n",
    "    # # Solo Pipe2\n",
    "    # combined_prob_maps = prob_maps2\n",
    "    \n",
    "    # Convertir a numpy\n",
    "    prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "    prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "    \n",
    "    # Generar segmentación semántica\n",
    "    segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128]\n",
    "    # segmentation_np = segmentation.astype(np.uint8)\n",
    "\n",
    "    # Aplicar umbral: asignar clase 1 si la probabilidad es > 0.4\n",
    "    # class_1_mask = prob_maps_np[1] > 0.3  # Máscara booleana para clase 1\n",
    "    # segmentation[class_1_mask] = 1  # Asignar clase 1 a los vóxeles que cumplen el criterio\n",
    "    segmentation_np = segmentation.astype(np.uint8)\n",
    "    \n",
    "    # Etiquetas (usamos las del modelo 2, asumiendo que son iguales)\n",
    "    labels = labels2.squeeze(0)  # [128, 128, 128]\n",
    "    labels_np = labels.cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    # Calcular métricas\n",
    "    dice, sensitivity, precision, auc, accuracy, f1 = calculate_metrics(segmentation_np, labels_np, prob_maps=prob_maps_np)\n",
    "    for cls in range(3):\n",
    "        all_dice[cls].append(dice[cls])\n",
    "        all_sensitivity[cls].append(sensitivity[cls])\n",
    "        all_precision[cls].append(precision[cls])\n",
    "        all_auc[cls].append(auc[cls])\n",
    "        all_f1[cls].append(f1[cls])\n",
    "    all_accuracy.append(accuracy)\n",
    "\n",
    "     # Graficar curvas ROC\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    \n",
    "    for cls in range(3):\n",
    "        # Etiquetas binarias para la clase actual\n",
    "        true_cls = (labels_np == cls).astype(np.uint8).flatten()\n",
    "        prob_cls = prob_maps_np[cls].flatten()\n",
    "        \n",
    "        # Calcular puntos de la curva ROC\n",
    "        fpr, tpr, _ = roc_curve(true_cls, prob_cls)\n",
    "        auc_value = auc[cls]  # Usar el AUC calculado previamente\n",
    "        all_fpr[cls].append(fpr)\n",
    "        all_tpr[cls].append(tpr)\n",
    "        \n",
    "        # Graficar\n",
    "        plt.plot(fpr, tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value:.4f})')\n",
    "    \n",
    "    # Configurar el gráfico\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Línea diagonal (clasificador aleatorio)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC - Caso {idx}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Guardar el gráfico\n",
    "    roc_output_path = os.path.join(output_dir, f\"roc_curve_case_{idx}.png\")\n",
    "    plt.savefig(roc_output_path)\n",
    "    plt.close()\n",
    "    print(f\"Guardada curva ROC en {roc_output_path}\")\n",
    "\n",
    "    print(f\"Caso {idx} - Dice: {dice}, Sensitivity: {sensitivity}, Precision: {precision}, \"\n",
    "          f\"AUC-ROC: {auc}, Accuracy: {accuracy:.4f}, F1 Score: {f1}\")\n",
    "    \n",
    "    # Crear imágenes NIfTI\n",
    "    affine = np.eye(4)\n",
    "    \n",
    "    # Guardar mapas de probabilidad combinados\n",
    "    nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine)\n",
    "    prob_output_path = os.path.join(output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_prob_img, prob_output_path)\n",
    "    print(f\"Guardado mapa de probabilidad en {prob_output_path}\")\n",
    "    \n",
    "    # Guardar etiquetas\n",
    "    nifti_label_img = nib.Nifti1Image(labels_np, affine)\n",
    "    label_output_path = os.path.join(output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_label_img, label_output_path)\n",
    "    print(f\"Guardadas etiquetas en {label_output_path}\")\n",
    "    \n",
    "    # Guardar segmentación semántica\n",
    "    nifti_seg_img = nib.Nifti1Image(segmentation_np, affine)\n",
    "    seg_output_path = os.path.join(output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_seg_img, seg_output_path)\n",
    "    print(f\"Guardada segmentación en {seg_output_path}\")\n",
    "\n",
    "# Curva ROC Promedio\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cls in range(3):\n",
    "    # Interpolar FPR y TPR a una base común\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    for fpr, tpr in zip(all_fpr[cls], all_tpr[cls]):\n",
    "        tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0  # Asegurar que comienza en 0\n",
    "        tprs.append(tpr_interp)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0  # Asegurar que termina en 1\n",
    "    mean_auc = np.nanmean(all_auc[cls])\n",
    "    \n",
    "    plt.plot(mean_fpr, mean_tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC Promedio')\n",
    "plt.legend(loc=\"lower right\")\n",
    "roc_avg_path = os.path.join(output_dir, \"roc_curve_average.png\")\n",
    "plt.savefig(roc_avg_path)\n",
    "plt.close()\n",
    "print(f\"Guardada curva ROC promedio en {roc_avg_path}\")\n",
    "\n",
    "# # Calcular promedios y desviaciones estándar\n",
    "# class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "# for cls in range(3):\n",
    "#     dice_mean = np.mean(all_dice[cls])\n",
    "#     dice_std = np.std(all_dice[cls])\n",
    "#     sens_mean = np.mean(all_sensitivity[cls])\n",
    "#     sens_std = np.std(all_sensitivity[cls])\n",
    "#     prec_mean = np.mean(all_precision[cls])\n",
    "#     prec_std = np.std(all_precision[cls])\n",
    "    \n",
    "#     print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "#     print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "#     print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "#     print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "\n",
    "# Calcular promedios y desviaciones estándar\n",
    "class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice[cls])\n",
    "    dice_std = np.nanstd(all_dice[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity[cls])\n",
    "    prec_mean = np.nanmean(all_precision[cls])\n",
    "    prec_std = np.nanstd(all_precision[cls])\n",
    "    auc_mean = np.nanmean(all_auc[cls])\n",
    "    auc_std = np.nanstd(all_auc[cls])\n",
    "    f1_mean = np.nanmean(all_f1[cls])\n",
    "    f1_std = np.nanstd(all_f1[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "# Accuracy global\n",
    "accuracy_mean = np.nanmean(all_accuracy)\n",
    "accuracy_std = np.nanstd(all_accuracy)\n",
    "print(f\"\\nAccuracy Global: {accuracy_mean:.4f} ± {accuracy_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas basdas en regions (supervoxeles) TN - todo el volumen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_0.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_cube_case_0.png\n",
      "Caso 0 - Voxel-wise:\n",
      "  Dice: [0.9965283923911065, 0.7510680249547851, 0.6373010934163637], Sensitivity: [0.9930846555431584, 0.8135382059318024, 0.8550301150423382], Precision: [0.9999960961608186, 0.6975076296695062, 0.5079533779534505], AUC-ROC: [0.9996141114101421, 0.9982643866435265, 0.9963533700744492], Accuracy: 0.9905, F1 Score: [0.9965283923913486, 0.7510680249753533, 0.6373010934305271]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [61.15818922 64.0628179  59.59348932]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [62.13075463 67.01934029 58.55481728]\n",
      "  Distancia entre centros (Voxel-wise): 3.2811198899580756\n",
      "Caso 0 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9980153806750166, 0.7428571322448981, 0.7333333211111114], Sensitivity: [0.9962852895006723, 0.8124999746093758, 0.8461538136094686], Precision: [0.9997514908052307, 0.6842105083102499, 0.6470588044982705], AUC-ROC: [0.9997779713412239, 0.9509296567421259, 0.9987006237006237], Accuracy: 0.9939, F1 Score: [0.9980153807988091, 0.742857142857143, 0.7333333333333334]\n",
      "  Centro de masa Infiltrado (Pred): [7.23684211 7.57894737 7.        ]\n",
      "  Centro de masa Infiltrado (True): [7.40625 8.09375 7.     ]\n",
      "Distancia entre centros: 0.541960131633111\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_1.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_cube_case_1.png\n",
      "Caso 1 - Voxel-wise:\n",
      "  Dice: [0.9961935453906653, 0.7573853989491772, 0.7093959615693377], Sensitivity: [0.9927675296776536, 0.8805763915435673, 0.8735349073860398], Precision: [0.9996432891758518, 0.6644325289943079, 0.597183916371108], AUC-ROC: [0.9991617817349431, 0.9987704145558074, 0.9967639233460344], Accuracy: 0.9909, F1 Score: [0.9961935453909074, 0.7573853989813244, 0.7093959615815701]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [67.77353292 65.54386357 62.98793566]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [67.84198579 65.86320568 61.8769246 ]\n",
      "  Distancia entre centros (Voxel-wise): 1.1580201904954446\n",
      "Caso 1 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9973955102322466, 0.8648648414901394, 0.7391304267485823], Sensitivity: [0.9952970294566097, 0.8888888395061756, 0.8947368185595574], Precision: [0.9995028583148141, 0.8421052188365674, 0.6296296179698219], AUC-ROC: [0.9992441654879775, 0.9997752166094491, 0.9984274078493425], Accuracy: 0.9939, F1 Score: [0.9973955103559469, 0.8648648648648649, 0.7391304347826088]\n",
      "  Centro de masa Infiltrado (Pred): [7.78947368 7.78947368 7.26315789]\n",
      "  Centro de masa Infiltrado (True): [8.05555556 8.         7.27777778]\n",
      "Distancia entre centros: 0.33960953001718336\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_2.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_cube_case_2.png\n",
      "Caso 2 - Voxel-wise:\n",
      "  Dice: [0.9946951829942254, 0.6495593571237637, 0.38712302292663575], Sensitivity: [0.9896216869328199, 0.5427375107503988, 0.9631785396731395], Precision: [0.9998209677344074, 0.8087349395850397, 0.242242943059471], AUC-ROC: [0.9983193080957244, 0.9983511234241773, 0.9961696443027749], Accuracy: 0.9880, F1 Score: [0.9946951829944655, 0.649559357179886, 0.3871230229364797]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [59.83089501 73.98493976 69.73472461]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [57.16734046 74.76653191 72.597892  ]\n",
      "  Distancia entre centros (Voxel-wise): 3.9878736985970944\n",
      "Caso 2 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9967988179023887, 0.6999999650000017, 0.3999999920000002], Sensitivity: [0.9936180655391218, 0.5833332847222263, 0.99999990000001], Precision: [0.9999999997529645, 0.8749998906250137, 0.24999999375000018], AUC-ROC: [0.9991911009952247, 0.9556909076069212, 0.9987273617229565], Accuracy: 0.9924, F1 Score: [0.9967988180251169, 0.7000000000000001, 0.4]\n",
      "  Centro de masa Infiltrado (Pred): [7.    9.    9.125]\n",
      "  Centro de masa Infiltrado (True): [6.83333333 8.83333333 8.58333333]\n",
      "Distancia entre centros: 0.5907269532815754\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_3.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_cube_case_3.png\n",
      "Caso 3 - Voxel-wise:\n",
      "  Dice: [0.9954219978265414, 0.7141616310605658, 0.811558219618579], Sensitivity: [0.9918490399207767, 0.9249993951340334, 0.7700595378837428], Precision: [0.9990207906749385, 0.5815966412032372, 0.8577844146908767], AUC-ROC: [0.9994691997128966, 0.9964043076918432, 0.996059979177656], Accuracy: 0.9798, F1 Score: [0.9954219978267969, 0.7141616310672357, 0.8115582196227943]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [78.99292647 50.64653625 61.25139189]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [81.33755111 53.92250744 57.86410374]\n",
      "  Distancia entre centros (Voxel-wise): 5.263361372764163\n",
      "Caso 3 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9972502290169896, 0.7373737336496277, 0.8291316503385668], Sensitivity: [0.9955555552952796, 0.9605263031509698, 0.7589743550821828], Precision: [0.998950681794609, 0.5983606508331094, 0.913580241274196], AUC-ROC: [0.9995678074427803, 0.9972096753076722, 0.9817804770637378], Accuracy: 0.9836, F1 Score: [0.997250229147571, 0.7373737373737373, 0.8291316526610644]\n",
      "  Centro de masa Infiltrado (Pred): [9.64754098 5.71311475 7.29508197]\n",
      "  Centro de masa Infiltrado (True): [9.71052632 6.19736842 6.77631579]\n",
      "Distancia entre centros: 0.7124514812920449\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_4.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_cube_case_4.png\n",
      "Caso 4 - Voxel-wise:\n",
      "  Dice: [0.9969358873437536, 0.7873751193027378, 0.6544701763724506], Sensitivity: [0.9939041744676321, 0.7655793693816368, 0.8678748381525744], Precision: [0.9999861521184785, 0.8104482695168737, 0.525301920932502], AUC-ROC: [0.9998924453048137, 0.9978815325961464, 0.9962206831555617], Accuracy: 0.9882, F1 Score: [0.9969358873439993, 0.7873751193127584, 0.6544701763834657]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [68.43019204 64.16429563 63.78123608]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [65.69935158 63.25543236 61.42414493]\n",
      "  Distancia entre centros (Voxel-wise): 3.7201345084709243\n",
      "Caso 4 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9973581581334308, 0.82993196714332, 0.7083333259548612], Sensitivity: [0.995479658213089, 0.7922077819193795, 0.9189188940832732], Precision: [0.999243760776596, 0.871428558979592, 0.5762711766733699], AUC-ROC: [0.9997874205856178, 0.9914787874479339, 0.9960381667698741], Accuracy: 0.9910, F1 Score: [0.9973581582589005, 0.8299319727891157, 0.7083333333333333]\n",
      "  Centro de masa Infiltrado (Pred): [8.01428571 7.51428571 7.51428571]\n",
      "  Centro de masa Infiltrado (True): [7.80519481 7.49350649 7.15584416]\n",
      "Distancia entre centros: 0.4154890312615578\n",
      "Guardada curva ROC en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_case_5.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_cube_case_5.png\n",
      "Caso 5 - Voxel-wise:\n",
      "  Dice: [0.9970043186948825, 0.5201514861183869, 0.6986450945139275], Sensitivity: [0.9941744317759829, 0.46502252785115744, 0.8572993125746872], Precision: [0.9998503619738852, 0.5901096696338736, 0.5895426721695103], AUC-ROC: [0.9997574719368248, 0.9910903903079956, 0.993121674198418], Accuracy: 0.9818, F1 Score: [0.9970043186951304, 0.5201514861260519, 0.698645094520561]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [58.84790023 70.68128929 65.09629531]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [64.13885595 62.57826786 57.30295365]\n",
      "  Distancia entre centros (Voxel-wise): 12.425350815714664\n",
      "Caso 5 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9978418178243186, 0.539682535399345, 0.6560846526133087], Sensitivity: [0.9956929310879927, 0.4415584358239164, 0.8611110991512347], Precision: [0.9999999997455471, 0.6938775368596422, 0.529914525385346], AUC-ROC: [0.9998240104199434, 0.9316364153388288, 0.9923341893085929], Accuracy: 0.9829, F1 Score: [0.9978418179509966, 0.5396825396825397, 0.6560846560846562]\n",
      "  Centro de masa Infiltrado (Pred): [6.81632653 8.55102041 7.75510204]\n",
      "  Centro de masa Infiltrado (True): [7.50649351 7.45454545 6.74025974]\n",
      "Distancia entre centros: 1.645749881819\n",
      "\n",
      "Resultados Voxel-wise:\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9961 ± 0.0008\n",
      "  Sensibilidad: 0.9926 ± 0.0015\n",
      "  Precisión: 0.9997 ± 0.0003\n",
      "  AUC-ROC: 0.9994 ± 0.0005\n",
      "  F1 Score: 0.9961 ± 0.0008\n",
      "\n",
      "Clase 1 (Treatment Zone):\n",
      "  Dice: 0.6966 ± 0.0900\n",
      "  Sensibilidad: 0.7321 ± 0.1704\n",
      "  Precisión: 0.6921 ± 0.0922\n",
      "  AUC-ROC: 0.9968 ± 0.0027\n",
      "  F1 Score: 0.6966 ± 0.0900\n",
      "\n",
      "Clase 2 (Vasogenic):\n",
      "  Dice: 0.6497 ± 0.1299\n",
      "  Sensibilidad: 0.8645 ± 0.0561\n",
      "  Precisión: 0.5533 ± 0.1805\n",
      "  AUC-ROC: 0.9958 ± 0.0012\n",
      "  F1 Score: 0.6497 ± 0.1299\n",
      "\n",
      "Accuracy Global: 0.9865 ± 0.0042\n",
      "\n",
      "Distancia entre centros Global (Voxel-wise): 4.9726 ± 3.5491\n",
      "Saved average ROC curve (voxel-level) to trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_average.png\n",
      "\n",
      "Resultados Cube-wise:\n",
      "\n",
      "Clase 0 (Background):\n",
      "  Dice: 0.9974 ± 0.0004\n",
      "  Sensibilidad: 0.9953 ± 0.0008\n",
      "  Precisión: 0.9996 ± 0.0004\n",
      "  AUC-ROC: 0.9996 ± 0.0003\n",
      "  F1 Score: 0.9974 ± 0.0004\n",
      "\n",
      "Clase 1 (Treatment Zone):\n",
      "  Dice: 0.7358 ± 0.1043\n",
      "  Sensibilidad: 0.7465 ± 0.1790\n",
      "  Precisión: 0.7608 ± 0.1069\n",
      "  AUC-ROC: 0.9711 ± 0.0262\n",
      "  F1 Score: 0.7358 ± 0.1043\n",
      "\n",
      "Clase 2 (Vasogenic):\n",
      "  Dice: 0.6777 ± 0.1344\n",
      "  Sensibilidad: 0.8800 ± 0.0734\n",
      "  Precisión: 0.5911 ± 0.1953\n",
      "  AUC-ROC: 0.9943 ± 0.0061\n",
      "  F1 Score: 0.6777 ± 0.1344\n",
      "\n",
      "Generando curva ROC promedio para métricas cube-wise...\n",
      "Saved average ROC curve (regional-level) to trained_models/mapas_combinados_temp_cube8_train_6_roi/roc_curve_average_cube.png\n",
      "\n",
      "Accuracy Global Cube-wise: 0.9896 ± 0.0046\n",
      "\n",
      "Distancia entre centros Global: 0.7077 ± 0.4363\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from scipy import stats\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "# Función para calcular métricas (ya definida previamente)\n",
    "def calculate_metrics(pred, true, prob_maps=None, num_classes=3):\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    accuracy = accuracy_score(true.flatten(), pred.flatten())\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "        \n",
    "        f1 = f1_score(true_cls.flatten(), pred_cls.flatten(), zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        if prob_maps is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(true_cls.flatten(), prob_maps[cls].flatten())\n",
    "                auc_scores.append(auc)\n",
    "            except ValueError:\n",
    "                auc_scores.append(np.nan)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)\n",
    "    \n",
    "    return dice_scores, sensitivity_scores, precision_scores, auc_scores, accuracy, f1_scores\n",
    "\n",
    "# Función para dividir en cubos y obtener clases predominantes\n",
    "def get_cube_labels(volume, cube_size, num_classes=3):\n",
    "    dims = volume.shape\n",
    "    assert dims[0] % cube_size == 0, \"El tamaño del cubo debe dividir exactamente el tamaño del volumen\"\n",
    "    num_cubes = dims[0] // cube_size\n",
    "    \n",
    "    cube_labels = np.zeros((num_cubes, num_cubes, num_cubes), dtype=np.uint8)\n",
    "    cube_probs = np.zeros((num_classes, num_cubes, num_cubes, num_cubes))\n",
    "    \n",
    "    for i in range(num_cubes):\n",
    "        for j in range(num_cubes):\n",
    "            for k in range(num_cubes):\n",
    "                cube = volume[i*cube_size:(i+1)*cube_size, \n",
    "                             j*cube_size:(j+1)*cube_size, \n",
    "                             k*cube_size:(k+1)*cube_size]\n",
    "                # Clase predominante (modo)\n",
    "                mode_value = stats.mode(cube.flatten(), keepdims=True)[0][0]\n",
    "                cube_labels[i, j, k] = mode_value\n",
    "                # Proporción de cada clase como \"probabilidad\" suavizada\n",
    "                for cls in range(num_classes):\n",
    "                    cube_probs[cls, i, j, k] = np.mean(cube == cls)\n",
    "    \n",
    "    return cube_labels, cube_probs\n",
    "\n",
    "# Listas para métricas voxel-wise\n",
    "all_dice = {0: [], 1: [], 2: []}\n",
    "all_sensitivity = {0: [], 1: [], 2: []}\n",
    "all_precision = {0: [], 1: [], 2: []}\n",
    "all_auc = {0: [], 1: [], 2: []}\n",
    "all_accuracy = []\n",
    "all_f1 = {0: [], 1: [], 2: []}\n",
    "# Listas para almacenar FPR y TPR de todos los casos\n",
    "all_fpr = {0: [], 1: [], 2: []}\n",
    "all_tpr = {0: [], 1: [], 2: []}\n",
    "all_center_distance_voxel = []\n",
    "\n",
    "# Listas para métricas cube-wise\n",
    "all_dice_cube = {0: [], 1: [], 2: []}\n",
    "all_sensitivity_cube = {0: [], 1: [], 2: []}\n",
    "all_precision_cube = {0: [], 1: [], 2: []}\n",
    "all_auc_cube = {0: [], 1: [], 2: []}\n",
    "all_accuracy_cube = []\n",
    "all_f1_cube = {0: [], 1: [], 2: []}\n",
    "all_center_distance=[]\n",
    "# Listas para almacenar FPR y TPR de todos los casos\n",
    "all_fpr_cube = {0: [], 1: [], 2: []}\n",
    "all_tpr_cube = {0: [], 1: [], 2: []}\n",
    "\n",
    "# Tamaño del cubo (ajusta según necesites)\n",
    "cube_size = 8  # 128 / 8 = 16 cubos por dimensión\n",
    "\n",
    "# Procesar y combinar\n",
    "for idx, ((embeddings1, labels1), (embeddings2, labels2)) in enumerate(zip(loader_model1, loader_model2)):\n",
    "    # Generar mapas de probabilidad para ambos modelos\n",
    "    prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "    prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "    \n",
    "    # Combinar mapas: (Pipe1 y Pipe2)\n",
    "    # - Clase 0: del modelo 1\n",
    "    # - Clase 1: máximo entre ambos modelos\n",
    "    # - Clase 2: del modelo 2\n",
    "    combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "    combined_prob_maps[0] = prob_maps1[0]  # Clase 0 del modelo 1\n",
    "    combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Clase 1 máximo entre ambos\n",
    "    combined_prob_maps[2] = prob_maps2[2]  # Clase 2 del modelo 2\n",
    "    # Normalizar probabilidades para que sumen 1 en cada vóxel\n",
    "    combined_prob_maps = combined_prob_maps / combined_prob_maps.sum(dim=0, keepdim=True)\n",
    "\n",
    "    # # Solo Pipe1\n",
    "    # combined_prob_maps = prob_maps1\n",
    "\n",
    "    # # Solo Pipe2\n",
    "    # combined_prob_maps = prob_maps2\n",
    "    \n",
    "    # Convertir a numpy\n",
    "    prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "    prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "    \n",
    "    # Generar segmentación semántica\n",
    "    segmentation = np.argmax(prob_maps_np, axis=0)\n",
    "    # Colocar nuevo umbral para infiltracion\n",
    "    # class_1_mask = prob_maps_np[1] > 0.4\n",
    "    # segmentation[class_1_mask] = 1\n",
    "    segmentation_np = segmentation.astype(np.uint8)\n",
    "    \n",
    "    # Etiquetas\n",
    "    labels = labels2.squeeze(0)\n",
    "    labels_np = labels.cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    # Calcular métricas voxel-wise\n",
    "    dice, sensitivity, precision, auc, accuracy, f1 = calculate_metrics(segmentation_np, labels_np, prob_maps=prob_maps_np)\n",
    "    \n",
    "    # Almacenar métricas voxel-wise\n",
    "    for cls in range(3):\n",
    "        all_dice[cls].append(dice[cls])\n",
    "        all_sensitivity[cls].append(sensitivity[cls])\n",
    "        all_precision[cls].append(precision[cls])\n",
    "        all_auc[cls].append(auc[cls])\n",
    "        all_f1[cls].append(f1[cls])\n",
    "    all_accuracy.append(accuracy)\n",
    "\n",
    "    # ***** NUEVO: Análisis espacial voxel-wise para la clase Infiltrado (Clase 1) *****\n",
    "    infiltrado_pred_voxel = (segmentation_np == 1).astype(np.uint8)\n",
    "    infiltrado_true_voxel = (labels_np == 1).astype(np.uint8)\n",
    "    if np.sum(infiltrado_pred_voxel) > 0:\n",
    "        pred_center_voxel = np.mean(np.where(infiltrado_pred_voxel), axis=1)\n",
    "    else:\n",
    "        pred_center_voxel = np.array([np.nan, np.nan, np.nan])\n",
    "    if np.sum(infiltrado_true_voxel) > 0:\n",
    "        true_center_voxel = np.mean(np.where(infiltrado_true_voxel), axis=1)\n",
    "    else:\n",
    "        true_center_voxel = np.array([np.nan, np.nan, np.nan])\n",
    "    distance_voxel = np.linalg.norm(pred_center_voxel - true_center_voxel) if not np.any(np.isnan(pred_center_voxel)) and not np.any(np.isnan(true_center_voxel)) else np.nan\n",
    "    all_center_distance_voxel.append(distance_voxel)\n",
    "\n",
    "    # Graficar curvas ROC\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_names = ['Background', 'Treatment Zone', 'Vasogenic']\n",
    "    title_fs = 16\n",
    "    label_fs = 14\n",
    "    legend_fs = 12\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    \n",
    "    for cls in range(3):\n",
    "        # Etiquetas binarias para la clase actual\n",
    "        true_cls = (labels_np == cls).astype(np.uint8).flatten()\n",
    "        prob_cls = prob_maps_np[cls].flatten()\n",
    "        \n",
    "        # Calcular puntos de la curva ROC\n",
    "        fpr, tpr, _ = roc_curve(true_cls, prob_cls)\n",
    "        auc_value = auc[cls]  # Usar el AUC calculado previamente\n",
    "        all_fpr[cls].append(fpr)\n",
    "        all_tpr[cls].append(tpr)\n",
    "        \n",
    "        # Graficar\n",
    "        plt.plot(fpr, tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value:.4f})')\n",
    "    \n",
    "    # Configurar el gráfico\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Línea diagonal (clasificador aleatorio)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC - Caso {idx}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Guardar el gráfico\n",
    "    roc_output_path = os.path.join(output_dir, f\"roc_curve_case_{idx}.png\")\n",
    "    plt.savefig(roc_output_path)\n",
    "    plt.close()\n",
    "    print(f\"Guardada curva ROC en {roc_output_path}\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    ################################\n",
    "    # Evaluación basada en cubos\n",
    "    ####################################\n",
    "    pred_cube_labels, pred_cube_probs = get_cube_labels(segmentation_np, cube_size)\n",
    "    true_cube_labels, true_cube_probs = get_cube_labels(labels_np, cube_size)\n",
    "    \n",
    "    # Calcular métricas cube-wise\n",
    "    dice_cube, sensitivity_cube, precision_cube, auc_cube, accuracy_cube, f1_cube = calculate_metrics(\n",
    "        pred_cube_labels, true_cube_labels, prob_maps=pred_cube_probs\n",
    "    )\n",
    "    \n",
    "    # Almacenar métricas cube-wise\n",
    "    for cls in range(3):\n",
    "        all_dice_cube[cls].append(dice_cube[cls])\n",
    "        all_sensitivity_cube[cls].append(sensitivity_cube[cls])\n",
    "        all_precision_cube[cls].append(precision_cube[cls])\n",
    "        all_auc_cube[cls].append(auc_cube[cls])\n",
    "        all_f1_cube[cls].append(f1_cube[cls])\n",
    "    all_accuracy_cube.append(accuracy_cube)\n",
    "\n",
    "    # ***** NUEVO: Calcular y graficar curvas ROC para métricas cube-wise *****\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_names = [\"Background\", \"Treatment Zone\", \"Vasogenic\"]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    \n",
    "    for cls in range(3):\n",
    "        # Etiquetas binarias para la clase actual (cube-wise)\n",
    "        true_cls_cube = (true_cube_labels == cls).astype(np.uint8).flatten()\n",
    "        prob_cls_cube = pred_cube_probs[cls].flatten()\n",
    "        \n",
    "        # Calcular puntos de la curva ROC\n",
    "        fpr_cube, tpr_cube, _ = roc_curve(true_cls_cube, prob_cls_cube)\n",
    "        auc_value_cube = auc_cube[cls]  # Usar el AUC calculado previamente\n",
    "        all_fpr_cube[cls].append(fpr_cube)\n",
    "        all_tpr_cube[cls].append(tpr_cube)\n",
    "        \n",
    "        # Graficar\n",
    "        plt.plot(fpr_cube, tpr_cube, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value_cube:.4f})')\n",
    "    \n",
    "    # Configurar el gráfico\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Línea diagonal (clasificador aleatorio)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC Cube-wise - Caso {idx}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Guardar el gráfico\n",
    "    roc_cube_output_path = os.path.join(output_dir, f\"roc_curve_cube_case_{idx}.png\")\n",
    "    plt.savefig(roc_cube_output_path)\n",
    "    plt.close()\n",
    "    print(f\"Guardada curva ROC cube-wise en {roc_cube_output_path}\")\n",
    "    \n",
    "    # Mapa de coincidencias/discrepancias\n",
    "    match_map = (pred_cube_labels == true_cube_labels).astype(np.uint8)\n",
    "    mismatch_map = (pred_cube_labels != true_cube_labels).astype(np.uint8)\n",
    "    \n",
    "    # Guardar mapas de cubos y coincidencias\n",
    "    # affine = np.eye(4) * cube_size  # Ajustar el affine para reflejar el tamaño del cubo\n",
    "    affine2 = affine * cube_size\n",
    "    nib.save(nib.Nifti1Image(pred_cube_labels, affine2), os.path.join(output_dir, f\"pred_cube_labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(true_cube_labels, affine2), os.path.join(output_dir, f\"true_cube_labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(match_map, affine2), os.path.join(output_dir, f\"match_map_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(mismatch_map, affine2), os.path.join(output_dir, f\"mismatch_map_case_{idx}.nii.gz\"))\n",
    "\n",
    "    # Análisis espacial (centro de masa de la clase Infiltrado)\n",
    "    infiltrado_pred = (pred_cube_labels == 1).astype(np.uint8)\n",
    "    infiltrado_true = (true_cube_labels == 1).astype(np.uint8)\n",
    "    if np.sum(infiltrado_pred) > 0:\n",
    "        pred_center = np.mean(np.where(infiltrado_pred), axis=1)\n",
    "    else:\n",
    "        pred_center = np.array([np.nan, np.nan, np.nan])\n",
    "    if np.sum(infiltrado_true) > 0:\n",
    "        true_center = np.mean(np.where(infiltrado_true), axis=1)\n",
    "    else:\n",
    "        true_center = np.array([np.nan, np.nan, np.nan])\n",
    "    distance = np.linalg.norm(pred_center - true_center) if not np.any(np.isnan(pred_center)) and not np.any(np.isnan(true_center)) else np.nan\n",
    "    all_center_distance.append(distance)\n",
    "\n",
    "    print(f\"Caso {idx} - Voxel-wise:\")\n",
    "    print(f\"  Dice: {dice}, Sensitivity: {sensitivity}, Precision: {precision}, AUC-ROC: {auc}, \"\n",
    "          f\"Accuracy: {accuracy:.4f}, F1 Score: {f1}\")\n",
    "    print(f\"  Centro de masa Infiltrado (Pred, Voxel-wise): {pred_center_voxel}\")\n",
    "    print(f\"  Centro de masa Infiltrado (True, Voxel-wise): {true_center_voxel}\")\n",
    "    print(f\"  Distancia entre centros (Voxel-wise): {distance_voxel}\")\n",
    "\n",
    "    print(f\"Caso {idx} - Cube-wise (tamaño {cube_size}):\")\n",
    "    print(f\"  Dice: {dice_cube}, Sensitivity: {sensitivity_cube}, Precision: {precision_cube}, \"\n",
    "          f\"AUC-ROC: {auc_cube}, Accuracy: {accuracy_cube:.4f}, F1 Score: {f1_cube}\")\n",
    "    print(f\"  Centro de masa Infiltrado (Pred): {pred_center}\")\n",
    "    print(f\"  Centro de masa Infiltrado (True): {true_center}\")\n",
    "    print(f\"Distancia entre centros: {distance}\")\n",
    "    \n",
    "    # Guardar mapas de probabilidad y segmentaciones voxel-wise\n",
    "    nib.save(nib.Nifti1Image(prob_maps_np_nifti, affine), os.path.join(output_dir, f\"probability_maps_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(labels_np, affine), os.path.join(output_dir, f\"labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(segmentation_np, affine), os.path.join(output_dir, f\"segmentation_case_{idx}.nii.gz\"))\n",
    "\n",
    "# Calcular promedios y desviaciones estándar (voxel-wise)\n",
    "class_names = [\"Fondo\", \"Treatment Zone\", \"Vasogenic\", ]\n",
    "print(\"\\nResultados Voxel-wise:\")\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice[cls])\n",
    "    dice_std = np.nanstd(all_dice[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity[cls])\n",
    "    prec_mean = np.nanmean(all_precision[cls])\n",
    "    prec_std = np.nanstd(all_precision[cls])\n",
    "    auc_mean = np.nanmean(all_auc[cls])\n",
    "    auc_std = np.nanstd(all_auc[cls])\n",
    "    f1_mean = np.nanmean(all_f1[cls])\n",
    "    f1_std = np.nanstd(all_f1[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "accuracy_mean = np.nanmean(all_accuracy)\n",
    "accuracy_std = np.nanstd(all_accuracy)\n",
    "print(f\"\\nAccuracy Global: {accuracy_mean:.4f} ± {accuracy_std:.4f}\")\n",
    "# ***** NUEVO: Calcular promedio y desviación estándar para distancia voxel-wise *****\n",
    "dist_mean_voxel = np.nanmean(all_center_distance_voxel)\n",
    "dist_std_voxel = np.nanstd(all_center_distance_voxel)\n",
    "print(f\"\\nDistancia entre centros Global (Voxel-wise): {dist_mean_voxel:.4f} ± {dist_std_voxel:.4f}\")\n",
    "\n",
    "#######################\n",
    "# Curvas ROC Promedio\n",
    "###########################\n",
    "# 1. Definir nombres de clases en inglés y tamaños de fuente\n",
    "class_names = ['Background', 'Treatment Zone', 'Vasogenic']\n",
    "title_fs = 16\n",
    "label_fs = 14\n",
    "legend_fs = 12\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "for cls in range(3):\n",
    "    # Interpolar FPR y TPR a una base común\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    for fpr, tpr in zip(all_fpr[cls], all_tpr[cls]):\n",
    "        tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0  # Asegurar que comienza en 0\n",
    "        tprs.append(tpr_interp)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0  # Asegurar que termina en 1\n",
    "    mean_auc = np.nanmean(all_auc[cls])\n",
    "    \n",
    "    plt.plot(mean_fpr, mean_tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Aplicar textos en inglés y tamaños de fuente\n",
    "plt.xlabel('False Positive Rate', fontsize=label_fs)\n",
    "plt.ylabel('True Positive Rate', fontsize=label_fs)\n",
    "plt.title('Average ROC curve per class at the voxel level', fontsize=title_fs)\n",
    "plt.legend(loc=\"lower right\", fontsize=legend_fs)\n",
    "\n",
    "# Guardar figura minimizando el espacio exterior\n",
    "roc_avg_path = os.path.join(output_dir, \"roc_curve_average.png\")\n",
    "plt.savefig(roc_avg_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved average ROC curve (voxel-level) to {roc_avg_path}\")\n",
    "\n",
    "# Calcular promedios y desviaciones estándar (cube-wise)\n",
    "print(\"\\nResultados Cube-wise:\")\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice_cube[cls])\n",
    "    dice_std = np.nanstd(all_dice_cube[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity_cube[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity_cube[cls])\n",
    "    prec_mean = np.nanmean(all_precision_cube[cls])\n",
    "    prec_std = np.nanstd(all_precision_cube[cls])\n",
    "    auc_mean = np.nanmean(all_auc_cube[cls])\n",
    "    auc_std = np.nanstd(all_auc_cube[cls])\n",
    "    f1_mean = np.nanmean(all_f1_cube[cls])\n",
    "    f1_std = np.nanstd(all_f1_cube[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "# ***** NUEVO: Curva ROC promedio para métricas cube-wise *****\n",
    "print(\"\\nGenerando curva ROC promedio para métricas cube-wise...\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cls in range(3):\n",
    "    # Interpolar FPR y TPR a una base común\n",
    "    mean_fpr_cube = np.linspace(0, 1, 100)\n",
    "    tprs_cube = []\n",
    "    for fpr, tpr in zip(all_fpr_cube[cls], all_tpr_cube[cls]):\n",
    "        tpr_interp = np.interp(mean_fpr_cube, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0  # Asegurar que comienza en 0\n",
    "        tprs_cube.append(tpr_interp)\n",
    "    mean_tpr_cube = np.mean(tprs_cube, axis=0)\n",
    "    mean_tpr_cube[-1] = 1.0  # Asegurar que termina en 1\n",
    "    mean_auc_cube = np.nanmean(all_auc_cube[cls])\n",
    "    \n",
    "    plt.plot(mean_fpr_cube, mean_tpr_cube, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc_cube:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "\n",
    "# Aplicar textos en inglés y tamaños de fuente\n",
    "plt.xlabel('False Positive Rate', fontsize=label_fs)\n",
    "plt.ylabel('True Positive Rate', fontsize=label_fs)\n",
    "plt.title('Average ROC curve per class at the regional level', fontsize=title_fs)\n",
    "plt.legend(loc=\"lower right\", fontsize=legend_fs)\n",
    "\n",
    "# Guardar figura minimizando el espacio exterior\n",
    "roc_avg_cube_path = os.path.join(output_dir, \"roc_curve_average_cube.png\")\n",
    "plt.savefig(roc_avg_cube_path, bbox_inches='tight')\n",
    "plt.close()\n",
    "print(f\"Saved average ROC curve (regional-level) to {roc_avg_cube_path}\")\n",
    "\n",
    "accuracy_mean_cube = np.nanmean(all_accuracy_cube)\n",
    "accuracy_std_cube = np.nanstd(all_accuracy_cube)\n",
    "print(f\"\\nAccuracy Global Cube-wise: {accuracy_mean_cube:.4f} ± {accuracy_std_cube:.4f}\")\n",
    "\n",
    "dist_mean = np.nanmean(all_center_distance)\n",
    "dist_std = np.nanstd(all_center_distance)\n",
    "print(f\"\\nDistancia entre centros Global: {dist_mean:.4f} ± {dist_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas basdas en regions (supervoxeles) TN - solo lesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iniciando evaluación completa (Voxel & Cube size 8)...\n",
      "Caso 0 Procesado. Dice Inf Voxel: 0.751 | Dice Inf Cube: 0.722\n",
      "Caso 1 Procesado. Dice Inf Voxel: 0.757 | Dice Inf Cube: 0.789\n",
      "Caso 2 Procesado. Dice Inf Voxel: 0.650 | Dice Inf Cube: 0.700\n",
      "Caso 3 Procesado. Dice Inf Voxel: 0.714 | Dice Inf Cube: 0.734\n",
      "Caso 4 Procesado. Dice Inf Voxel: 0.787 | Dice Inf Cube: 0.855\n",
      "Caso 5 Procesado. Dice Inf Voxel: 0.520 | Dice Inf Cube: 0.565\n",
      "\n",
      "==================== VOXEL-WISE REPORT ====================\n",
      "\n",
      "--- Clase: Background ---\n",
      "Dice: 0.9961 ± 0.0008\n",
      "Sens: 0.9926 ± 0.0015\n",
      "Prec: 0.9997 ± 0.0003\n",
      "\n",
      "--- Clase: Infiltration ---\n",
      "Dice: 0.6966 ± 0.0900\n",
      "Sens: 0.7321 ± 0.1704\n",
      "Prec: 0.6921 ± 0.0922\n",
      "ROI AUC: 0.8726 ± 0.0811\n",
      "\n",
      "--- Clase: Vasogenic ---\n",
      "Dice: 0.6497 ± 0.1299\n",
      "Sens: 0.8645 ± 0.0561\n",
      "Prec: 0.5533 ± 0.1805\n",
      "ROI AUC: 0.8587 ± 0.0914\n",
      "\n",
      "Global ROI Accuracy: 0.7945\n",
      "Center Distance: 4.9726\n",
      "\n",
      "==================== CUBE-WISE (Size 8) REPORT ====================\n",
      "\n",
      "--- Clase: Background ---\n",
      "Dice: 0.9978 ± 0.0005\n",
      "Sens: 0.9967 ± 0.0008\n",
      "Prec: 0.9990 ± 0.0010\n",
      "\n",
      "--- Clase: Infiltration ---\n",
      "Dice: 0.7276 ± 0.0889\n",
      "Sens: 0.7524 ± 0.1655\n",
      "Prec: 0.7367 ± 0.1056\n",
      "ROI AUC: 0.8968 ± 0.0686\n",
      "\n",
      "--- Clase: Vasogenic ---\n",
      "Dice: 0.6801 ± 0.1233\n",
      "Sens: 0.8058 ± 0.0715\n",
      "Prec: 0.6314 ± 0.1971\n",
      "ROI AUC: 0.8715 ± 0.1109\n",
      "\n",
      "Global ROI Accuracy: 0.7650\n",
      "Center Distance: 0.7403\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from scipy import stats\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "# ==========================================\n",
    "# 1. FUNCIONES AUXILIARES\n",
    "# ==========================================\n",
    "\n",
    "def calculate_segmentation_metrics(pred, true, num_classes=3):\n",
    "    \"\"\"\n",
    "    Calcula métricas de segmentación (Dice, Sensibilidad, Precisión, F1)\n",
    "    sobre el VOLUMEN COMPLETO (incluyendo fondo).\n",
    "    \"\"\"\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        # Dice Score\n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        # Sensibilidad (Recall)\n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        # Precisión\n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "        \n",
    "        # F1 Score\n",
    "        f1 = f1_score(true_cls.flatten(), pred_cls.flatten(), zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "    return dice_scores, sensitivity_scores, precision_scores, f1_scores\n",
    "\n",
    "def calculate_discriminative_roi_metrics(y_true, y_pred, y_probs_map, num_classes=3):\n",
    "    \"\"\"\n",
    "    Calcula Accuracy y AUC/ROC restringido a la ROI de LESIÓN.\n",
    "    La ROI se define como la unión de las clases 1 y 2 del Ground Truth.\n",
    "    \"\"\"\n",
    "    # 1. Definir ROI: Unión de clases Infiltración (1) y Vasogénico (2)\n",
    "    roi_mask = (y_true == 1) | (y_true == 2)\n",
    "    \n",
    "    auc_list = [np.nan] * num_classes\n",
    "    fpr_list = [np.nan] * num_classes\n",
    "    tpr_list = [np.nan] * num_classes\n",
    "    accuracy_val = np.nan\n",
    "    \n",
    "    # Si hay lesión en el GT\n",
    "    if np.sum(roi_mask) > 0:\n",
    "        # Extraer datos dentro de la ROI\n",
    "        roi_true = y_true[roi_mask]\n",
    "        roi_pred = y_pred[roi_mask]\n",
    "        \n",
    "        # Calcular Accuracy discriminativa (Qué tan bien distingue 1 de 2)\n",
    "        accuracy_val = accuracy_score(roi_true, roi_pred)\n",
    "        \n",
    "        # Calcular AUC por clase (Solo para 1 y 2)\n",
    "        # Se indexa el mapa de probabilidades: [Clases, N_elementos_en_ROI]\n",
    "        roi_probs = y_probs_map[:, roi_mask] \n",
    "        \n",
    "        for cls in [1, 2]:\n",
    "            # Binarizar: Clase actual vs La otra clase de lesión\n",
    "            # (Ej: Infiltración=1 vs Vasogénico=0, ignorando fondo)\n",
    "            bin_true = (roi_true == cls).astype(np.uint8)\n",
    "            bin_score = roi_probs[cls]\n",
    "            \n",
    "            # Solo calculamos si hay al menos una instancia de cada clase o variación\n",
    "            if len(np.unique(bin_true)) > 1:\n",
    "                auc_list[cls] = roc_auc_score(bin_true, bin_score)\n",
    "                fpr, tpr, _ = roc_curve(bin_true, bin_score)\n",
    "                fpr_list[cls] = fpr\n",
    "                tpr_list[cls] = tpr\n",
    "                \n",
    "    return accuracy_val, auc_list, fpr_list, tpr_list\n",
    "\n",
    "def get_cube_data(volume, prob_maps, cube_size, num_classes=3):\n",
    "    \"\"\"\n",
    "    Transforma volúmenes de vóxeles a cubos (Region-wise).\n",
    "    - Labels: Moda del cubo.\n",
    "    - Probs: Promedio del cubo.\n",
    "    \"\"\"\n",
    "    dims = volume.shape\n",
    "    n_x, n_y, n_z = dims[0] // cube_size, dims[1] // cube_size, dims[2] // cube_size\n",
    "    \n",
    "    cube_labels = np.zeros((n_x, n_y, n_z), dtype=np.uint8)\n",
    "    cube_probs = np.zeros((num_classes, n_x, n_y, n_z))\n",
    "    \n",
    "    for i in range(n_x):\n",
    "        for j in range(n_y):\n",
    "            for k in range(n_z):\n",
    "                # Extraer sub-volumen (cubo)\n",
    "                sl_x = slice(i*cube_size, (i+1)*cube_size)\n",
    "                sl_y = slice(j*cube_size, (j+1)*cube_size)\n",
    "                sl_z = slice(k*cube_size, (k+1)*cube_size)\n",
    "                \n",
    "                vol_cube = volume[sl_x, sl_y, sl_z]\n",
    "                prob_cube = prob_maps[:, sl_x, sl_y, sl_z]\n",
    "                \n",
    "                # Etiqueta: Moda\n",
    "                mode_res = stats.mode(vol_cube.flatten(), keepdims=True)\n",
    "                cube_labels[i, j, k] = mode_res.mode[0]\n",
    "                \n",
    "                # Probabilidad: Media\n",
    "                for cls in range(num_classes):\n",
    "                    cube_probs[cls, i, j, k] = np.mean(prob_cube[cls])\n",
    "                    \n",
    "    return cube_labels, cube_probs\n",
    "\n",
    "def get_center_distance(pred_mask, true_mask, target_class=1):\n",
    "    \"\"\"Calcula distancia euclidiana entre centros de masa de la clase objetivo.\"\"\"\n",
    "    p_mask = (pred_mask == target_class)\n",
    "    t_mask = (true_mask == target_class)\n",
    "    \n",
    "    if np.sum(p_mask) == 0 or np.sum(t_mask) == 0:\n",
    "        return np.nan\n",
    "        \n",
    "    p_center = np.mean(np.where(p_mask), axis=1)\n",
    "    t_center = np.mean(np.where(t_mask), axis=1)\n",
    "    \n",
    "    return np.linalg.norm(p_center - t_center)\n",
    "\n",
    "# ==========================================\n",
    "# 2. INICIALIZACIÓN\n",
    "# ==========================================\n",
    "\n",
    "# Voxel-wise Storage\n",
    "metrics_voxel = {\n",
    "    'dice': {0:[], 1:[], 2:[]},\n",
    "    'sens': {0:[], 1:[], 2:[]},\n",
    "    'prec': {0:[], 1:[], 2:[]},\n",
    "    'f1':   {0:[], 1:[], 2:[]},\n",
    "    'auc':  {0:[], 1:[], 2:[]}, # ROI-based\n",
    "    'fpr':  {0:[], 1:[], 2:[]}, # ROI-based\n",
    "    'tpr':  {0:[], 1:[], 2:[]}, # ROI-based\n",
    "    'acc':  [],                 # ROI-based\n",
    "    'dist': []\n",
    "}\n",
    "\n",
    "# Cube-wise Storage\n",
    "metrics_cube = {\n",
    "    'dice': {0:[], 1:[], 2:[]},\n",
    "    'sens': {0:[], 1:[], 2:[]},\n",
    "    'prec': {0:[], 1:[], 2:[]},\n",
    "    'f1':   {0:[], 1:[], 2:[]},\n",
    "    'auc':  {0:[], 1:[], 2:[]}, # ROI-based\n",
    "    'fpr':  {0:[], 1:[], 2:[]}, # ROI-based\n",
    "    'tpr':  {0:[], 1:[], 2:[]}, # ROI-based\n",
    "    'acc':  [],                 # ROI-based\n",
    "    'dist': []\n",
    "}\n",
    "\n",
    "cube_size = 8  # Tamaño del cubo\n",
    "\n",
    "# ==========================================\n",
    "# 3. BUCLE DE PROCESAMIENTO\n",
    "# ==========================================\n",
    "print(f\"Iniciando evaluación completa (Voxel & Cube size {cube_size})...\")\n",
    "\n",
    "for idx, ((embeddings1, labels1), (embeddings2, labels2)) in enumerate(zip(loader_model1, loader_model2)):\n",
    "    \n",
    "    # --- A. Preparar Mapas ---\n",
    "    prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)\n",
    "    prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)\n",
    "    \n",
    "    # Combinar mapas: (Pipe1 y Pipe2)\n",
    "    # - Clase 0: del modelo 1\n",
    "    # - Clase 1: máximo entre ambos modelos\n",
    "    # - Clase 2: del modelo 2\n",
    "    combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "    combined_prob_maps[0] = prob_maps1[0]  # Clase 0 del modelo 1\n",
    "    combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Clase 1 máximo entre ambos\n",
    "    combined_prob_maps[2] = prob_maps2[2]  # Clase 2 del modelo 2\n",
    "    # Normalizar probabilidades para que sumen 1 en cada vóxel\n",
    "    combined_prob_maps = combined_prob_maps / combined_prob_maps.sum(dim=0, keepdim=True)\n",
    "\n",
    "    # # Solo Pipe1\n",
    "    # combined_prob_maps = prob_maps1\n",
    "\n",
    "    # # Solo Pipe2\n",
    "    # combined_prob_maps = prob_maps2\n",
    "    \n",
    "    # Numpy Conversions\n",
    "    prob_maps_np = combined_prob_maps.cpu().numpy() # [3, D, H, W]\n",
    "    prob_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0)) # [D, H, W, 3] para guardar\n",
    "    \n",
    "    segmentation_np = np.argmax(prob_maps_np, axis=0).astype(np.uint8)\n",
    "    labels_np = labels2.squeeze(0).cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    # ------------------------------------------------\n",
    "    # NIVEL 1: VOXEL-WISE\n",
    "    # ------------------------------------------------\n",
    "    \n",
    "    # 1.1 Métricas de Segmentación (Globales)\n",
    "    d, s, p, f = calculate_segmentation_metrics(segmentation_np, labels_np)\n",
    "    \n",
    "    # 1.2 Métricas Discriminativas (ROI de Lesión)\n",
    "    acc_roi, auc_roi, fpr_roi, tpr_roi = calculate_discriminative_roi_metrics(\n",
    "        labels_np, segmentation_np, prob_maps_np\n",
    "    )\n",
    "    \n",
    "    # 1.3 Distancia Espacial\n",
    "    dist_v = get_center_distance(segmentation_np, labels_np, target_class=1)\n",
    "    \n",
    "    # 1.4 Guardar Voxel Metrics\n",
    "    metrics_voxel['acc'].append(acc_roi)\n",
    "    metrics_voxel['dist'].append(dist_v)\n",
    "    for c in range(3):\n",
    "        metrics_voxel['dice'][c].append(d[c])\n",
    "        metrics_voxel['sens'][c].append(s[c])\n",
    "        metrics_voxel['prec'][c].append(p[c])\n",
    "        metrics_voxel['f1'][c].append(f[c])\n",
    "        metrics_voxel['auc'][c].append(auc_roi[c])\n",
    "        metrics_voxel['fpr'][c].append(fpr_roi[c])\n",
    "        metrics_voxel['tpr'][c].append(tpr_roi[c])\n",
    "\n",
    "    # 1.5 Plot ROC Voxel (Individual Case)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for c in [1, 2]:\n",
    "        if not np.isnan(auc_roi[c]):\n",
    "            plt.plot(fpr_roi[c], tpr_roi[c], label=f'Class {c} (AUC={auc_roi[c]:.2f})')\n",
    "    plt.plot([0,1],[0,1], 'k--')\n",
    "    plt.title(f'Voxel ROC (Lesion ROI) - Case {idx}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f\"roc_voxel_case_{idx}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ------------------------------------------------\n",
    "    # NIVEL 2: CUBE-WISE (REGION-BASED)\n",
    "    # ------------------------------------------------\n",
    "    \n",
    "    # 2.1 Transformar a Cubos\n",
    "    cube_labels, cube_probs = get_cube_data(labels_np, prob_maps_np, cube_size)\n",
    "    cube_preds = np.argmax(cube_probs, axis=0).astype(np.uint8)\n",
    "    \n",
    "    # 2.2 Métricas de Segmentación Cubos (Globales)\n",
    "    dc, sc, pc, fc = calculate_segmentation_metrics(cube_preds, cube_labels)\n",
    "    \n",
    "    # 2.3 Métricas Discriminativas Cubos (ROI de Lesión)\n",
    "    acc_roi_c, auc_roi_c, fpr_roi_c, tpr_roi_c = calculate_discriminative_roi_metrics(\n",
    "        cube_labels, cube_preds, cube_probs\n",
    "    )\n",
    "    \n",
    "    # 2.4 Distancia Espacial Cubos\n",
    "    dist_c = get_center_distance(cube_preds, cube_labels, target_class=1)\n",
    "    # Escalar distancia de cubos a mm reales (aprox) si se desea, o dejar en unidades de cubo\n",
    "    # Aquí lo dejamos en unidades de cubo para comparar con la lógica de región\n",
    "    \n",
    "    # 2.5 Guardar Cube Metrics\n",
    "    metrics_cube['acc'].append(acc_roi_c)\n",
    "    metrics_cube['dist'].append(dist_c)\n",
    "    for c in range(3):\n",
    "        metrics_cube['dice'][c].append(dc[c])\n",
    "        metrics_cube['sens'][c].append(sc[c])\n",
    "        metrics_cube['prec'][c].append(pc[c])\n",
    "        metrics_cube['f1'][c].append(fc[c])\n",
    "        metrics_cube['auc'][c].append(auc_roi_c[c])\n",
    "        metrics_cube['fpr'][c].append(fpr_roi_c[c])\n",
    "        metrics_cube['tpr'][c].append(tpr_roi_c[c])\n",
    "        \n",
    "    # 2.6 Plot ROC Cube (Individual Case)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    for c in [1, 2]:\n",
    "        if not np.isnan(auc_roi_c[c]):\n",
    "            plt.plot(fpr_roi_c[c], tpr_roi_c[c], linestyle='--', label=f'Class {c} (AUC={auc_roi_c[c]:.2f})')\n",
    "    plt.plot([0,1],[0,1], 'k--')\n",
    "    plt.title(f'Cube ROC (Lesion ROI) - Case {idx}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f\"roc_cube_case_{idx}.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # --- Guardar Archivos NIfTI (Opcional) ---\n",
    "    nib.save(nib.Nifti1Image(prob_nifti, affine), os.path.join(output_dir, f\"prob_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(segmentation_np, affine), os.path.join(output_dir, f\"seg_voxel_case_{idx}.nii.gz\"))\n",
    "    \n",
    "    # Guardar Cubos (Ajustar affine para visualización correcta)\n",
    "    affine_cube = affine.copy()\n",
    "    affine_cube[:3, :3] *= cube_size\n",
    "    nib.save(nib.Nifti1Image(cube_preds, affine_cube), os.path.join(output_dir, f\"seg_cube_case_{idx}.nii.gz\"))\n",
    "    \n",
    "    print(f\"Caso {idx} Procesado. Dice Inf Voxel: {d[1]:.3f} | Dice Inf Cube: {dc[1]:.3f}\")\n",
    "\n",
    "# ==========================================\n",
    "# 4. REPORTES Y GRÁFICOS FINALES\n",
    "# ==========================================\n",
    "\n",
    "def print_summary(metrics_dict, label):\n",
    "    print(f\"\\n{'='*20} {label} REPORT {'='*20}\")\n",
    "    cls_names = ['Background', 'Infiltration', 'Vasogenic']\n",
    "    \n",
    "    for c in range(3):\n",
    "        print(f\"\\n--- Clase: {cls_names[c]} ---\")\n",
    "        d_m = np.nanmean(metrics_dict['dice'][c])\n",
    "        s_m = np.nanmean(metrics_dict['sens'][c])\n",
    "        p_m = np.nanmean(metrics_dict['prec'][c])\n",
    "        \n",
    "        print(f\"Dice: {d_m:.4f} ± {np.nanstd(metrics_dict['dice'][c]):.4f}\")\n",
    "        print(f\"Sens: {s_m:.4f} ± {np.nanstd(metrics_dict['sens'][c]):.4f}\")\n",
    "        print(f\"Prec: {p_m:.4f} ± {np.nanstd(metrics_dict['prec'][c]):.4f}\")\n",
    "        \n",
    "        if c > 0: # Solo imprimir AUC para lesiones\n",
    "            auc_m = np.nanmean(metrics_dict['auc'][c])\n",
    "            print(f\"ROI AUC: {auc_m:.4f} ± {np.nanstd(metrics_dict['auc'][c]):.4f}\")\n",
    "            \n",
    "    print(f\"\\nGlobal ROI Accuracy: {np.nanmean(metrics_dict['acc']):.4f}\")\n",
    "    print(f\"Center Distance: {np.nanmean(metrics_dict['dist']):.4f}\")\n",
    "\n",
    "def plot_average_roc(metrics_dict, filename, title):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    colors = ['gray', 'green', 'red']\n",
    "    classes = ['Background', 'Infiltration', 'Vasogenic']\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    \n",
    "    # Solo graficamos clases 1 y 2\n",
    "    for c in [1, 2]:\n",
    "        tprs = []\n",
    "        aucs = []\n",
    "        for i in range(len(metrics_dict['fpr'][c])):\n",
    "            fpr_i = metrics_dict['fpr'][c][i]\n",
    "            tpr_i = metrics_dict['tpr'][c][i]\n",
    "            \n",
    "            # Verificar si hay datos válidos\n",
    "            if isinstance(fpr_i, np.ndarray) and len(fpr_i) > 1:\n",
    "                tpr_interp = np.interp(mean_fpr, fpr_i, tpr_i)\n",
    "                tpr_interp[0] = 0.0\n",
    "                tprs.append(tpr_interp)\n",
    "                aucs.append(metrics_dict['auc'][c][i])\n",
    "        \n",
    "        if len(tprs) > 0:\n",
    "            mean_tpr = np.mean(tprs, axis=0)\n",
    "            mean_tpr[-1] = 1.0\n",
    "            mean_auc = np.nanmean(aucs)\n",
    "            std_auc = np.nanstd(aucs)\n",
    "            plt.plot(mean_fpr, mean_tpr, color=colors[c], \n",
    "                     label=f'{classes[c]} (AUC={mean_auc:.3f} $\\pm$ {std_auc:.3f})')\n",
    "    \n",
    "    plt.plot([0, 1], [0, 1], 'k--')\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([0, 1.05])\n",
    "    plt.xlabel('False Positive Rate (ROI)')\n",
    "    plt.ylabel('True Positive Rate (ROI)')\n",
    "    plt.title(title)\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.savefig(os.path.join(output_dir, filename))\n",
    "    plt.show()\n",
    "\n",
    "# Imprimir Resúmenes\n",
    "print_summary(metrics_voxel, \"VOXEL-WISE\")\n",
    "print_summary(metrics_cube, f\"CUBE-WISE (Size {cube_size})\")\n",
    "\n",
    "# Graficar Curvas Promedio\n",
    "plot_average_roc(metrics_voxel, \"average_roc_voxel.png\", \"Average Voxel-wise ROC (Lesion ROI)\")\n",
    "plot_average_roc(metrics_cube, \"average_roc_cube.png\", f\"Average Cube-wise ROC (Lesion ROI)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solo Pipe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guardada curva ROC en trained_models/mapas_combinados_pipe1/roc_curve_case_0.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_cube_case_0.png\n",
      "Caso 0 - Voxel-wise:\n",
      "  Dice: [0.9950628731270902, 0.8567807350715344, 0.6943817406462506], Sensitivity: [0.9901896122507773, 0.9955817377520293, 0.9448805460347747], Precision: [0.9999843391738426, 0.7519466072857288, 0.5488699444748991], AUC-ROC: [0.9996016598736299, 0.9996073054817175, 0.9977012889563411], Accuracy: 0.9897, F1 Score: [0.9950628731273324, 0.8567807351077312, 0.6943817406571356]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [61.69351131 64.77879125 59.4962551 ]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [60.96269023 65.06273932 59.91644575]\n",
      "  Distancia entre centros (Voxel-wise): 0.8895426595733933\n",
      "Caso 0 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9980148882136457, 0.888888869135803, 0.8275861973840667], Sensitivity: [0.9960376421505603, 0.9999999500000024, 0.9473683961218844], Precision: [0.9999999997513676, 0.7999999680000013, 0.7346938625572681], AUC-ROC: [0.9997758364502741, 1.0, 0.9994649944229722], Accuracy: 0.9956, F1 Score: [0.998014888337469, 0.888888888888889, 0.8275862068965517]\n",
      "  Centro de masa Infiltrado (Pred): [7.2  7.6  7.08]\n",
      "  Centro de masa Infiltrado (True): [7.15 7.75 7.1 ]\n",
      "Distancia entre centros: 0.1593737745050925\n",
      "Guardada curva ROC en trained_models/mapas_combinados_pipe1/roc_curve_case_1.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_cube_case_1.png\n",
      "Caso 1 - Voxel-wise:\n",
      "  Dice: [0.9939283960047789, 0.7665171897782872, 0.6752860053194996], Sensitivity: [0.9884873649843621, 0.7831398899231612, 0.9528969482178646], Precision: [0.9994296577941871, 0.7505854799838135, 0.5229368931933063], AUC-ROC: [0.9982287513682517, 0.9988253702983251, 0.997554273990403], Accuracy: 0.9874, F1 Score: [0.993928396005021, 0.7665171898355755, 0.6752860053283185]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [68.8764637  64.65207845 64.51917447]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [69.10690287 67.2533598  62.43433109]\n",
      "  Distancia entre centros (Voxel-wise): 3.3416072168624407\n",
      "Caso 1 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.995529060979194, 0.9090908677685968, 0.6949152483481759], Sensitivity: [0.9918337042831394, 0.8333332638888947, 0.9534883499188757], Precision: [0.999252056594552, 0.99999990000001, 0.5466666593777779], AUC-ROC: [0.9988076758678095, 0.9998163565132223, 0.9980950085781992], Accuracy: 0.9910, F1 Score: [0.9955290611028316, 0.9090909090909091, 0.6949152542372881]\n",
      "  Centro de masa Infiltrado (Pred): [8.2 7.9 7.5]\n",
      "  Centro de masa Infiltrado (True): [8.33333333 8.08333333 7.5       ]\n",
      "Distancia entre centros: 0.22669117514559167\n",
      "Guardada curva ROC en trained_models/mapas_combinados_pipe1/roc_curve_case_2.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_cube_case_2.png\n",
      "Caso 2 - Voxel-wise:\n",
      "  Dice: [0.9953578761991803, 0.8626278519492324, 0.5419162396732838], Sensitivity: [0.9909917913786713, 0.9648011260243573, 0.9396062728612273], Precision: [0.9997626032247204, 0.7800227658565673, 0.3807592198093243], AUC-ROC: [0.9982360935542833, 0.9999142312846772, 0.9973470506190995], Accuracy: 0.9907, F1 Score: [0.9953578761994203, 0.8626278520849724, 0.5419162396863199]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [59.83323847 74.44166192 72.1587934 ]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [60.03836677 76.14220345 76.81802182]\n",
      "  Distancia entre centros (Voxel-wise): 4.96410400978349\n",
      "Caso 2 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9974160205491059, 0.9090908264462886, 0.6296296179698219], Sensitivity: [0.9950896142904273, 0.99999980000004, 0.9444443919753115], Precision: [0.9997533297977915, 0.8333331944444675, 0.4722222091049387], AUC-ROC: [0.9991139956660511, 0.9999511121975067, 0.9986376764209035], Accuracy: 0.9949, F1 Score: [0.9974160206718345, 0.9090909090909091, 0.6296296296296297]\n",
      "  Centro de masa Infiltrado (Pred): [7.16666667 9.16666667 9.16666667]\n",
      "  Centro de masa Infiltrado (True): [7.2 9.2 9. ]\n",
      "Distancia entre centros: 0.17320508075688712\n",
      "Guardada curva ROC en trained_models/mapas_combinados_pipe1/roc_curve_case_3.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_cube_case_3.png\n",
      "Caso 3 - Voxel-wise:\n",
      "  Dice: [0.9948299210707119, 0.7689967540741129, 0.8745912692428474], Sensitivity: [0.9910145003169863, 0.9686259750592369, 0.8738826803265974], Precision: [0.998674834224856, 0.6375920545765468, 0.8753010082044007], AUC-ROC: [0.9992539133215343, 0.9984083406945206, 0.9966907533025336], Accuracy: 0.9844, F1 Score: [0.9948299210709673, 0.7689967540845568, 0.8745912692467015]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [79.43533095 50.4771074  60.26000495]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [81.00283974 53.77699466 57.12419598]\n",
      "  Distancia entre centros (Voxel-wise): 4.814523621672709\n",
      "Caso 3 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9969875571713179, 0.8059701432390288, 0.8936170191640259], Sensitivity: [0.9952928867690134, 0.9999999814814818, 0.8669724730872822], Precision: [0.9986880081346923, 0.6749999915625001, 0.9219512150148721], AUC-ROC: [0.9994587204651736, 0.9986667766232338, 0.9940040501346102], Accuracy: 0.9885, F1 Score: [0.9969875573018991, 0.8059701492537313, 0.8936170212765958]\n",
      "  Centro de masa Infiltrado (Pred): [9.6625 5.825  7.075 ]\n",
      "  Centro de masa Infiltrado (True): [9.7037037  6.2962963  6.68518519]\n",
      "Distancia entre centros: 0.613003698154112\n",
      "Guardada curva ROC en trained_models/mapas_combinados_pipe1/roc_curve_case_4.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_cube_case_4.png\n",
      "Caso 4 - Voxel-wise:\n",
      "  Dice: [0.9965386352182716, 0.936873359418717, 0.8472390858107898], Sensitivity: [0.9931275109453062, 0.9761040125094775, 0.9733606557136737], Precision: [0.9999732728304468, 0.9006743060066738, 0.7500523181563067], AUC-ROC: [0.999885814820197, 0.9998527276753851, 0.9990407703705287], Accuracy: 0.9926, F1 Score: [0.9965386352185173, 0.9368733594388743, 0.8472390858198932]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [68.75005171 62.37740454 63.08058578]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [68.19058507 61.84066353 62.92284241]\n",
      "  Distancia entre centros (Voxel-wise): 0.7911869605904943\n",
      "Caso 4 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9982367756929172, 0.9438202141143797, 0.9079754545522979], Sensitivity: [0.9964797583614585, 0.9767441633315311, 0.9736841977146816], Precision: [0.999999999747666, 0.9130434584120988, 0.8505747028669575], AUC-ROC: [0.9997696840868607, 0.99991966903643, 0.9995712228332023], Accuracy: 0.9958, F1 Score: [0.9982367758186398, 0.9438202247191011, 0.9079754601226995]\n",
      "  Centro de masa Infiltrado (Pred): [8.10869565 7.23913043 7.32608696]\n",
      "  Centro de masa Infiltrado (True): [8.04651163 7.23255814 7.39534884]\n",
      "Distancia entre centros: 0.09331267896289476\n",
      "Guardada curva ROC en trained_models/mapas_combinados_pipe1/roc_curve_case_5.png\n",
      "Guardada curva ROC cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_cube_case_5.png\n",
      "Caso 5 - Voxel-wise:\n",
      "  Dice: [0.9966926431516928, 0.6696216975041858, 0.9411133982345197], Sensitivity: [0.9936928527920701, 0.9984295248006243, 0.9708850560452992], Precision: [0.9997106000702545, 0.5037306041265281, 0.9131132802348689], AUC-ROC: [0.9997443045040533, 0.9995011297963159, 0.999477466897396], Accuracy: 0.9929, F1 Score: [0.9966926431519406, 0.6696216975335733, 0.9411133982407487]\n",
      "  Centro de masa Infiltrado (Pred, Voxel-wise): [59.05203037 70.42647739 60.98157808]\n",
      "  Centro de masa Infiltrado (True, Voxel-wise): [61.30140034 66.66928413 56.1087554 ]\n",
      "  Distancia entre centros (Voxel-wise): 6.551379039175347\n",
      "Caso 5 - Cube-wise (tamaño 8):\n",
      "  Dice: [0.9980952379684958, 0.7499999765625008, 0.9473684177285319], Sensitivity: [0.9964503040069852, 0.9999999166666736, 0.9642857073979593], Precision: [0.9997456115492889, 0.5999999700000015, 0.9310344763376933], AUC-ROC: [0.999820680313868, 0.9999795951681358, 0.9997715946843854], Accuracy: 0.9954, F1 Score: [0.998095238095238, 0.7499999999999999, 0.9473684210526316]\n",
      "  Centro de masa Infiltrado (Pred): [7.05 8.25 6.75]\n",
      "  Centro de masa Infiltrado (True): [7.16666667 8.         6.75      ]\n",
      "Distancia entre centros: 0.275882422620781\n",
      "\n",
      "Resultados Voxel-wise:\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9954 ± 0.0010\n",
      "  Sensibilidad: 0.9913 ± 0.0017\n",
      "  Precisión: 0.9996 ± 0.0004\n",
      "  AUC-ROC: 0.9992 ± 0.0007\n",
      "  F1 Score: 0.9954 ± 0.0010\n",
      "\n",
      "Clase 1 (Infiltrado):\n",
      "  Dice: 0.8102 ± 0.0860\n",
      "  Sensibilidad: 0.9478 ± 0.0747\n",
      "  Precisión: 0.7208 ± 0.1237\n",
      "  AUC-ROC: 0.9994 ± 0.0006\n",
      "  F1 Score: 0.8102 ± 0.0860\n",
      "\n",
      "Clase 2 (Vasogénico):\n",
      "  Dice: 0.7624 ± 0.1370\n",
      "  Sensibilidad: 0.9426 ± 0.0331\n",
      "  Precisión: 0.6652 ± 0.1947\n",
      "  AUC-ROC: 0.9980 ± 0.0010\n",
      "  F1 Score: 0.7624 ± 0.1370\n",
      "\n",
      "Accuracy Global: 0.9896 ± 0.0030\n",
      "\n",
      "Distancia entre centros Global (Voxel-wise): 3.5587 ± 2.1346\n",
      "Guardada curva ROC promedio en trained_models/mapas_combinados_pipe1/roc_curve_average.png\n",
      "\n",
      "Resultados Cube-wise:\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9974 ± 0.0009\n",
      "  Sensibilidad: 0.9952 ± 0.0016\n",
      "  Precisión: 0.9996 ± 0.0005\n",
      "  AUC-ROC: 0.9995 ± 0.0004\n",
      "  F1 Score: 0.9974 ± 0.0009\n",
      "\n",
      "Clase 1 (Infiltrado):\n",
      "  Dice: 0.8678 ± 0.0675\n",
      "  Sensibilidad: 0.9683 ± 0.0610\n",
      "  Precisión: 0.8036 ± 0.1351\n",
      "  AUC-ROC: 0.9997 ± 0.0005\n",
      "  F1 Score: 0.8678 ± 0.0675\n",
      "\n",
      "Clase 2 (Vasogénico):\n",
      "  Dice: 0.8168 ± 0.1164\n",
      "  Sensibilidad: 0.9417 ± 0.0349\n",
      "  Precisión: 0.7429 ± 0.1784\n",
      "  AUC-ROC: 0.9983 ± 0.0020\n",
      "  F1 Score: 0.8168 ± 0.1164\n",
      "\n",
      "Generando curva ROC promedio para métricas cube-wise...\n",
      "Guardada curva ROC promedio cube-wise en trained_models/mapas_combinados_pipe1/roc_curve_average_cube.png\n",
      "\n",
      "Accuracy Global Cube-wise: 0.9935 ± 0.0028\n",
      "\n",
      "Distancia entre centros Global: 0.2569 ± 0.1690\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from scipy import stats\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "\n",
    "# Función para calcular métricas (ya definida previamente)\n",
    "def calculate_metrics(pred, true, prob_maps=None, num_classes=3):\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    accuracy = accuracy_score(true.flatten(), pred.flatten())\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "        \n",
    "        f1 = f1_score(true_cls.flatten(), pred_cls.flatten(), zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        if prob_maps is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(true_cls.flatten(), prob_maps[cls].flatten())\n",
    "                auc_scores.append(auc)\n",
    "            except ValueError:\n",
    "                auc_scores.append(np.nan)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)\n",
    "    \n",
    "    return dice_scores, sensitivity_scores, precision_scores, auc_scores, accuracy, f1_scores\n",
    "\n",
    "# Función para dividir en cubos y obtener clases predominantes\n",
    "def get_cube_labels(volume, cube_size, num_classes=3):\n",
    "    dims = volume.shape\n",
    "    assert dims[0] % cube_size == 0, \"El tamaño del cubo debe dividir exactamente el tamaño del volumen\"\n",
    "    num_cubes = dims[0] // cube_size\n",
    "    \n",
    "    cube_labels = np.zeros((num_cubes, num_cubes, num_cubes), dtype=np.uint8)\n",
    "    cube_probs = np.zeros((num_classes, num_cubes, num_cubes, num_cubes))\n",
    "    \n",
    "    for i in range(num_cubes):\n",
    "        for j in range(num_cubes):\n",
    "            for k in range(num_cubes):\n",
    "                cube = volume[i*cube_size:(i+1)*cube_size, \n",
    "                             j*cube_size:(j+1)*cube_size, \n",
    "                             k*cube_size:(k+1)*cube_size]\n",
    "                # Clase predominante (modo)\n",
    "                mode_value = stats.mode(cube.flatten(), keepdims=True)[0][0]\n",
    "                cube_labels[i, j, k] = mode_value\n",
    "                # Proporción de cada clase como \"probabilidad\" suavizada\n",
    "                for cls in range(num_classes):\n",
    "                    cube_probs[cls, i, j, k] = np.mean(cube == cls)\n",
    "    \n",
    "    return cube_labels, cube_probs\n",
    "\n",
    "# Listas para métricas voxel-wise\n",
    "all_dice = {0: [], 1: [], 2: []}\n",
    "all_sensitivity = {0: [], 1: [], 2: []}\n",
    "all_precision = {0: [], 1: [], 2: []}\n",
    "all_auc = {0: [], 1: [], 2: []}\n",
    "all_accuracy = []\n",
    "all_f1 = {0: [], 1: [], 2: []}\n",
    "# Listas para almacenar FPR y TPR de todos los casos\n",
    "all_fpr = {0: [], 1: [], 2: []}\n",
    "all_tpr = {0: [], 1: [], 2: []}\n",
    "all_center_distance_voxel = []\n",
    "\n",
    "# Listas para métricas cube-wise\n",
    "all_dice_cube = {0: [], 1: [], 2: []}\n",
    "all_sensitivity_cube = {0: [], 1: [], 2: []}\n",
    "all_precision_cube = {0: [], 1: [], 2: []}\n",
    "all_auc_cube = {0: [], 1: [], 2: []}\n",
    "all_accuracy_cube = []\n",
    "all_f1_cube = {0: [], 1: [], 2: []}\n",
    "all_center_distance=[]\n",
    "# Listas para almacenar FPR y TPR de todos los casos\n",
    "all_fpr_cube = {0: [], 1: [], 2: []}\n",
    "all_tpr_cube = {0: [], 1: [], 2: []}\n",
    "\n",
    "# Tamaño del cubo (ajusta según necesites)\n",
    "cube_size = 8  # 128 / 8 = 16 cubos por dimensión\n",
    "\n",
    "# Procesar y combinar\n",
    "for idx, ((embeddings1, labels1), (embeddings2, labels2)) in enumerate(zip(loader_model1, loader_model2)):\n",
    "    # Generar mapas de probabilidad para ambos modelos\n",
    "    prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "    prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "    \n",
    "    # Combinar mapas\n",
    "    # combined_prob_maps = torch.zeros_like(prob_maps1)\n",
    "    # combined_prob_maps[0] = prob_maps1[0]\n",
    "    # combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])\n",
    "    # combined_prob_maps[2] = prob_maps2[2]\n",
    "\n",
    "    combined_prob_maps = prob_maps2 #prob_maps1\n",
    "\n",
    "    # Convertir a numpy\n",
    "    prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "    prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "    \n",
    "    # Generar segmentación semántica\n",
    "    segmentation = np.argmax(prob_maps_np, axis=0)\n",
    "    # Colocar nuevo umbral para infiltracion\n",
    "    # class_1_mask = prob_maps_np[1] > 0.4\n",
    "    # segmentation[class_1_mask] = 1\n",
    "    segmentation_np = segmentation.astype(np.uint8)\n",
    "    \n",
    "    # Etiquetas\n",
    "    labels = labels1.squeeze(0)\n",
    "    labels_np = labels.cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    # Calcular métricas voxel-wise\n",
    "    dice, sensitivity, precision, auc, accuracy, f1 = calculate_metrics(segmentation_np, labels_np, prob_maps=prob_maps_np)\n",
    "    \n",
    "    # Almacenar métricas voxel-wise\n",
    "    for cls in range(3):\n",
    "        all_dice[cls].append(dice[cls])\n",
    "        all_sensitivity[cls].append(sensitivity[cls])\n",
    "        all_precision[cls].append(precision[cls])\n",
    "        all_auc[cls].append(auc[cls])\n",
    "        all_f1[cls].append(f1[cls])\n",
    "    all_accuracy.append(accuracy)\n",
    "\n",
    "    # ***** NUEVO: Análisis espacial voxel-wise para la clase Infiltrado (Clase 1) *****\n",
    "    infiltrado_pred_voxel = (segmentation_np == 1).astype(np.uint8)\n",
    "    infiltrado_true_voxel = (labels_np == 1).astype(np.uint8)\n",
    "    if np.sum(infiltrado_pred_voxel) > 0:\n",
    "        pred_center_voxel = np.mean(np.where(infiltrado_pred_voxel), axis=1)\n",
    "    else:\n",
    "        pred_center_voxel = np.array([np.nan, np.nan, np.nan])\n",
    "    if np.sum(infiltrado_true_voxel) > 0:\n",
    "        true_center_voxel = np.mean(np.where(infiltrado_true_voxel), axis=1)\n",
    "    else:\n",
    "        true_center_voxel = np.array([np.nan, np.nan, np.nan])\n",
    "    distance_voxel = np.linalg.norm(pred_center_voxel - true_center_voxel) if not np.any(np.isnan(pred_center_voxel)) and not np.any(np.isnan(true_center_voxel)) else np.nan\n",
    "    all_center_distance_voxel.append(distance_voxel)\n",
    "\n",
    "    # Graficar curvas ROC\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    \n",
    "    for cls in range(3):\n",
    "        # Etiquetas binarias para la clase actual\n",
    "        true_cls = (labels_np == cls).astype(np.uint8).flatten()\n",
    "        prob_cls = prob_maps_np[cls].flatten()\n",
    "        \n",
    "        # Calcular puntos de la curva ROC\n",
    "        fpr, tpr, _ = roc_curve(true_cls, prob_cls)\n",
    "        auc_value = auc[cls]  # Usar el AUC calculado previamente\n",
    "        all_fpr[cls].append(fpr)\n",
    "        all_tpr[cls].append(tpr)\n",
    "        \n",
    "        # Graficar\n",
    "        plt.plot(fpr, tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value:.4f})')\n",
    "    \n",
    "    # Configurar el gráfico\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Línea diagonal (clasificador aleatorio)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC - Caso {idx}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Guardar el gráfico\n",
    "    roc_output_path = os.path.join(output_dir, f\"roc_curve_case_{idx}.png\")\n",
    "    plt.savefig(roc_output_path)\n",
    "    plt.close()\n",
    "    print(f\"Guardada curva ROC en {roc_output_path}\")\n",
    "    \n",
    "    ################################\n",
    "    # Evaluación basada en cubos\n",
    "    ####################################\n",
    "    pred_cube_labels, pred_cube_probs = get_cube_labels(segmentation_np, cube_size)\n",
    "    true_cube_labels, true_cube_probs = get_cube_labels(labels_np, cube_size)\n",
    "    \n",
    "    # Calcular métricas cube-wise\n",
    "    dice_cube, sensitivity_cube, precision_cube, auc_cube, accuracy_cube, f1_cube = calculate_metrics(\n",
    "        pred_cube_labels, true_cube_labels, prob_maps=pred_cube_probs\n",
    "    )\n",
    "    \n",
    "    # Almacenar métricas cube-wise\n",
    "    for cls in range(3):\n",
    "        all_dice_cube[cls].append(dice_cube[cls])\n",
    "        all_sensitivity_cube[cls].append(sensitivity_cube[cls])\n",
    "        all_precision_cube[cls].append(precision_cube[cls])\n",
    "        all_auc_cube[cls].append(auc_cube[cls])\n",
    "        all_f1_cube[cls].append(f1_cube[cls])\n",
    "    all_accuracy_cube.append(accuracy_cube)\n",
    "\n",
    "    # ***** NUEVO: Calcular y graficar curvas ROC para métricas cube-wise *****\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "    colors = ['blue', 'green', 'red']\n",
    "    \n",
    "    for cls in range(3):\n",
    "        # Etiquetas binarias para la clase actual (cube-wise)\n",
    "        true_cls_cube = (true_cube_labels == cls).astype(np.uint8).flatten()\n",
    "        prob_cls_cube = pred_cube_probs[cls].flatten()\n",
    "        \n",
    "        # Calcular puntos de la curva ROC\n",
    "        fpr_cube, tpr_cube, _ = roc_curve(true_cls_cube, prob_cls_cube)\n",
    "        auc_value_cube = auc_cube[cls]  # Usar el AUC calculado previamente\n",
    "        all_fpr_cube[cls].append(fpr_cube)\n",
    "        all_tpr_cube[cls].append(tpr_cube)\n",
    "        \n",
    "        # Graficar\n",
    "        plt.plot(fpr_cube, tpr_cube, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value_cube:.4f})')\n",
    "    \n",
    "    # Configurar el gráfico\n",
    "    plt.plot([0, 1], [0, 1], 'k--')  # Línea diagonal (clasificador aleatorio)\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "    plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "    plt.title(f'Curva ROC Cube-wise - Caso {idx}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    \n",
    "    # Guardar el gráfico\n",
    "    roc_cube_output_path = os.path.join(output_dir, f\"roc_curve_cube_case_{idx}.png\")\n",
    "    plt.savefig(roc_cube_output_path)\n",
    "    plt.close()\n",
    "    print(f\"Guardada curva ROC cube-wise en {roc_cube_output_path}\")\n",
    "    \n",
    "    # Mapa de coincidencias/discrepancias\n",
    "    match_map = (pred_cube_labels == true_cube_labels).astype(np.uint8)\n",
    "    mismatch_map = (pred_cube_labels != true_cube_labels).astype(np.uint8)\n",
    "    \n",
    "    # Guardar mapas de cubos y coincidencias\n",
    "    affine = np.eye(4) * cube_size  # Ajustar el affine para reflejar el tamaño del cubo\n",
    "    nib.save(nib.Nifti1Image(pred_cube_labels, affine), os.path.join(output_dir, f\"pred_cube_labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(true_cube_labels, affine), os.path.join(output_dir, f\"true_cube_labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(match_map, affine), os.path.join(output_dir, f\"match_map_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(mismatch_map, affine), os.path.join(output_dir, f\"mismatch_map_case_{idx}.nii.gz\"))\n",
    "    \n",
    "    # Análisis espacial (centro de masa de la clase Infiltrado)\n",
    "    infiltrado_pred = (pred_cube_labels == 1).astype(np.uint8)\n",
    "    infiltrado_true = (true_cube_labels == 1).astype(np.uint8)\n",
    "    if np.sum(infiltrado_pred) > 0:\n",
    "        pred_center = np.mean(np.where(infiltrado_pred), axis=1)\n",
    "    else:\n",
    "        pred_center = np.array([np.nan, np.nan, np.nan])\n",
    "    if np.sum(infiltrado_true) > 0:\n",
    "        true_center = np.mean(np.where(infiltrado_true), axis=1)\n",
    "    else:\n",
    "        true_center = np.array([np.nan, np.nan, np.nan])\n",
    "    distance = np.linalg.norm(pred_center - true_center) if not np.any(np.isnan(pred_center)) and not np.any(np.isnan(true_center)) else np.nan\n",
    "    all_center_distance.append(distance)\n",
    "\n",
    "    print(f\"Caso {idx} - Voxel-wise:\")\n",
    "    print(f\"  Dice: {dice}, Sensitivity: {sensitivity}, Precision: {precision}, AUC-ROC: {auc}, \"\n",
    "          f\"Accuracy: {accuracy:.4f}, F1 Score: {f1}\")\n",
    "    print(f\"  Centro de masa Infiltrado (Pred, Voxel-wise): {pred_center_voxel}\")\n",
    "    print(f\"  Centro de masa Infiltrado (True, Voxel-wise): {true_center_voxel}\")\n",
    "    print(f\"  Distancia entre centros (Voxel-wise): {distance_voxel}\")\n",
    "\n",
    "    print(f\"Caso {idx} - Cube-wise (tamaño {cube_size}):\")\n",
    "    print(f\"  Dice: {dice_cube}, Sensitivity: {sensitivity_cube}, Precision: {precision_cube}, \"\n",
    "          f\"AUC-ROC: {auc_cube}, Accuracy: {accuracy_cube:.4f}, F1 Score: {f1_cube}\")\n",
    "    print(f\"  Centro de masa Infiltrado (Pred): {pred_center}\")\n",
    "    print(f\"  Centro de masa Infiltrado (True): {true_center}\")\n",
    "    print(f\"Distancia entre centros: {distance}\")\n",
    "    \n",
    "    # Guardar mapas de probabilidad y segmentaciones voxel-wise\n",
    "    nib.save(nib.Nifti1Image(prob_maps_np_nifti, np.eye(4)), os.path.join(output_dir, f\"probability_maps_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(labels_np, np.eye(4)), os.path.join(output_dir, f\"labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(segmentation_np, np.eye(4)), os.path.join(output_dir, f\"segmentation_case_{idx}.nii.gz\"))\n",
    "\n",
    "# Calcular promedios y desviaciones estándar (voxel-wise)\n",
    "class_names = [\"Fondo\", \"Infiltrado\", \"Vasogénico\", ]\n",
    "print(\"\\nResultados Voxel-wise:\")\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice[cls])\n",
    "    dice_std = np.nanstd(all_dice[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity[cls])\n",
    "    prec_mean = np.nanmean(all_precision[cls])\n",
    "    prec_std = np.nanstd(all_precision[cls])\n",
    "    auc_mean = np.nanmean(all_auc[cls])\n",
    "    auc_std = np.nanstd(all_auc[cls])\n",
    "    f1_mean = np.nanmean(all_f1[cls])\n",
    "    f1_std = np.nanstd(all_f1[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "accuracy_mean = np.nanmean(all_accuracy)\n",
    "accuracy_std = np.nanstd(all_accuracy)\n",
    "print(f\"\\nAccuracy Global: {accuracy_mean:.4f} ± {accuracy_std:.4f}\")\n",
    "# ***** NUEVO: Calcular promedio y desviación estándar para distancia voxel-wise *****\n",
    "dist_mean_voxel = np.nanmean(all_center_distance_voxel)\n",
    "dist_std_voxel = np.nanstd(all_center_distance_voxel)\n",
    "print(f\"\\nDistancia entre centros Global (Voxel-wise): {dist_mean_voxel:.4f} ± {dist_std_voxel:.4f}\")\n",
    "\n",
    "# Curva ROC Promedio\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cls in range(3):\n",
    "    # Interpolar FPR y TPR a una base común\n",
    "    mean_fpr = np.linspace(0, 1, 100)\n",
    "    tprs = []\n",
    "    for fpr, tpr in zip(all_fpr[cls], all_tpr[cls]):\n",
    "        tpr_interp = np.interp(mean_fpr, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0  # Asegurar que comienza en 0\n",
    "        tprs.append(tpr_interp)\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[-1] = 1.0  # Asegurar que termina en 1\n",
    "    mean_auc = np.nanmean(all_auc[cls])\n",
    "    \n",
    "    plt.plot(mean_fpr, mean_tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC Promedio')\n",
    "plt.legend(loc=\"lower right\")\n",
    "roc_avg_path = os.path.join(output_dir, \"roc_curve_average.png\")\n",
    "plt.savefig(roc_avg_path)\n",
    "plt.close()\n",
    "print(f\"Guardada curva ROC promedio en {roc_avg_path}\")\n",
    "\n",
    "# Calcular promedios y desviaciones estándar (cube-wise)\n",
    "print(\"\\nResultados Cube-wise:\")\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice_cube[cls])\n",
    "    dice_std = np.nanstd(all_dice_cube[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity_cube[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity_cube[cls])\n",
    "    prec_mean = np.nanmean(all_precision_cube[cls])\n",
    "    prec_std = np.nanstd(all_precision_cube[cls])\n",
    "    auc_mean = np.nanmean(all_auc_cube[cls])\n",
    "    auc_std = np.nanstd(all_auc_cube[cls])\n",
    "    f1_mean = np.nanmean(all_f1_cube[cls])\n",
    "    f1_std = np.nanstd(all_f1_cube[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "# ***** NUEVO: Curva ROC promedio para métricas cube-wise *****\n",
    "print(\"\\nGenerando curva ROC promedio para métricas cube-wise...\")\n",
    "plt.figure(figsize=(8, 6))\n",
    "for cls in range(3):\n",
    "    # Interpolar FPR y TPR a una base común\n",
    "    mean_fpr_cube = np.linspace(0, 1, 100)\n",
    "    tprs_cube = []\n",
    "    for fpr, tpr in zip(all_fpr_cube[cls], all_tpr_cube[cls]):\n",
    "        tpr_interp = np.interp(mean_fpr_cube, fpr, tpr)\n",
    "        tpr_interp[0] = 0.0  # Asegurar que comienza en 0\n",
    "        tprs_cube.append(tpr_interp)\n",
    "    mean_tpr_cube = np.mean(tprs_cube, axis=0)\n",
    "    mean_tpr_cube[-1] = 1.0  # Asegurar que termina en 1\n",
    "    mean_auc_cube = np.nanmean(all_auc_cube[cls])\n",
    "    \n",
    "    plt.plot(mean_fpr_cube, mean_tpr_cube, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc_cube:.4f})')\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('Tasa de Falsos Positivos (FPR)')\n",
    "plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC Promedio Cube-wise')\n",
    "plt.legend(loc=\"lower right\")\n",
    "roc_avg_cube_path = os.path.join(output_dir, \"roc_curve_average_cube.png\")\n",
    "plt.savefig(roc_avg_cube_path)\n",
    "plt.close()\n",
    "print(f\"Guardada curva ROC promedio cube-wise en {roc_avg_cube_path}\")\n",
    "\n",
    "accuracy_mean_cube = np.nanmean(all_accuracy_cube)\n",
    "accuracy_std_cube = np.nanstd(all_accuracy_cube)\n",
    "print(f\"\\nAccuracy Global Cube-wise: {accuracy_mean_cube:.4f} ± {accuracy_std_cube:.4f}\")\n",
    "\n",
    "dist_mean = np.nanmean(all_center_distance)\n",
    "dist_std = np.nanstd(all_center_distance)\n",
    "print(f\"\\nDistancia entre centros Global: {dist_mean:.4f} ± {dist_std:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metricas basadas en regiones centrada en tumor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 0 - Voxel-wise:\n",
      "  Dice: [0.9970035703989371, 0.520193908666654, 0.6986080252122276], Sensitivity: [0.9941729438903477, 0.4651015729859273, 0.8572294069472858], Precision: [0.9998503617499696, 0.5900915958885441, 0.5895229395928157], AUC-ROC: [0.9997442857524647, 0.9908721550503753, 0.9926824584823732], Accuracy: 0.9818, F1 Score: [0.9970035703991849, 0.5201939086743189, 0.698608025218861]\n",
      "Caso 0 - Cube-wise (Grilla 5x5x5):\n",
      "  Dice: [0.9290322520707597, 0.5499999862500004, 0.6545454426446283], Sensitivity: [0.8780487697798931, 0.49999997727272827, 0.8571428163265326], Precision: [0.9863013563520362, 0.6111110771604957, 0.5294117491349486], AUC-ROC: [0.994895065229722, 0.823477493380406, 0.8811813186813187], Accuracy: 0.8080, F1 Score: [0.9290322580645162, 0.55, 0.6545454545454545]\n",
      "  Centro de masa Infiltrado (Pred): [1.72222222 2.77777778 1.83333333]\n",
      "  Centro de masa Infiltrado (True): [2.40909091 2.         1.54545455]\n",
      "  Distancia entre centros: 1.08\n",
      "Caso 1 - Voxel-wise:\n",
      "  Dice: [0.9961940335339866, 0.7573532532253574, 0.7093981720864045], Sensitivity: [0.9927684989178468, 0.8805763915435673, 0.8734924409345383], Precision: [0.9996432895239844, 0.6643830515552622, 0.5972068985367515], AUC-ROC: [0.9982288768831301, 0.9987986678355506, 0.9947559103374306], Accuracy: 0.9909, F1 Score: [0.9961940335342289, 0.7573532532575018, 0.7093981720986376]\n",
      "Caso 1 - Cube-wise (Grilla 5x5x5):\n",
      "  Dice: [0.9763033129085151, 0.8571427959183717, 0.7999999680000013], Sensitivity: [0.9537036948731139, 0.9999998333333611, 0.9090908264462886], Precision: [0.9999999902912623, 0.7499999062500118, 0.7142856632653098], AUC-ROC: [0.9929193899782134, 1.0, 0.9824561403508772], Accuracy: 0.9520, F1 Score: [0.976303317535545, 0.8571428571428571, 0.8]\n",
      "  Centro de masa Infiltrado (Pred): [2.75  3.    1.875]\n",
      "  Centro de masa Infiltrado (True): [3.         2.83333333 2.        ]\n",
      "  Distancia entre centros: 0.33\n",
      "Caso 2 - Voxel-wise:\n",
      "  Dice: [0.9954207128587987, 0.7141549611409692, 0.8115478311414778], Sensitivity: [0.9918475049000461, 0.9249993951340334, 0.7700496806169659], Precision: [0.9990197594230913, 0.5815877941468294, 0.8577734344881823], AUC-ROC: [0.9992538722066036, 0.9960538811731321, 0.9950507396812097], Accuracy: 0.9798, F1 Score: [0.9954207128590542, 0.714154961147639, 0.8115478311456931]\n",
      "Caso 2 - Cube-wise (Grilla 5x5x5):\n",
      "  Dice: [0.9902912573286833, 0.7058823114186875, 0.8148147846364894], Sensitivity: [0.9807692213387575, 0.857142734693895, 0.7857142295918408], Precision: [0.9999999901960785, 0.599999940000006, 0.8461537810650938], AUC-ROC: [0.9995421245421247, 0.9842615012106537, 0.9478764478764479], Accuracy: 0.9520, F1 Score: [0.9902912621359222, 0.7058823529411764, 0.8148148148148148]\n",
      "  Centro de masa Infiltrado (Pred): [2.6 1.6 2. ]\n",
      "  Centro de masa Infiltrado (True): [2.57142857 1.85714286 1.57142857]\n",
      "  Distancia entre centros: 0.50\n",
      "Caso 3 - Voxel-wise:\n",
      "  Dice: [0.9946954256219234, 0.6495593571237637, 0.3871328671230227], Sensitivity: [0.9896221671657137, 0.5427375107503988, 0.9631785396731395], Precision: [0.9998209678212706, 0.8087349395850397, 0.2422506524014305], AUC-ROC: [0.9982360359904578, 0.9980275841103045, 0.9913611417658387], Accuracy: 0.9880, F1 Score: [0.9946954256221634, 0.649559357179886, 0.38713286713286715]\n",
      "Caso 3 - Cube-wise (Grilla 5x5x5):\n",
      "  Dice: [0.9680365252601072, 0.599999940000006, 0.47619045351474026], Sensitivity: [0.938053089043778, 0.4285713673469475, 0.99999980000004], Precision: [0.9999999905660378, 0.9999996666667778, 0.3124999804687512], AUC-ROC: [0.9918879056047198, 0.891041162227603, 0.9866666666666667], Accuracy: 0.9120, F1 Score: [0.9680365296803652, 0.6, 0.47619047619047616]\n",
      "  Centro de masa Infiltrado (Pred): [2.33333333 3.         3.33333333]\n",
      "  Centro de masa Infiltrado (True): [1.85714286 2.71428571 3.        ]\n",
      "  Distancia entre centros: 0.65\n",
      "Caso 4 - Voxel-wise:\n",
      "  Dice: [0.9965279044150087, 0.7510474573280651, 0.6372424828180269], Sensitivity: [0.9930836863287986, 0.8135382059318024, 0.8549704811941695], Precision: [0.9999960961570087, 0.6974721529577604, 0.5078999574710252], AUC-ROC: [0.9996016155347753, 0.9980592234123471, 0.9952250280934484], Accuracy: 0.9905, F1 Score: [0.996527904415251, 0.7510474573486321, 0.6372424828321889]\n",
      "Caso 4 - Cube-wise (Grilla 5x5x5):\n",
      "  Dice: [0.9644670001803706, 0.8148147846364894, 0.7692307396449716], Sensitivity: [0.9313725398885045, 0.9166665902777842, 0.9090908264462886], Precision: [0.9999999894736844, 0.7333332844444478, 0.6666666222222252], AUC-ROC: [0.9978687127024722, 0.9874631268436578, 0.9880382775119617], Accuracy: 0.9280, F1 Score: [0.9644670050761421, 0.8148148148148148, 0.7692307692307692]\n",
      "  Centro de masa Infiltrado (Pred): [1.73333333 2.06666667 1.53333333]\n",
      "  Centro de masa Infiltrado (True): [2.         2.08333333 1.5       ]\n",
      "  Distancia entre centros: 0.27\n",
      "Caso 5 - Voxel-wise:\n",
      "  Dice: [0.9969356400590003, 0.7873596864002423, 0.6544481470151394], Sensitivity: [0.9939036829084408, 0.7655546205819543, 0.8678748381525744], Precision: [0.9999861521116298, 0.8104433032694811, 0.5252735377407733], AUC-ROC: [0.9998858128010235, 0.997705949643649, 0.9948220587097338], Accuracy: 0.9882, F1 Score: [0.996935640059246, 0.7873596864102629, 0.6544481470261537]\n",
      "Caso 5 - Cube-wise (Grilla 5x5x5):\n",
      "  Dice: [0.9585798759847345, 0.8461538298816571, 0.689655148632581], Sensitivity: [0.9204545349948349, 0.8148147846364894, 0.99999990000001], Precision: [0.9999999876543212, 0.8799999648000014, 0.5263157617728547], AUC-ROC: [0.9993857493857494, 0.9914965986394558, 0.9895652173913043], Accuracy: 0.9040, F1 Score: [0.9585798816568047, 0.8461538461538461, 0.6896551724137931]\n",
      "  Centro de masa Infiltrado (Pred): [2.56 1.92 2.2 ]\n",
      "  Centro de masa Infiltrado (True): [2.37037037 2.07407407 1.96296296]\n",
      "  Distancia entre centros: 0.34\n",
      "\n",
      "Resultados Voxel-wise:\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9961 ± 0.0008\n",
      "  Sensibilidad: 0.9926 ± 0.0015\n",
      "  Precisión: 0.9997 ± 0.0003\n",
      "  AUC-ROC: 0.9992 ± 0.0007\n",
      "  F1 Score: 0.9961 ± 0.0008\n",
      "\n",
      "Clase 1 (Vasogénico):\n",
      "  Dice: 0.6966 ± 0.0899\n",
      "  Sensibilidad: 0.7321 ± 0.1704\n",
      "  Precisión: 0.6921 ± 0.0922\n",
      "  AUC-ROC: 0.9966 ± 0.0027\n",
      "  F1 Score: 0.6966 ± 0.0899\n",
      "\n",
      "Clase 2 (Infiltrado):\n",
      "  Dice: 0.6497 ± 0.1299\n",
      "  Sensibilidad: 0.8645 ± 0.0561\n",
      "  Precisión: 0.5533 ± 0.1805\n",
      "  AUC-ROC: 0.9940 ± 0.0014\n",
      "  F1 Score: 0.6497 ± 0.1299\n",
      "\n",
      "Accuracy Global: 0.9865 ± 0.0042\n",
      "\n",
      "Resultados Cube-wise (Grilla 5x5x5):\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9645 ± 0.0188\n",
      "  Sensibilidad: 0.9337 ± 0.0314\n",
      "  Precisión: 0.9977 ± 0.0051\n",
      "  AUC-ROC: 0.9961 ± 0.0030\n",
      "  F1 Score: 0.9645 ± 0.0188\n",
      "\n",
      "Clase 1 (Vasogénico):\n",
      "  Dice: 0.7290 ± 0.1202\n",
      "  Sensibilidad: 0.7529 ± 0.2128\n",
      "  Precisión: 0.7624 ± 0.1417\n",
      "  AUC-ROC: 0.9463 ± 0.0661\n",
      "  F1 Score: 0.7290 ± 0.1202\n",
      "\n",
      "Clase 2 (Infiltrado):\n",
      "  Dice: 0.7007 ± 0.1156\n",
      "  Sensibilidad: 0.9102 ± 0.0758\n",
      "  Precisión: 0.5992 ± 0.1689\n",
      "  AUC-ROC: 0.9626 ± 0.0391\n",
      "  F1 Score: 0.7007 ± 0.1156\n",
      "\n",
      "Accuracy Global Cube-wise: 0.9093 ± 0.0488\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from scipy import stats\n",
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "import torch\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "# Función para calcular métricas (para todas las clases o un subconjunto)\n",
    "def calculate_metrics(pred, true, prob_maps=None, num_classes=3, class_offset=0):\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    accuracy = accuracy_score(true.flatten(), pred.flatten())\n",
    "    \n",
    "    for cls in range(class_offset, class_offset + num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "        \n",
    "        f1 = f1_score(true_cls.flatten(), pred_cls.flatten(), zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        if prob_maps is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(true_cls.flatten(), prob_maps[cls - class_offset].flatten())\n",
    "                auc_scores.append(auc)\n",
    "            except ValueError:\n",
    "                auc_scores.append(np.nan)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)\n",
    "    \n",
    "    return dice_scores, sensitivity_scores, precision_scores, auc_scores, accuracy, f1_scores\n",
    "\n",
    "# Función para obtener el cuadro delimitador y centro del tumor\n",
    "def get_tumor_bbox_and_center(labels_np):\n",
    "    tumor_mask = (labels_np > 0).astype(np.uint8)  # Clases 1 (Infiltrado) y 2 (Vasogénico)\n",
    "    if np.sum(tumor_mask) == 0:\n",
    "        return None, None\n",
    "    indices = np.where(tumor_mask)\n",
    "    bbox = {\n",
    "        'x_min': np.min(indices[0]), 'x_max': np.max(indices[0]),\n",
    "        'y_min': np.min(indices[1]), 'y_max': np.max(indices[1]),\n",
    "        'z_min': np.min(indices[2]), 'z_max': np.max(indices[2])\n",
    "    }\n",
    "    center = np.mean(indices, axis=1)\n",
    "    return bbox, center\n",
    "\n",
    "# Función para dividir la región del tumor en cubos\n",
    "def get_tumor_cube_labels(segmentation_np, labels_np, bbox, center, grid_size=5):\n",
    "    # Dimensiones del cuadro delimitador\n",
    "    dims = [bbox['x_max'] - bbox['x_min'] + 1, \n",
    "            bbox['y_max'] - bbox['y_min'] + 1, \n",
    "            bbox['z_max'] - bbox['z_min'] + 1]\n",
    "    \n",
    "    # Tamaño del cubo (dinámico)\n",
    "    cube_size = [max(1, d // grid_size) for d in dims]\n",
    "    \n",
    "    # Ajustar el cuadro delimitador para centrarlo y cubrir la grilla\n",
    "    half_grid = np.array([grid_size * cs / 2 for cs in cube_size])\n",
    "    bbox_min = np.floor(center - half_grid).astype(int)\n",
    "    bbox_max = np.ceil(center + half_grid).astype(int)\n",
    "    \n",
    "    # Asegurar que no exceda los límites del volumen\n",
    "    bbox_min = np.maximum(bbox_min, 0)\n",
    "    bbox_max = np.minimum(bbox_max, np.array(segmentation_np.shape))\n",
    "    \n",
    "    # Extraer la región del tumor\n",
    "    tumor_pred = segmentation_np[bbox_min[0]:bbox_max[0], bbox_min[1]:bbox_max[1], bbox_min[2]:bbox_max[2]]\n",
    "    tumor_true = labels_np[bbox_min[0]:bbox_max[0], bbox_min[1]:bbox_max[1], bbox_min[2]:bbox_max[2]]\n",
    "    \n",
    "    # Ajustar para que coincida con la grilla\n",
    "    cube_labels_pred = np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8)\n",
    "    cube_labels_true = np.zeros((grid_size, grid_size, grid_size), dtype=np.uint8)\n",
    "    cube_probs_pred = np.zeros((3, grid_size, grid_size, grid_size))  # Clases 0, 1, 2\n",
    "    \n",
    "    for i in range(grid_size):\n",
    "        for j in range(grid_size):\n",
    "            for k in range(grid_size):\n",
    "                x_start = i * cube_size[0]\n",
    "                y_start = j * cube_size[1]\n",
    "                z_start = k * cube_size[2]\n",
    "                x_end = min(x_start + cube_size[0], tumor_pred.shape[0])\n",
    "                y_end = min(y_start + cube_size[1], tumor_pred.shape[1])\n",
    "                z_end = min(z_start + cube_size[2], tumor_pred.shape[2])\n",
    "                \n",
    "                if x_end <= x_start or y_end <= y_start or z_end <= z_start:\n",
    "                    continue\n",
    "                \n",
    "                cube_pred = tumor_pred[x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "                cube_true = tumor_true[x_start:x_end, y_start:y_end, z_start:z_end]\n",
    "                \n",
    "                # Clase predominante (incluye clase 0)\n",
    "                cube_labels_pred[i, j, k] = stats.mode(cube_pred.flatten(), keepdims=True)[0][0]\n",
    "                cube_labels_true[i, j, k] = stats.mode(cube_true.flatten(), keepdims=True)[0][0]\n",
    "                \n",
    "                # Proporciones para clases 0, 1, 2\n",
    "                cube_probs_pred[0, i, j, k] = np.mean(cube_pred == 0)\n",
    "                cube_probs_pred[1, i, j, k] = np.mean(cube_pred == 1)\n",
    "                cube_probs_pred[2, i, j, k] = np.mean(cube_pred == 2)\n",
    "    \n",
    "    return cube_labels_pred, cube_labels_true, cube_probs_pred, bbox_min, bbox_max\n",
    "\n",
    "# Listas para métricas voxel-wise (todas las clases)\n",
    "all_dice = {0: [], 1: [], 2: []}\n",
    "all_sensitivity = {0: [], 1: [], 2: []}\n",
    "all_precision = {0: [], 1: [], 2: []}\n",
    "all_auc = {0: [], 1: [], 2: []}\n",
    "all_accuracy = []\n",
    "all_f1 = {0: [], 1: [], 2: []}\n",
    "\n",
    "# Listas para métricas cube-wise (todas las clases)\n",
    "all_dice_cube = {0: [], 1: [], 2: []}\n",
    "all_sensitivity_cube = {0: [], 1: [], 2: []}\n",
    "all_precision_cube = {0: [], 1: [], 2: []}\n",
    "all_auc_cube = {0: [], 1: [], 2: []}\n",
    "all_accuracy_cube = []\n",
    "all_f1_cube = {0: [], 1: [], 2: []}\n",
    "\n",
    "# Configuración de la grilla (5x5x5 o 3x3x3)\n",
    "grid_size = 5  # Cambia a 3 para una grilla 3x3x3\n",
    "\n",
    "# Procesar y combinar\n",
    "for idx, ((embeddings1, labels1), (embeddings2, labels2)) in enumerate(zip(loader_model1, loader_model2)):\n",
    "    # Generar mapas de probabilidad\n",
    "    prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)\n",
    "    prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)\n",
    "    \n",
    "    # Combinar mapas\n",
    "    combined_prob_maps = torch.zeros_like(prob_maps1)\n",
    "    combined_prob_maps[0] = prob_maps1[0]  # Fondo\n",
    "    combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Infiltrado\n",
    "    combined_prob_maps[2] = prob_maps2[2]  # Vasogénico\n",
    "    \n",
    "    # Convertir a numpy\n",
    "    prob_maps_np = combined_prob_maps.cpu().numpy()\n",
    "    prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))\n",
    "    \n",
    "    # Generar segmentación\n",
    "    segmentation = np.argmax(prob_maps_np, axis=0)\n",
    "    # class_1_mask = prob_maps_np[1] > 0.4  # Umbral para Infiltrado\n",
    "    # segmentation[class_1_mask] = 1\n",
    "    segmentation_np = segmentation.astype(np.uint8)\n",
    "    \n",
    "    # Etiquetas\n",
    "    labels = labels2.squeeze(0)\n",
    "    labels_np = labels.cpu().numpy().astype(np.uint8)\n",
    "    \n",
    "    # Calcular métricas voxel-wise\n",
    "    dice, sensitivity, precision, auc, accuracy, f1 = calculate_metrics(\n",
    "        segmentation_np, labels_np, prob_maps=prob_maps_np, num_classes=3, class_offset=0\n",
    "    )\n",
    "    \n",
    "    # Almacenar métricas voxel-wise\n",
    "    for cls in range(3):\n",
    "        all_dice[cls].append(dice[cls])\n",
    "        all_sensitivity[cls].append(sensitivity[cls])\n",
    "        all_precision[cls].append(precision[cls])\n",
    "        all_auc[cls].append(auc[cls])\n",
    "        all_f1[cls].append(f1[cls])\n",
    "    all_accuracy.append(accuracy)\n",
    "    \n",
    "    # Obtener cuadro delimitador y centro del tumor\n",
    "    bbox, center = get_tumor_bbox_and_center(labels_np)\n",
    "    if bbox is None:\n",
    "        print(f\"Caso {idx}: No se detectó tumor en el ground truth. Saltando evaluación cube-wise.\")\n",
    "        continue\n",
    "    \n",
    "    # Evaluación basada en cubos\n",
    "    cube_labels_pred, cube_labels_true, cube_probs_pred, bbox_min, bbox_max = get_tumor_cube_labels(\n",
    "        segmentation_np, labels_np, bbox, center, grid_size=grid_size\n",
    "    )\n",
    "    \n",
    "    # Calcular métricas cube-wise (clases 0, 1, 2)\n",
    "    dice_cube, sensitivity_cube, precision_cube, auc_cube, accuracy_cube, f1_cube = calculate_metrics(\n",
    "        cube_labels_pred, cube_labels_true, prob_maps=cube_probs_pred, num_classes=3, class_offset=0\n",
    "    )\n",
    "    \n",
    "    # Almacenar métricas cube-wise\n",
    "    for cls in range(3):\n",
    "        all_dice_cube[cls].append(dice_cube[cls])\n",
    "        all_sensitivity_cube[cls].append(sensitivity_cube[cls])\n",
    "        all_precision_cube[cls].append(precision_cube[cls])\n",
    "        all_auc_cube[cls].append(auc_cube[cls])\n",
    "        all_f1_cube[cls].append(f1_cube[cls])\n",
    "    all_accuracy_cube.append(accuracy_cube)\n",
    "    \n",
    "    # Mapa de coincidencias/discrepancias\n",
    "    match_map = (cube_labels_pred == cube_labels_true).astype(np.uint8)\n",
    "    mismatch_map = (cube_labels_pred != cube_labels_true).astype(np.uint8)\n",
    "    \n",
    "    # Guardar mapas de cubos\n",
    "    affine = np.eye(4)\n",
    "    affine[:3, 3] = bbox_min  # Ajustar origen al cuadro delimitador\n",
    "    nib.save(nib.Nifti1Image(cube_labels_pred, affine), \n",
    "             os.path.join(output_dir, f\"pred_cube_labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(cube_labels_true, affine), \n",
    "             os.path.join(output_dir, f\"true_cube_labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(match_map, affine), \n",
    "             os.path.join(output_dir, f\"match_map_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(mismatch_map, affine), \n",
    "             os.path.join(output_dir, f\"mismatch_map_case_{idx}.nii.gz\"))\n",
    "    \n",
    "    # Análisis espacial (centro de masa de Infiltrado)\n",
    "    infiltrado_pred = (cube_labels_pred == 1).astype(np.uint8)  # Clase 1: Infiltrado\n",
    "    infiltrado_true = (cube_labels_true == 1).astype(np.uint8)\n",
    "    pred_center = np.mean(np.where(infiltrado_pred), axis=1) if np.sum(infiltrado_pred) > 0 else np.array([np.nan] * 3)\n",
    "    true_center = np.mean(np.where(infiltrado_true), axis=1) if np.sum(infiltrado_true) > 0 else np.array([np.nan] * 3)\n",
    "    distance = np.linalg.norm(pred_center - true_center) if not np.any(np.isnan(pred_center)) and not np.any(np.isnan(true_center)) else np.nan\n",
    "    \n",
    "    # Visualización 3D\n",
    "    fig = plt.figure(figsize=(10, 8))\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    infiltrado_pred_pos = np.where(infiltrado_pred)\n",
    "    infiltrado_true_pos = np.where(infiltrado_true)\n",
    "    ax.scatter(infiltrado_pred_pos[0], infiltrado_pred_pos[1], infiltrado_pred_pos[2], \n",
    "               c='red', label='Infiltrado Predicho', alpha=0.5)\n",
    "    ax.scatter(infiltrado_true_pos[0], infiltrado_true_pos[1], infiltrado_true_pos[2], \n",
    "               c='blue', label='Infiltrado Verdadero', alpha=0.5)\n",
    "    ax.set_xlabel('X')\n",
    "    ax.set_ylabel('Y')\n",
    "    ax.set_zlabel('Z')\n",
    "    ax.set_title(f'Infiltrado - Caso {idx} (Grilla {grid_size}x{grid_size}x{grid_size})')\n",
    "    ax.legend()\n",
    "    plt.savefig(os.path.join(output_dir, f\"infiltrado_scatter_case_{idx}.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    # Imprimir resultados\n",
    "    print(f\"Caso {idx} - Voxel-wise:\")\n",
    "    print(f\"  Dice: {dice}, Sensitivity: {sensitivity}, Precision: {precision}, AUC-ROC: {auc}, \"\n",
    "          f\"Accuracy: {accuracy:.4f}, F1 Score: {f1}\")\n",
    "    print(f\"Caso {idx} - Cube-wise (Grilla {grid_size}x{grid_size}x{grid_size}):\")\n",
    "    print(f\"  Dice: {dice_cube}, Sensitivity: {sensitivity_cube}, Precision: {precision_cube}, \"\n",
    "          f\"AUC-ROC: {auc_cube}, Accuracy: {accuracy_cube:.4f}, F1 Score: {f1_cube}\")\n",
    "    print(f\"  Centro de masa Infiltrado (Pred): {pred_center}\")\n",
    "    print(f\"  Centro de masa Infiltrado (True): {true_center}\")\n",
    "    print(f\"  Distancia entre centros: {distance:.2f}\")\n",
    "    \n",
    "    # Guardar mapas voxel-wise\n",
    "    nib.save(nib.Nifti1Image(prob_maps_np_nifti, np.eye(4)), \n",
    "             os.path.join(output_dir, f\"probability_maps_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(labels_np, np.eye(4)), \n",
    "             os.path.join(output_dir, f\"labels_case_{idx}.nii.gz\"))\n",
    "    nib.save(nib.Nifti1Image(segmentation_np, np.eye(4)), \n",
    "             os.path.join(output_dir, f\"segmentation_case_{idx}.nii.gz\"))\n",
    "\n",
    "# Calcular promedios y desviaciones estándar (voxel-wise)\n",
    "class_names = [\"Fondo\", \"Infiltrado\", \"Vasogénico\"]\n",
    "print(\"\\nResultados Voxel-wise:\")\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice[cls])\n",
    "    dice_std = np.nanstd(all_dice[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity[cls])\n",
    "    prec_mean = np.nanmean(all_precision[cls])\n",
    "    prec_std = np.nanstd(all_precision[cls])\n",
    "    auc_mean = np.nanmean(all_auc[cls])\n",
    "    auc_std = np.nanstd(all_auc[cls])\n",
    "    f1_mean = np.nanmean(all_f1[cls])\n",
    "    f1_std = np.nanstd(all_f1[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "accuracy_mean = np.nanmean(all_accuracy)\n",
    "accuracy_std = np.nanstd(all_accuracy)\n",
    "print(f\"\\nAccuracy Global: {accuracy_mean:.4f} ± {accuracy_std:.4f}\")\n",
    "\n",
    "# Calcular promedios y desviaciones estándar (cube-wise, clases 0, 1, 2)\n",
    "print(f\"\\nResultados Cube-wise (Grilla {grid_size}x{grid_size}x{grid_size}):\")\n",
    "for cls in range(3):\n",
    "    dice_mean = np.nanmean(all_dice_cube[cls])\n",
    "    dice_std = np.nanstd(all_dice_cube[cls])\n",
    "    sens_mean = np.nanmean(all_sensitivity_cube[cls])\n",
    "    sens_std = np.nanstd(all_sensitivity_cube[cls])\n",
    "    prec_mean = np.nanmean(all_precision_cube[cls])\n",
    "    prec_std = np.nanstd(all_precision_cube[cls])\n",
    "    auc_mean = np.nanmean(all_auc_cube[cls])\n",
    "    auc_std = np.nanstd(all_auc_cube[cls])\n",
    "    f1_mean = np.nanmean(all_f1_cube[cls])\n",
    "    f1_std = np.nanstd(all_f1_cube[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")\n",
    "    print(f\"  AUC-ROC: {auc_mean:.4f} ± {auc_std:.4f}\")\n",
    "    print(f\"  F1 Score: {f1_mean:.4f} ± {f1_std:.4f}\")\n",
    "\n",
    "accuracy_mean_cube = np.nanmean(all_accuracy_cube)\n",
    "accuracy_std_cube = np.nanstd(all_accuracy_cube)\n",
    "print(f\"\\nAccuracy Global Cube-wise: {accuracy_mean_cube:.4f} ± {accuracy_std_cube:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardando resultados e imagenes MRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images and 6 labels.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigo/anaconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caso 0: Vasogénico channel sum (6): 16856, Infiltrado channel sum (2): 16769\n",
      "Caso 0: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardadas etiquetas en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/labels_case_0.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/combined_results_test6_10mri_test/probability_maps/probability_maps_case_0.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/segmentation_case_0.nii.gz\n",
      "Caso 1: Vasogénico channel sum (6): 10132, Infiltrado channel sum (2): 23548\n",
      "Caso 1: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardadas etiquetas en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/labels_case_1.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/combined_results_test6_10mri_test/probability_maps/probability_maps_case_1.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/segmentation_case_1.nii.gz\n",
      "Caso 2: Vasogénico channel sum (6): 6926, Infiltrado channel sum (2): 7903\n",
      "Caso 2: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardadas etiquetas en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/labels_case_2.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/combined_results_test6_10mri_test/probability_maps/probability_maps_case_2.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/segmentation_case_2.nii.gz\n",
      "Caso 3: Vasogénico channel sum (6): 41333, Infiltrado channel sum (2): 101448\n",
      "Caso 3: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardadas etiquetas en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/labels_case_3.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/combined_results_test6_10mri_test/probability_maps/probability_maps_case_3.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/segmentation_case_3.nii.gz\n",
      "Caso 4: Vasogénico channel sum (6): 40406, Infiltrado channel sum (2): 22403\n",
      "Caso 4: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardadas etiquetas en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/labels_case_4.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/combined_results_test6_10mri_test/probability_maps/probability_maps_case_4.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/segmentation_case_4.nii.gz\n",
      "Caso 5: Vasogénico channel sum (6): 37953, Infiltrado channel sum (2): 42915\n",
      "Caso 5: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardadas etiquetas en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/labels_case_5.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/combined_results_test6_10mri_test/probability_maps/probability_maps_case_5.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/combined_results_test6_10mri_test/nifti_volumes/segmentation_case_5.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from monai import transforms\n",
    "import nibabel as nib\n",
    "from src.custom_transforms import (ConvertToMultiChannelBasedOnAnotatedInfiltration, \n",
    "                                   ConvertToMultiChannelBasedOnBratsClassesdI)\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Modelo de proyección (MLP más profundo)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim1=256, hidden_dim2=128, output_dim=128, dropout_p=0.3):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Clasificador supervisado (MLP)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=256, hidden_dim2=128, num_classes=3, dropout_p=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device, batch_size=8192):\n",
    "    projection_head.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        probs_flat = []\n",
    "        \n",
    "        for i in range(0, embeddings_flat.shape[0], batch_size):\n",
    "            batch = embeddings_flat[i:i+batch_size].to(device)\n",
    "            z = projection_head(batch)  # [batch_size, 128]\n",
    "            z = F.normalize(z, dim=1)\n",
    "            logits = classifier(z)  # [batch_size, 3]\n",
    "            probs = F.softmax(logits, dim=1)  # [batch_size, 3]\n",
    "            probs_flat.append(probs.cpu())\n",
    "        \n",
    "        probs_flat = torch.cat(probs_flat, dim=0)  # [2097152, 3]\n",
    "        probs = probs_flat.reshape(128, 128, 128, 3)  # [128, 128, 128, 3]\n",
    "        probs = probs.permute(3, 0, 1, 2)  # [3, 128, 128, 128]\n",
    "    \n",
    "    return probs  # Tensor [3, 128, 128, 128]\n",
    "\n",
    "# Transformaciones de MONAI\n",
    "roi = (128, 128, 128)\n",
    "source_k = \"label\"\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # transforms.ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        # ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            source_key=source_k,\n",
    "            k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[roi[0], roi[1], roi[2]],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dataset y DataLoader para imágenes MRI\n",
    "dataset_path = './Dataset/Dataset_30_6'\n",
    "train_set = CustomDataset(dataset_path, section=\"test_6\", transform=train_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "# DataLoader para embeddings (asumiendo que son los mismos que train_loader)\n",
    "loader_model1 = train_loader  # Reemplaza con tu loader real si es diferente\n",
    "loader_model2 = train_loader  # Reemplaza con tu loader real si es diferente\n",
    "\n",
    "# Directorios\n",
    "output_dir = \"Dataset/MRIs/combined_results_test6_10mri_test\"\n",
    "nifti_output_dir = os.path.join(output_dir, \"nifti_volumes\")\n",
    "probs_output_dir = os.path.join(output_dir, \"probability_maps\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(nifti_output_dir, exist_ok=True)\n",
    "os.makedirs(probs_output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "# Cargar modelos contrastivos preentrenados\n",
    "projection_head1 = ProjectionHead(input_dim=48).to(device)\n",
    "# projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe1_v01_m1.pth\", map_location=device))\n",
    "projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_gffqpzjv.pth\", map_location=device))\n",
    "# projection_head1.eval()\n",
    "\n",
    "projection_head2 = ProjectionHead(input_dim=48).to(device)\n",
    "# projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_8exzvcui.pth\", map_location=device))\n",
    "# projection_head2.eval()\n",
    "\n",
    "# Cargar clasificadores preentrenados\n",
    "classifier1 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe1_v01_m1.pth\", map_location=device))\n",
    "classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_gffqpzjv.pth\", map_location=device))\n",
    "# classifier1.eval()\n",
    "\n",
    "classifier2 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_8exzvcui.pth\", map_location=device))\n",
    "# classifier2.eval()\n",
    "\n",
    "# Hooks para embeddings\n",
    "decoder_features_model1 = None\n",
    "decoder_features_model2 = None\n",
    "\n",
    "def decoder_hook_fn_model1(module, input, output):\n",
    "    global decoder_features_model1\n",
    "    decoder_features_model1 = output\n",
    "\n",
    "def decoder_hook_fn_model2(module, input, output):\n",
    "    global decoder_features_model2\n",
    "    decoder_features_model2 = output\n",
    "\n",
    "hook_handle_decoder1 = model1.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model1)\n",
    "hook_handle_decoder2 = model2.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model2)\n",
    "\n",
    "# Procesar y guardar\n",
    "# Procesar y combinar\n",
    "with torch.no_grad():\n",
    "    for idx, (batch_data, (embeddings1, labels1), (embeddings2, labels2)) in enumerate(zip(train_loader, loader_model1, loader_model2)):\n",
    "        # Obtener imágenes y metadatos\n",
    "        image, label = batch_data[\"image\"], batch_data[\"label\"]  # [1, 11, 128, 128, 128], [1, 2, 128, 128, 128]\n",
    "        image_meta = batch_data[\"image\"].meta\n",
    "        affine = image_meta.get(\"affine\", np.eye(4)).numpy()\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.squeeze(0)  # [2, 128, 128, 128]\n",
    "        \n",
    "        # Debug: Verificar canales one-hot\n",
    "        print(f\"Caso {idx}: Vasogénico channel sum (6): {label[0].sum().item()}, Infiltrado channel sum (2): {label[1].sum().item()}\")\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas (0, 6, 2)\n",
    "        label_class = torch.zeros(label.shape[1:], dtype=torch.long)  # [128, 128, 128]\n",
    "        label_class[label[0] == 1] = 6  # Vasogénico\n",
    "        label_class[label[1] == 1] = 2  # Infiltrado\n",
    "        labels_np = label_class.cpu().numpy().astype(np.int16)  # [128, 128, 128]\n",
    "        \n",
    "        # Mapear etiquetas a 0, 1, 2 para métricas\n",
    "        labels_metrics = np.zeros_like(labels_np, dtype=np.int16)\n",
    "        labels_metrics[labels_np == 6] = 1  # Vasogénico -> 1\n",
    "        labels_metrics[labels_np == 2] = 2  # Infiltrado -> 2\n",
    "        # Fondo (0) ya está correcto\n",
    "        \n",
    "        # Verificar etiquetas\n",
    "        unique_labels = np.unique(labels_np)\n",
    "        print(f\"Caso {idx}: Etiquetas únicas (0, 2, 6): {unique_labels}\")\n",
    "        if not np.all(np.isin(unique_labels, [0, 2, 6])):\n",
    "            print(f\"Advertencia: Etiquetas inválidas en caso {idx}: {unique_labels}\")\n",
    "        if 6 not in unique_labels:\n",
    "            print(f\"Advertencia: Clase vasogénico (6) no presente en caso {idx}\")\n",
    "        \n",
    "        # Obtener embeddings\n",
    "        _ = model1(image)\n",
    "        _ = model2(image)\n",
    "        embeddings1 = decoder_features_model1\n",
    "        embeddings2 = decoder_features_model2\n",
    "        \n",
    "        # Generar mapas de probabilidad\n",
    "        prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "        prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "        \n",
    "        # Combinar mapas\n",
    "        combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "        combined_prob_maps[0] = prob_maps1[0]  # Fondo (0)\n",
    "        combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Vasogénico (1)\n",
    "        combined_prob_maps[2] = prob_maps2[2]  # Infiltrado (2)\n",
    "        \n",
    "        # Normalizar probabilidades\n",
    "        combined_prob_maps = combined_prob_maps / (combined_prob_maps.sum(dim=0, keepdim=True) + 1e-6)\n",
    "        \n",
    "        # Convertir a numpy\n",
    "        prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "        prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "        \n",
    "        # Generar segmentación semántica (clases 0, 1, 2)\n",
    "        segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128]\n",
    "        segmentation_np = segmentation.astype(np.int16)  # [0, 1, 2]\n",
    "        \n",
    "        # Mapear segmentación a valores originales (0, 6, 2)\n",
    "        segmentation_np_orig = np.zeros_like(segmentation_np, dtype=np.int16)\n",
    "        segmentation_np_orig[segmentation_np == 1] = 6  # Vasogénico\n",
    "        segmentation_np_orig[segmentation_np == 2] = 2  # Infiltrado\n",
    "        # Fondo (0) ya está correcto\n",
    "                \n",
    "        # Guardar imágenes MRI en NIfTI\n",
    "        image_np = image.squeeze(0).cpu().numpy()  # [11, 128, 128, 128]\n",
    "        for channel in range(image_np.shape[0]):\n",
    "            nifti_img = nib.Nifti1Image(image_np[channel], affine)\n",
    "            nib.save(nifti_img, f\"{nifti_output_dir}/case_{idx}_modality_{channel}.nii.gz\")\n",
    "        \n",
    "        # Guardar etiquetas en NIfTI (valores 0, 2, 6)\n",
    "        nifti_label_img = nib.Nifti1Image(labels_np, affine)\n",
    "        label_output_path = os.path.join(nifti_output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_label_img, label_output_path)\n",
    "        print(f\"Guardadas etiquetas en {label_output_path}\")\n",
    "        \n",
    "        # Guardar mapas de probabilidad\n",
    "        nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine)\n",
    "        prob_output_path = os.path.join(probs_output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_prob_img, prob_output_path)\n",
    "        print(f\"Guardado mapa de probabilidad en {prob_output_path}\")\n",
    "        \n",
    "        # Guardar segmentación (valores 0, 6, 2)\n",
    "        nifti_seg_img = nib.Nifti1Image(segmentation_np_orig, affine)\n",
    "        seg_output_path = os.path.join(nifti_output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_seg_img, seg_output_path)\n",
    "        print(f\"Guardada segmentación en {seg_output_path}\")\n",
    "\n",
    "# Remover hooks\n",
    "hook_handle_decoder1.remove()\n",
    "hook_handle_decoder2.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardando resultados Pipeline1 + Pipeline2 con Recurrencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images, 6 labels, and 6 recurrence files.\n",
      "2025-11-18 11:42:33,282 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigo/anaconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 0:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 0: recurrence_np shape: (128, 128, 128), min: -2.4518356323242188, max: 10.343467712402344, mean: 1.5454133972525597e-08\n",
      "Caso 0: Vasogénico channel sum (6): 40406, Infiltrado channel sum (2): 22403\n",
      "Caso 0: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/case_0_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.4518356323242188, max: 10.343467712402344, mean: 1.4600035069811668e-08\n",
      "Recurrence file size: 3104.09 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/labels_case_0.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/probability_maps/probability_maps_case_0.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/segmentation_case_0.nii.gz\n",
      "2025-11-18 11:42:38,069 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 1:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 1: recurrence_np shape: (128, 128, 128), min: -2.74082088470459, max: 12.87743854522705, mean: 9.313225746154785e-08\n",
      "Caso 1: Vasogénico channel sum (6): 41333, Infiltrado channel sum (2): 101448\n",
      "Caso 1: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/case_1_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.74082088470459, max: 12.87743854522705, mean: 9.258546653651001e-08\n",
      "Recurrence file size: 3484.12 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/labels_case_1.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/probability_maps/probability_maps_case_1.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/segmentation_case_1.nii.gz\n",
      "2025-11-18 11:42:43,235 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 2:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 2: recurrence_np shape: (128, 128, 128), min: -3.149334192276001, max: 13.404967308044434, mean: -3.3760443329811096e-09\n",
      "Caso 2: Vasogénico channel sum (6): 10132, Infiltrado channel sum (2): 23548\n",
      "Caso 2: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/case_2_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -3.149334192276001, max: 13.404967308044434, mean: -9.55301994107205e-09\n",
      "Recurrence file size: 3352.61 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/labels_case_2.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/probability_maps/probability_maps_case_2.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/segmentation_case_2.nii.gz\n",
      "2025-11-18 11:42:48,170 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 3:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 3: recurrence_np shape: (128, 128, 128), min: -2.4558212757110596, max: 9.173452377319336, mean: -4.60495357401669e-08\n",
      "Caso 3: Vasogénico channel sum (6): 37953, Infiltrado channel sum (2): 42915\n",
      "Caso 3: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/case_3_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.4558212757110596, max: 9.173452377319336, mean: -4.621535892868067e-08\n",
      "Recurrence file size: 3037.72 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/labels_case_3.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/probability_maps/probability_maps_case_3.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/segmentation_case_3.nii.gz\n",
      "2025-11-18 11:42:53,051 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 4:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 4: recurrence_np shape: (128, 128, 128), min: -2.65439772605896, max: 12.409589767456055, mean: 2.2140739019960165e-08\n",
      "Caso 4: Vasogénico channel sum (6): 16856, Infiltrado channel sum (2): 16769\n",
      "Caso 4: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/case_4_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.65439772605896, max: 12.409589767456055, mean: 1.906607699150853e-08\n",
      "Recurrence file size: 3580.78 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/labels_case_4.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/probability_maps/probability_maps_case_4.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/segmentation_case_4.nii.gz\n",
      "2025-11-18 11:42:58,060 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 5:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 5: recurrence_np shape: (128, 128, 128), min: -3.037285327911377, max: 11.260549545288086, mean: -7.253402145579457e-08\n",
      "Caso 5: Vasogénico channel sum (6): 6926, Infiltrado channel sum (2): 7903\n",
      "Caso 5: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/case_5_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -3.037285327911377, max: 11.260549545288086, mean: -7.070550909343831e-08\n",
      "Recurrence file size: 2770.12 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/labels_case_5.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/probability_maps/probability_maps_case_5.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri/nifti_volumes/segmentation_case_5.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from monai import transforms\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import monai.utils\n",
    "from src.get_data import CustomDatasetRec\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Modelo de proyección (MLP más profundo)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim1=256, hidden_dim2=128, output_dim=128, dropout_p=0.3):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Clasificador supervisado (MLP)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=256, hidden_dim2=128, num_classes=3, dropout_p=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device, batch_size=8192):\n",
    "    projection_head.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        probs_flat = []\n",
    "        \n",
    "        for i in range(0, embeddings_flat.shape[0], batch_size):\n",
    "            batch = embeddings_flat[i:i+batch_size].to(device)\n",
    "            z = projection_head(batch)  # [batch_size, 128]\n",
    "            z = F.normalize(z, dim=1)\n",
    "            logits = classifier(z)  # [batch_size, 3]\n",
    "            probs = F.softmax(logits, dim=1)  # [batch_size, 3]\n",
    "            probs_flat.append(probs.cpu())\n",
    "        \n",
    "        probs_flat = torch.cat(probs_flat, dim=0)  # [2097152, 3]\n",
    "        probs = probs_flat.reshape(128, 128, 128, 3)  # [128, 128, 128, 3]\n",
    "        probs = probs.permute(3, 0, 1, 2)  # [3, 128, 128, 128]\n",
    "    \n",
    "    return probs  # Tensor [3, 128, 128, 128]\n",
    "\n",
    "# Transformaciones de MONAI\n",
    "roi = (128, 128, 128)\n",
    "source_k = \"label\"\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # transforms.ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            source_key=source_k,\n",
    "            k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[roi[0], roi[1], roi[2]],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "# Transformaciones combinadas para imágenes de entrada, etiquetas y recurrencia\n",
    "combined_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\", \"recurrence\"]),\n",
    "        transforms.EnsureChannelFirstD(keys=\"recurrence\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        # ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            source_key=\"label\",\n",
    "            k_divisible=[128, 128, 128],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            roi_size=[128, 128, 128],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=[\"image\", \"recurrence\"], nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dataset y DataLoader\n",
    "dataset_path = './Dataset/Dataset_30_6'\n",
    "train_set = CustomDatasetRec(dataset_path, section=\"test_6\", transform=combined_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Directorios\n",
    "output_dir = \"Dataset/MRIs/contrastive_voxel_wise/combined_results_recurrencia_pipe1-pipe2_test6_10mri\"\n",
    "nifti_output_dir = os.path.join(output_dir, \"nifti_volumes\")\n",
    "probs_output_dir = os.path.join(output_dir, \"probability_maps\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(nifti_output_dir, exist_ok=True)\n",
    "os.makedirs(probs_output_dir, exist_ok=True)\n",
    "\n",
    "# Cargar modelos contrastivos preentrenados\n",
    "projection_head1 = ProjectionHead(input_dim=48).to(device)\n",
    "# projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe1_v01_m1.pth\", map_location=device))\n",
    "projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_gffqpzjv.pth\", map_location=device))\n",
    "# projection_head1.eval()\n",
    "\n",
    "projection_head2 = ProjectionHead(input_dim=48).to(device)\n",
    "# projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_8exzvcui.pth\", map_location=device))\n",
    "# projection_head2.eval()\n",
    "\n",
    "# Cargar clasificadores preentrenados\n",
    "classifier1 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe1_v01_m1.pth\", map_location=device))\n",
    "classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_gffqpzjv.pth\", map_location=device))\n",
    "# classifier1.eval()\n",
    "\n",
    "classifier2 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_8exzvcui.pth\", map_location=device))\n",
    "# classifier2.eval()\n",
    "\n",
    "# Hooks para embeddings\n",
    "decoder_features_model1 = None\n",
    "decoder_features_model2 = None\n",
    "\n",
    "def decoder_hook_fn_model1(module, input, output):\n",
    "    global decoder_features_model1\n",
    "    decoder_features_model1 = output\n",
    "\n",
    "def decoder_hook_fn_model2(module, input, output):\n",
    "    global decoder_features_model2\n",
    "    decoder_features_model2 = output\n",
    "\n",
    "hook_handle_decoder1 = model1.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model1)\n",
    "hook_handle_decoder2 = model2.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model2)\n",
    "\n",
    "\n",
    "# Procesar y combinar\n",
    "with torch.no_grad():\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        monai.utils.set_determinism(seed=idx)\n",
    "        \n",
    "        print(f\"\\nCaso {idx}:\")\n",
    "        print(f\"image shape: {batch_data['image'].shape}\")\n",
    "        print(f\"label shape: {batch_data['label'].shape}\")\n",
    "        print(f\"recurrence shape: {batch_data['recurrence'].shape}\")\n",
    "        \n",
    "        # Extraer datos\n",
    "        image = batch_data[\"image\"].to(device)  # [1, 11, 128, 128, 128]\n",
    "        label = batch_data[\"label\"].to(device)  # [1, 2, 128, 128, 128]\n",
    "        recurrence = batch_data[\"recurrence\"].to(device)  # [1, 1, 128, 128, 128]\n",
    "                \n",
    "        # Convertir recurrencia a numpy\n",
    "        recurrence_np = recurrence.squeeze().cpu().numpy().astype(np.float32)  # [128, 128, 128]\n",
    "        print(f\"Caso {idx}: recurrence_np shape: {recurrence_np.shape}, min: {recurrence_np.min()}, max: {recurrence_np.max()}, mean: {recurrence_np.mean()}\")\n",
    "        \n",
    "        # Debug: Verificar canales one-hot\n",
    "        print(f\"Caso {idx}: Vasogénico channel sum (6): {label[0, 0].sum().item()}, Infiltrado channel sum (2): {label[0, 1].sum().item()}\")\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas (0, 6, 2)\n",
    "        label_class = torch.zeros(label.shape[2:], dtype=torch.long, device=device)  # [128, 128, 128]\n",
    "        label_class[label[0, 0] == 1] = 6  # Vasogénico\n",
    "        label_class[label[0, 1] == 1] = 2  # Infiltrado\n",
    "        labels_np = label_class.cpu().numpy().astype(np.int16)  # [128, 128, 128]\n",
    "        \n",
    "        # Mapear etiquetas a 0, 1, 2 para métricas\n",
    "        labels_metrics = np.zeros_like(labels_np, dtype=np.int16)\n",
    "        labels_metrics[labels_np == 6] = 1  # Vasogénico -> 1\n",
    "        labels_metrics[labels_np == 2] = 2  # Infiltrado -> 2\n",
    "        \n",
    "        # Verificar etiquetas\n",
    "        unique_labels = np.unique(labels_np)\n",
    "        print(f\"Caso {idx}: Etiquetas únicas (0, 2, 6): {unique_labels}\")\n",
    "        if not np.all(np.isin(unique_labels, [0, 2, 6])):\n",
    "            print(f\"Advertencia: Etiquetas inválidas en caso {idx}: {unique_labels}\")\n",
    "        if 6 not in unique_labels:\n",
    "            print(f\"Advertencia: Clase vasogénico (6) no presente en caso {idx}\")\n",
    "        \n",
    "        # Obtener embeddings\n",
    "        _ = model1(image)\n",
    "        _ = model2(image)\n",
    "        embeddings1 = decoder_features_model1\n",
    "        embeddings2 = decoder_features_model2\n",
    "        \n",
    "        # Generar mapas de probabilidad\n",
    "        prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "        prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "        \n",
    "        # Combinar mapas\n",
    "        combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "        combined_prob_maps[0] = prob_maps1[0]  # Fondo (0)\n",
    "        combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Vasogénico (1)\n",
    "        combined_prob_maps[2] = prob_maps2[2]  # Infiltrado (2)\n",
    "        \n",
    "        # Normalizar probabilidades\n",
    "        combined_prob_maps = combined_prob_maps / (combined_prob_maps.sum(dim=0, keepdim=True) + 1e-6)\n",
    "        \n",
    "        # Convertir a numpy\n",
    "        prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "        prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "        \n",
    "        # Generar segmentación semántica (clases 0, 1, 2)\n",
    "        segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128]\n",
    "        segmentation_np = segmentation.astype(np.int16)  # [0, 1, 2]\n",
    "        \n",
    "        # Mapear segmentación a valores originales (0, 6, 2)\n",
    "        segmentation_np_orig = np.zeros_like(segmentation_np, dtype=np.int16)\n",
    "        segmentation_np_orig[segmentation_np == 1] = 6  # Vasogénico\n",
    "        segmentation_np_orig[segmentation_np == 2] = 2  # Infiltrado\n",
    "        \n",
    "        # Guardar imágenes MRI en NIfTI\n",
    "        image_np = image.squeeze(0).cpu().numpy()  # [11, 128, 128, 128]\n",
    "        for channel in range(image_np.shape[0]):\n",
    "            nifti_img = nib.Nifti1Image(image_np[channel], affine, header=nib.Nifti1Header())\n",
    "            nib.save(nifti_img, os.path.join(nifti_output_dir, f\"case_{idx}_modality_{channel}.nii.gz\"))\n",
    "        \n",
    "        # Guardar imagen de recurrencia en NIfTI\n",
    "        nifti_recurrence_img = nib.Nifti1Image(recurrence_np, affine, header=nib.Nifti1Header())\n",
    "        recurrence_output_path = os.path.join(nifti_output_dir, f\"case_{idx}_recurrence.nii.gz\")\n",
    "        nib.save(nifti_recurrence_img, recurrence_output_path)\n",
    "        print(f\"Guardada imagen de recurrencia en {recurrence_output_path}\")\n",
    "        saved_nifti = nib.load(recurrence_output_path)\n",
    "        saved_data = saved_nifti.get_fdata()\n",
    "        print(f\"Saved recurrence NIfTI shape: {saved_data.shape}, min: {saved_data.min()}, max: {saved_data.max()}, mean: {saved_data.mean()}\")\n",
    "        file_size = os.path.getsize(recurrence_output_path) / 1024  # Size in kB\n",
    "        print(f\"Recurrence file size: {file_size:.2f} kB\")\n",
    "        \n",
    "        # Guardar etiquetas en NIfTI (valores 0, 2, 6)\n",
    "        nifti_label_img = nib.Nifti1Image(labels_np, affine, header=nib.Nifti1Header())\n",
    "        label_output_path = os.path.join(nifti_output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_label_img, label_output_path)\n",
    "        print(f\"Guardadas etiquetas en {label_output_path}\")\n",
    "        \n",
    "        # Guardar mapas de probabilidad\n",
    "        nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine, header=nib.Nifti1Header())\n",
    "        prob_output_path = os.path.join(probs_output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_prob_img, prob_output_path)\n",
    "        print(f\"Guardado mapa de probabilidad en {prob_output_path}\")\n",
    "        \n",
    "        # Guardar segmentación (valores 0, 6, 2)\n",
    "        nifti_seg_img = nib.Nifti1Image(segmentation_np_orig, affine, header=nib.Nifti1Header())\n",
    "        seg_output_path = os.path.join(nifti_output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_seg_img, seg_output_path)\n",
    "        print(f\"Guardada segmentación en {seg_output_path}\")\n",
    "        \n",
    "        # Restaurar aleatoriedad después de cada caso\n",
    "        monai.utils.set_determinism(seed=None)\n",
    "\n",
    "# Remover hooks\n",
    "hook_handle_decoder1.remove()\n",
    "hook_handle_decoder2.remove()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardando resultados Pipeline 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images, 6 labels, and 6 recurrence files.\n",
      "2025-11-18 12:02:13,681 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/minigo/anaconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 0:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 0: recurrence_np shape: (128, 128, 128), min: -2.4518356323242188, max: 10.343467712402344, mean: 1.5454133972525597e-08\n",
      "Caso 0: Vasogénico channel sum (6): 18101.0, Infiltrado channel sum (2): 22403.0\n",
      "Caso 0: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/case_0_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.4518356323242188, max: 10.343467712402344, mean: 1.4600035069811668e-08\n",
      "Recurrence file size: 3104.09 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/labels_case_0.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/probability_maps/probability_maps_case_0.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/segmentation_case_0.nii.gz\n",
      "2025-11-18 12:02:17,975 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 1:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 1: recurrence_np shape: (128, 128, 128), min: -2.74082088470459, max: 12.87743854522705, mean: 9.313225746154785e-08\n",
      "Caso 1: Vasogénico channel sum (6): 12105.0, Infiltrado channel sum (2): 101448.0\n",
      "Caso 1: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/case_1_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.74082088470459, max: 12.87743854522705, mean: 9.258546653651001e-08\n",
      "Recurrence file size: 3484.12 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/labels_case_1.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/probability_maps/probability_maps_case_1.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/segmentation_case_1.nii.gz\n",
      "2025-11-18 12:02:22,286 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 2:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 2: recurrence_np shape: (128, 128, 128), min: -3.149334192276001, max: 13.404967308044434, mean: -3.3760443329811096e-09\n",
      "Caso 2: Vasogénico channel sum (6): 3584.0, Infiltrado channel sum (2): 23548.0\n",
      "Caso 2: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/case_2_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -3.149334192276001, max: 13.404967308044434, mean: -9.55301994107205e-09\n",
      "Recurrence file size: 3352.61 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/labels_case_2.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/probability_maps/probability_maps_case_2.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/segmentation_case_2.nii.gz\n",
      "2025-11-18 12:02:26,657 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 3:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 3: recurrence_np shape: (128, 128, 128), min: -2.4558212757110596, max: 9.173452377319336, mean: -4.60495357401669e-08\n",
      "Caso 3: Vasogénico channel sum (6): 30312.0, Infiltrado channel sum (2): 42915.0\n",
      "Caso 3: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/case_3_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.4558212757110596, max: 9.173452377319336, mean: -4.621535892868067e-08\n",
      "Recurrence file size: 3037.72 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/labels_case_3.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/probability_maps/probability_maps_case_3.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/segmentation_case_3.nii.gz\n",
      "2025-11-18 12:02:30,756 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 4:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 4: recurrence_np shape: (128, 128, 128), min: -2.65439772605896, max: 12.409589767456055, mean: 2.2140739019960165e-08\n",
      "Caso 4: Vasogénico channel sum (6): 6671.0, Infiltrado channel sum (2): 16769.0\n",
      "Caso 4: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/case_4_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.65439772605896, max: 12.409589767456055, mean: 1.906607699150853e-08\n",
      "Recurrence file size: 3580.78 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/labels_case_4.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/probability_maps/probability_maps_case_4.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/segmentation_case_4.nii.gz\n",
      "2025-11-18 12:02:35,190 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([10, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 5:\n",
      "image shape: torch.Size([1, 10, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 5: recurrence_np shape: (128, 128, 128), min: -3.033317804336548, max: 11.25364875793457, mean: -1.0141957318410277e-07\n",
      "Caso 5: Vasogénico channel sum (6): 4085.0, Infiltrado channel sum (2): 7903.0\n",
      "Caso 5: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/case_5_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -3.033317804336548, max: 11.25364875793457, mean: -9.8086326311142e-08\n",
      "Recurrence file size: 2801.90 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/labels_case_5.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/probability_maps/probability_maps_case_5.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri/nifti_volumes/segmentation_case_5.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from monai import transforms\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import monai.utils\n",
    "from src.get_data import CustomDatasetRec\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Modelo de proyección (MLP más profundo)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim1=256, hidden_dim2=128, output_dim=128, dropout_p=0.3):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Clasificador supervisado (MLP)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=256, hidden_dim2=128, num_classes=3, dropout_p=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device, batch_size=8192):\n",
    "    projection_head.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        probs_flat = []\n",
    "        \n",
    "        for i in range(0, embeddings_flat.shape[0], batch_size):\n",
    "            batch = embeddings_flat[i:i+batch_size].to(device)\n",
    "            z = projection_head(batch)  # [batch_size, 128]\n",
    "            z = F.normalize(z, dim=1)\n",
    "            logits = classifier(z)  # [batch_size, 3]\n",
    "            probs = F.softmax(logits, dim=1)  # [batch_size, 3]\n",
    "            probs_flat.append(probs.cpu())\n",
    "        \n",
    "        probs_flat = torch.cat(probs_flat, dim=0)  # [2097152, 3]\n",
    "        probs = probs_flat.reshape(128, 128, 128, 3)  # [128, 128, 128, 3]\n",
    "        probs = probs.permute(3, 0, 1, 2)  # [3, 128, 128, 128]\n",
    "    \n",
    "    return probs  # Tensor [3, 128, 128, 128]\n",
    "\n",
    "# Transformaciones de MONAI\n",
    "roi = (128, 128, 128)\n",
    "source_k = \"label\"\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # transforms.ConvertToMultiChannelBasedOnBratsClassesd(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            source_key=source_k,\n",
    "            k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[roi[0], roi[1], roi[2]],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "# Transformaciones combinadas para imágenes de entrada, etiquetas y recurrencia\n",
    "combined_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\", \"recurrence\"]),\n",
    "        transforms.EnsureChannelFirstD(keys=\"recurrence\"),\n",
    "        ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            source_key=\"label\",\n",
    "            k_divisible=[128, 128, 128],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            roi_size=[128, 128, 128],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=[\"image\", \"recurrence\"], nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dataset y DataLoader\n",
    "dataset_path = './Dataset/Dataset_30_6'\n",
    "train_set = CustomDatasetRec(dataset_path, section=\"test_6\", transform=combined_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Directorios\n",
    "output_dir = \"Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe2_test_6_10mri\"\n",
    "nifti_output_dir = os.path.join(output_dir, \"nifti_volumes\")\n",
    "probs_output_dir = os.path.join(output_dir, \"probability_maps\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(nifti_output_dir, exist_ok=True)\n",
    "os.makedirs(probs_output_dir, exist_ok=True)\n",
    "\n",
    "# Cargar modelos contrastivos preentrenados\n",
    "# projection_head1 = ProjectionHead(input_dim=48).to(device)\n",
    "# # projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe1_v01_m1.pth\", map_location=device))\n",
    "# projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_gffqpzjv.pth\", map_location=device))\n",
    "# # projection_head1.eval()\n",
    "\n",
    "projection_head2 = ProjectionHead(input_dim=48).to(device)\n",
    "# projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_8exzvcui.pth\", map_location=device))\n",
    "# projection_head2.eval()\n",
    "\n",
    "# Cargar clasificadores preentrenados\n",
    "# classifier1 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# # classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe1_v01_m1.pth\", map_location=device))\n",
    "# classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_gffqpzjv.pth\", map_location=device))\n",
    "# # classifier1.eval()\n",
    "\n",
    "classifier2 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_8exzvcui.pth\", map_location=device))\n",
    "# classifier2.eval()\n",
    "\n",
    "# Hooks para embeddings\n",
    "# decoder_features_model1 = None\n",
    "decoder_features_model2 = None\n",
    "\n",
    "# def decoder_hook_fn_model1(module, input, output):\n",
    "#     global decoder_features_model1\n",
    "#     decoder_features_model1 = output\n",
    "\n",
    "def decoder_hook_fn_model2(module, input, output):\n",
    "    global decoder_features_model2\n",
    "    decoder_features_model2 = output\n",
    "\n",
    "# hook_handle_decoder1 = model1.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model1)\n",
    "hook_handle_decoder2 = model2.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model2)\n",
    "\n",
    "\n",
    "# Procesar y combinar\n",
    "with torch.no_grad():\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        monai.utils.set_determinism(seed=idx)\n",
    "        \n",
    "        print(f\"\\nCaso {idx}:\")\n",
    "        print(f\"image shape: {batch_data['image'].shape}\")\n",
    "        print(f\"label shape: {batch_data['label'].shape}\")\n",
    "        print(f\"recurrence shape: {batch_data['recurrence'].shape}\")\n",
    "        \n",
    "        # Extraer datos\n",
    "        image = batch_data[\"image\"].to(device)  # [1, 11, 128, 128, 128]\n",
    "        label = batch_data[\"label\"].to(device)  # [1, 2, 128, 128, 128]\n",
    "        recurrence = batch_data[\"recurrence\"].to(device)  # [1, 1, 128, 128, 128]\n",
    "                \n",
    "        # Convertir recurrencia a numpy\n",
    "        recurrence_np = recurrence.squeeze().cpu().numpy().astype(np.float32)  # [128, 128, 128]\n",
    "        print(f\"Caso {idx}: recurrence_np shape: {recurrence_np.shape}, min: {recurrence_np.min()}, max: {recurrence_np.max()}, mean: {recurrence_np.mean()}\")\n",
    "        \n",
    "        # Debug: Verificar canales one-hot\n",
    "        print(f\"Caso {idx}: Vasogénico channel sum (6): {label[0, 0].sum().item()}, Infiltrado channel sum (2): {label[0, 1].sum().item()}\")\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas (0, 6, 2)\n",
    "        label_class = torch.zeros(label.shape[2:], dtype=torch.long, device=device)  # [128, 128, 128]\n",
    "        label_class[label[0, 0] == 1] = 6  # Vasogénico\n",
    "        label_class[label[0, 1] == 1] = 2  # Infiltrado\n",
    "        labels_np = label_class.cpu().numpy().astype(np.int16)  # [128, 128, 128]\n",
    "        \n",
    "        # Mapear etiquetas a 0, 1, 2 para métricas\n",
    "        labels_metrics = np.zeros_like(labels_np, dtype=np.int16)\n",
    "        labels_metrics[labels_np == 6] = 1  # Vasogénico -> 1\n",
    "        labels_metrics[labels_np == 2] = 2  # Infiltrado -> 2\n",
    "        \n",
    "        # Verificar etiquetas\n",
    "        unique_labels = np.unique(labels_np)\n",
    "        print(f\"Caso {idx}: Etiquetas únicas (0, 2, 6): {unique_labels}\")\n",
    "        if not np.all(np.isin(unique_labels, [0, 2, 6])):\n",
    "            print(f\"Advertencia: Etiquetas inválidas en caso {idx}: {unique_labels}\")\n",
    "        if 6 not in unique_labels:\n",
    "            print(f\"Advertencia: Clase vasogénico (6) no presente en caso {idx}\")\n",
    "        \n",
    "        # Obtener embeddings\n",
    "        # _ = model1(image)\n",
    "        _ = model2(image)\n",
    "        # embeddings1 = decoder_features_model1\n",
    "        embeddings2 = decoder_features_model2\n",
    "        \n",
    "        # Generar mapas de probabilidad\n",
    "        # prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "        prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "        \n",
    "        # # Combinar mapas\n",
    "        # combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "        # combined_prob_maps[0] = prob_maps1[0]  # Fondo (0)\n",
    "        # combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Vasogénico (1)\n",
    "        # combined_prob_maps[2] = prob_maps2[2]  # Infiltrado (2)\n",
    "        \n",
    "        # Normalizar probabilidades\n",
    "        combined_prob_maps = prob_maps2 / (prob_maps2.sum(dim=0, keepdim=True) + 1e-6)\n",
    "        \n",
    "        # Convertir a numpy\n",
    "        prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "        prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "        \n",
    "        # Generar segmentación semántica (clases 0, 1, 2)\n",
    "        segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128]\n",
    "        segmentation_np = segmentation.astype(np.int16)  # [0, 1, 2]\n",
    "        \n",
    "        # Mapear segmentación a valores originales (0, 6, 2)\n",
    "        segmentation_np_orig = np.zeros_like(segmentation_np, dtype=np.int16)\n",
    "        segmentation_np_orig[segmentation_np == 1] = 6  # Vasogénico\n",
    "        segmentation_np_orig[segmentation_np == 2] = 2  # Infiltrado\n",
    "        \n",
    "        # Guardar imágenes MRI en NIfTI\n",
    "        image_np = image.squeeze(0).cpu().numpy()  # [11, 128, 128, 128]\n",
    "        for channel in range(image_np.shape[0]):\n",
    "            nifti_img = nib.Nifti1Image(image_np[channel], affine, header=nib.Nifti1Header())\n",
    "            nib.save(nifti_img, os.path.join(nifti_output_dir, f\"case_{idx}_modality_{channel}.nii.gz\"))\n",
    "        \n",
    "        # Guardar imagen de recurrencia en NIfTI\n",
    "        nifti_recurrence_img = nib.Nifti1Image(recurrence_np, affine, header=nib.Nifti1Header())\n",
    "        recurrence_output_path = os.path.join(nifti_output_dir, f\"case_{idx}_recurrence.nii.gz\")\n",
    "        nib.save(nifti_recurrence_img, recurrence_output_path)\n",
    "        print(f\"Guardada imagen de recurrencia en {recurrence_output_path}\")\n",
    "        saved_nifti = nib.load(recurrence_output_path)\n",
    "        saved_data = saved_nifti.get_fdata()\n",
    "        print(f\"Saved recurrence NIfTI shape: {saved_data.shape}, min: {saved_data.min()}, max: {saved_data.max()}, mean: {saved_data.mean()}\")\n",
    "        file_size = os.path.getsize(recurrence_output_path) / 1024  # Size in kB\n",
    "        print(f\"Recurrence file size: {file_size:.2f} kB\")\n",
    "        \n",
    "        # Guardar etiquetas en NIfTI (valores 0, 2, 6)\n",
    "        nifti_label_img = nib.Nifti1Image(labels_np, affine, header=nib.Nifti1Header())\n",
    "        label_output_path = os.path.join(nifti_output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_label_img, label_output_path)\n",
    "        print(f\"Guardadas etiquetas en {label_output_path}\")\n",
    "        \n",
    "        # Guardar mapas de probabilidad\n",
    "        nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine, header=nib.Nifti1Header())\n",
    "        prob_output_path = os.path.join(probs_output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_prob_img, prob_output_path)\n",
    "        print(f\"Guardado mapa de probabilidad en {prob_output_path}\")\n",
    "        \n",
    "        # Guardar segmentación (valores 0, 6, 2)\n",
    "        nifti_seg_img = nib.Nifti1Image(segmentation_np_orig, affine, header=nib.Nifti1Header())\n",
    "        seg_output_path = os.path.join(nifti_output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_seg_img, seg_output_path)\n",
    "        print(f\"Guardada segmentación en {seg_output_path}\")\n",
    "        \n",
    "        # Restaurar aleatoriedad después de cada caso\n",
    "        monai.utils.set_determinism(seed=None)\n",
    "\n",
    "# Remover hooks\n",
    "# hook_handle_decoder1.remove()\n",
    "hook_handle_decoder2.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardando resultados pipe 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 6 images, 6 labels, and 6 recurrence files.\n",
      "2025-06-20 13:11:46,329 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/training2/miniconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After transforms - image shape: torch.Size([11, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 0:\n",
      "image shape: torch.Size([1, 11, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 0: recurrence_np shape: (128, 128, 128), min: -2.4518356323242188, max: 10.343467712402344, mean: 1.5454133972525597e-08\n",
      "Caso 0: Vasogénico channel sum (6): 22305, Infiltrado channel sum (2): 40504\n",
      "Caso 0: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/case_0_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.4518356323242188, max: 10.343467712402344, mean: 1.4600035069811668e-08\n",
      "Recurrence file size: 3104.10 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/labels_case_0.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/probability_maps/probability_maps_case_0.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/segmentation_case_0.nii.gz\n",
      "2025-06-20 13:11:50,636 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([11, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 1:\n",
      "image shape: torch.Size([1, 11, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 1: recurrence_np shape: (128, 128, 128), min: -2.740821123123169, max: 12.877437591552734, mean: -3.565219230949879e-08\n",
      "Caso 1: Vasogénico channel sum (6): 29228, Infiltrado channel sum (2): 113553\n",
      "Caso 1: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/case_1_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.740821123123169, max: 12.877437591552734, mean: -3.290565862845707e-08\n",
      "Recurrence file size: 3481.42 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/labels_case_1.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/probability_maps/probability_maps_case_1.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/segmentation_case_1.nii.gz\n",
      "2025-06-20 13:11:54,810 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([11, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 2:\n",
      "image shape: torch.Size([1, 11, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 2: recurrence_np shape: (128, 128, 128), min: -3.149333953857422, max: 13.404967308044434, mean: 1.1228257790207863e-07\n",
      "Caso 2: Vasogénico channel sum (6): 6548, Infiltrado channel sum (2): 27132\n",
      "Caso 2: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/case_2_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -3.149333953857422, max: 13.404967308044434, mean: 1.1601991016171875e-07\n",
      "Recurrence file size: 3352.38 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/labels_case_2.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/probability_maps/probability_maps_case_2.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/segmentation_case_2.nii.gz\n",
      "2025-06-20 13:11:59,002 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([11, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 3:\n",
      "image shape: torch.Size([1, 11, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 3: recurrence_np shape: (128, 128, 128), min: -2.4558207988739014, max: 9.173452377319336, mean: 1.0602525435388088e-07\n",
      "Caso 3: Vasogénico channel sum (6): 7641, Infiltrado channel sum (2): 73227\n",
      "Caso 3: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/case_3_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.4558207988739014, max: 9.173452377319336, mean: 1.0488573484908337e-07\n",
      "Recurrence file size: 3036.71 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/labels_case_3.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/probability_maps/probability_maps_case_3.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/segmentation_case_3.nii.gz\n",
      "2025-06-20 13:12:03,197 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([11, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 4:\n",
      "image shape: torch.Size([1, 11, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 4: recurrence_np shape: (128, 128, 128), min: -2.65439772605896, max: 12.409589767456055, mean: 2.2140739019960165e-08\n",
      "Caso 4: Vasogénico channel sum (6): 10185, Infiltrado channel sum (2): 23440\n",
      "Caso 4: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/case_4_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -2.65439772605896, max: 12.409589767456055, mean: 1.906607699150853e-08\n",
      "Recurrence file size: 3580.78 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/labels_case_4.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/probability_maps/probability_maps_case_4.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/segmentation_case_4.nii.gz\n",
      "2025-06-20 13:12:07,572 - INFO - Apply pending transforms - lazy: None, pending: 0, upcoming 'Compose', transform.lazy: False\n",
      "After transforms - image shape: torch.Size([11, 128, 128, 128]), label shape: torch.Size([2, 128, 128, 128]), recurrence shape: torch.Size([1, 128, 128, 128])\n",
      "\n",
      "Caso 5:\n",
      "image shape: torch.Size([1, 11, 128, 128, 128])\n",
      "label shape: torch.Size([1, 2, 128, 128, 128])\n",
      "recurrence shape: torch.Size([1, 1, 128, 128, 128])\n",
      "Caso 5: recurrence_np shape: (128, 128, 128), min: -3.037285327911377, max: 11.260549545288086, mean: -7.253402145579457e-08\n",
      "Caso 5: Vasogénico channel sum (6): 2841, Infiltrado channel sum (2): 11988\n",
      "Caso 5: Etiquetas únicas (0, 2, 6): [0 2 6]\n",
      "Guardada imagen de recurrencia en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/case_5_recurrence.nii.gz\n",
      "Saved recurrence NIfTI shape: (128, 128, 128), min: -3.037285327911377, max: 11.260549545288086, mean: -7.070550909343831e-08\n",
      "Recurrence file size: 2770.12 kB\n",
      "Guardadas etiquetas en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/labels_case_5.nii.gz\n",
      "Guardado mapa de probabilidad en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/probability_maps/probability_maps_case_5.nii.gz\n",
      "Guardada segmentación en Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1/nifti_volumes/segmentation_case_5.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from monai import transforms\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import monai.utils\n",
    "from src.get_data import CustomDatasetRec\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Modelo de proyección (MLP más profundo)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim1=256, hidden_dim2=128, output_dim=128, dropout_p=0.3):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Clasificador supervisado (MLP)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=256, hidden_dim2=128, num_classes=3, dropout_p=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device, batch_size=8192):\n",
    "    projection_head.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        probs_flat = []\n",
    "        \n",
    "        for i in range(0, embeddings_flat.shape[0], batch_size):\n",
    "            batch = embeddings_flat[i:i+batch_size].to(device)\n",
    "            z = projection_head(batch)  # [batch_size, 128]\n",
    "            z = F.normalize(z, dim=1)\n",
    "            logits = classifier(z)  # [batch_size, 3]\n",
    "            probs = F.softmax(logits, dim=1)  # [batch_size, 3]\n",
    "            probs_flat.append(probs.cpu())\n",
    "        \n",
    "        probs_flat = torch.cat(probs_flat, dim=0)  # [2097152, 3]\n",
    "        probs = probs_flat.reshape(128, 128, 128, 3)  # [128, 128, 128, 3]\n",
    "        probs = probs.permute(3, 0, 1, 2)  # [3, 128, 128, 128]\n",
    "    \n",
    "    return probs  # Tensor [3, 128, 128, 128]\n",
    "\n",
    "# Transformaciones de MONAI\n",
    "roi = (128, 128, 128)\n",
    "source_k = \"label\"\n",
    "# Transformaciones combinadas para imágenes de entrada, etiquetas y recurrencia\n",
    "combined_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\", \"recurrence\"]),\n",
    "        transforms.EnsureChannelFirstD(keys=\"recurrence\"),\n",
    "        # ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            source_key=\"label\",\n",
    "            k_divisible=[128, 128, 128],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            roi_size=[128, 128, 128],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=[\"image\", \"recurrence\"], nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dataset y DataLoader\n",
    "dataset_path = './Dataset/Dataset_30_6'\n",
    "train_set = CustomDatasetRec(dataset_path, section=\"train_30\", transform=combined_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Directorios\n",
    "output_dir = \"Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1_train_30\"\n",
    "nifti_output_dir = os.path.join(output_dir, \"nifti_volumes\")\n",
    "probs_output_dir = os.path.join(output_dir, \"probability_maps\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(nifti_output_dir, exist_ok=True)\n",
    "os.makedirs(probs_output_dir, exist_ok=True)\n",
    "\n",
    "# Cargar modelos contrastivos preentrenados\n",
    "projection_head1 = ProjectionHead(input_dim=48).to(device)\n",
    "projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe1_v01_m1.pth\", map_location=device))\n",
    "# projection_head1.eval()\n",
    "\n",
    "# projection_head2 = ProjectionHead(input_dim=48).to(device)\n",
    "# projection_head2.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "# # projection_head2.eval()\n",
    "\n",
    "# Cargar clasificadores preentrenados\n",
    "classifier1 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe1_v01_m1.pth\", map_location=device))\n",
    "# classifier1.eval()\n",
    "\n",
    "# classifier2 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "# classifier2.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe2_m1_1dhzmigz.pth\", map_location=device))\n",
    "# # classifier2.eval()\n",
    "\n",
    "# Hooks para embeddings\n",
    "decoder_features_model1 = None\n",
    "# decoder_features_model2 = None\n",
    "\n",
    "def decoder_hook_fn_model1(module, input, output):\n",
    "    global decoder_features_model1\n",
    "    decoder_features_model1 = output\n",
    "\n",
    "# def decoder_hook_fn_model2(module, input, output):\n",
    "#     global decoder_features_model2\n",
    "#     decoder_features_model2 = output\n",
    "\n",
    "hook_handle_decoder1 = model1.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model1)\n",
    "# hook_handle_decoder2 = model2.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model2)\n",
    "\n",
    "\n",
    "# Procesar y combinar\n",
    "with torch.no_grad():\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        monai.utils.set_determinism(seed=idx)\n",
    "        \n",
    "        print(f\"\\nCaso {idx}:\")\n",
    "        print(f\"image shape: {batch_data['image'].shape}\")\n",
    "        print(f\"label shape: {batch_data['label'].shape}\")\n",
    "        print(f\"recurrence shape: {batch_data['recurrence'].shape}\")\n",
    "        \n",
    "        # Extraer datos\n",
    "        image = batch_data[\"image\"].to(device)  # [1, 11, 128, 128, 128]\n",
    "        label = batch_data[\"label\"].to(device)  # [1, 2, 128, 128, 128]\n",
    "        recurrence = batch_data[\"recurrence\"].to(device)  # [1, 1, 128, 128, 128]\n",
    "\n",
    "        image_meta = batch_data[\"image\"].meta\n",
    "        affine = image_meta.get(\"affine\", np.eye(4)).numpy()\n",
    "                \n",
    "        # Convertir recurrencia a numpy\n",
    "        recurrence_np = recurrence.squeeze().cpu().numpy().astype(np.float32)  # [128, 128, 128]\n",
    "        print(f\"Caso {idx}: recurrence_np shape: {recurrence_np.shape}, min: {recurrence_np.min()}, max: {recurrence_np.max()}, mean: {recurrence_np.mean()}\")\n",
    "        \n",
    "        # Debug: Verificar canales one-hot\n",
    "        print(f\"Caso {idx}: Vasogénico channel sum (6): {label[0, 0].sum().item()}, Infiltrado channel sum (2): {label[0, 1].sum().item()}\")\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas (0, 6, 2)\n",
    "        label_class = torch.zeros(label.shape[2:], dtype=torch.long, device=device)  # [128, 128, 128]\n",
    "        label_class[label[0, 0] == 1] = 6  # Vasogénico\n",
    "        label_class[label[0, 1] == 1] = 2  # Infiltrado\n",
    "        labels_np = label_class.cpu().numpy().astype(np.int16)  # [128, 128, 128]\n",
    "        \n",
    "        # Mapear etiquetas a 0, 1, 2 para métricas\n",
    "        labels_metrics = np.zeros_like(labels_np, dtype=np.int16)\n",
    "        labels_metrics[labels_np == 6] = 1  # Vasogénico -> 1\n",
    "        labels_metrics[labels_np == 2] = 2  # Infiltrado -> 2\n",
    "        \n",
    "        # Verificar etiquetas\n",
    "        unique_labels = np.unique(labels_np)\n",
    "        print(f\"Caso {idx}: Etiquetas únicas (0, 2, 6): {unique_labels}\")\n",
    "        if not np.all(np.isin(unique_labels, [0, 2, 6])):\n",
    "            print(f\"Advertencia: Etiquetas inválidas en caso {idx}: {unique_labels}\")\n",
    "        if 6 not in unique_labels:\n",
    "            print(f\"Advertencia: Clase vasogénico (6) no presente en caso {idx}\")\n",
    "        \n",
    "        # Obtener embeddings\n",
    "        _ = model1(image)\n",
    "        # _ = model2(image)\n",
    "        embeddings1 = decoder_features_model1\n",
    "        # embeddings2 = decoder_features_model2\n",
    "        \n",
    "        # Generar mapas de probabilidad\n",
    "        prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)  # [3, 128, 128, 128]\n",
    "        # prob_maps2 = generate_probability_maps(embeddings2, projection_head2, classifier2, device)  # [3, 128, 128, 128]\n",
    "        \n",
    "        # # Combinar mapas\n",
    "        # combined_prob_maps = torch.zeros_like(prob_maps1)  # [3, 128, 128, 128]\n",
    "        # combined_prob_maps[0] = prob_maps1[0]  # Fondo (0)\n",
    "        # combined_prob_maps[1] = torch.max(prob_maps1[1], prob_maps2[1])  # Vasogénico (1)\n",
    "        # combined_prob_maps[2] = prob_maps2[2]  # Infiltrado (2)\n",
    "        \n",
    "        # Normalizar probabilidades\n",
    "        combined_prob_maps = prob_maps1 / (prob_maps1.sum(dim=0, keepdim=True) + 1e-6)\n",
    "        \n",
    "        # Convertir a numpy\n",
    "        prob_maps_np = combined_prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "        prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "        \n",
    "        # Generar segmentación semántica (clases 0, 1, 2)\n",
    "        segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128]\n",
    "        segmentation_np = segmentation.astype(np.int16)  # [0, 1, 2]\n",
    "        \n",
    "        # Mapear segmentación a valores originales (0, 6, 2)\n",
    "        segmentation_np_orig = np.zeros_like(segmentation_np, dtype=np.int16)\n",
    "        segmentation_np_orig[segmentation_np == 1] = 6  # Vasogénico\n",
    "        segmentation_np_orig[segmentation_np == 2] = 2  # Infiltrado\n",
    "        \n",
    "        # Guardar imágenes MRI en NIfTI\n",
    "        image_np = image.squeeze(0).cpu().numpy()  # [11, 128, 128, 128]\n",
    "        for channel in range(image_np.shape[0]):\n",
    "            nifti_img = nib.Nifti1Image(image_np[channel], affine, header=nib.Nifti1Header())\n",
    "            nib.save(nifti_img, os.path.join(nifti_output_dir, f\"case_{idx}_modality_{channel}.nii.gz\"))\n",
    "        \n",
    "        # Guardar imagen de recurrencia en NIfTI\n",
    "        nifti_recurrence_img = nib.Nifti1Image(recurrence_np, affine, header=nib.Nifti1Header())\n",
    "        recurrence_output_path = os.path.join(nifti_output_dir, f\"case_{idx}_recurrence.nii.gz\")\n",
    "        nib.save(nifti_recurrence_img, recurrence_output_path)\n",
    "        print(f\"Guardada imagen de recurrencia en {recurrence_output_path}\")\n",
    "        saved_nifti = nib.load(recurrence_output_path)\n",
    "        saved_data = saved_nifti.get_fdata()\n",
    "        print(f\"Saved recurrence NIfTI shape: {saved_data.shape}, min: {saved_data.min()}, max: {saved_data.max()}, mean: {saved_data.mean()}\")\n",
    "        file_size = os.path.getsize(recurrence_output_path) / 1024  # Size in kB\n",
    "        print(f\"Recurrence file size: {file_size:.2f} kB\")\n",
    "        \n",
    "        # Guardar etiquetas en NIfTI (valores 0, 2, 6)\n",
    "        nifti_label_img = nib.Nifti1Image(labels_np, affine, header=nib.Nifti1Header())\n",
    "        label_output_path = os.path.join(nifti_output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_label_img, label_output_path)\n",
    "        print(f\"Guardadas etiquetas en {label_output_path}\")\n",
    "        \n",
    "        # Guardar mapas de probabilidad\n",
    "        nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine, header=nib.Nifti1Header())\n",
    "        prob_output_path = os.path.join(probs_output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_prob_img, prob_output_path)\n",
    "        print(f\"Guardado mapa de probabilidad en {prob_output_path}\")\n",
    "        \n",
    "        # Guardar segmentación (valores 0, 6, 2)\n",
    "        nifti_seg_img = nib.Nifti1Image(segmentation_np_orig, affine, header=nib.Nifti1Header())\n",
    "        seg_output_path = os.path.join(nifti_output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "        nib.save(nifti_seg_img, seg_output_path)\n",
    "        print(f\"Guardada segmentación en {seg_output_path}\")\n",
    "        \n",
    "        # Restaurar aleatoriedad después de cada caso\n",
    "        monai.utils.set_determinism(seed=None)\n",
    "\n",
    "# Remover hooks\n",
    "hook_handle_decoder1.remove()\n",
    "# hook_handle_decoder2.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MRIs y metricas Pipe1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from monai import transforms\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "import monai.utils\n",
    "from src.get_data import CustomDatasetRec\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score, f1_score\n",
    "from scipy import stats\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "# Modelo de proyección (MLP más profundo)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim1=256, hidden_dim2=128, output_dim=128, dropout_p=0.3):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "\n",
    "# Clasificador supervisado (MLP)\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, hidden_dim1=256, hidden_dim2=128, num_classes=3, dropout_p=0.3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim1),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim1, hidden_dim2),\n",
    "            nn.ReLU(),\n",
    "            # nn.Dropout(dropout_p),\n",
    "            nn.Linear(hidden_dim2, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device, batch_size=8192):\n",
    "    projection_head.eval()\n",
    "    classifier.eval()\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        probs_flat = []\n",
    "        \n",
    "        for i in range(0, embeddings_flat.shape[0], batch_size):\n",
    "            batch = embeddings_flat[i:i+batch_size].to(device)\n",
    "            z = projection_head(batch)  # [batch_size, 128]\n",
    "            z = F.normalize(z, dim=1)\n",
    "            logits = classifier(z)  # [batch_size, 3]\n",
    "            probs = F.softmax(logits, dim=1)  # [batch_size, 3]\n",
    "            probs_flat.append(probs.cpu())\n",
    "        \n",
    "        probs_flat = torch.cat(probs_flat, dim=0)  # [2097152, 3]\n",
    "        probs = probs_flat.reshape(128, 128, 128, 3)  # [128, 128, 128, 3]\n",
    "        probs = probs.permute(3, 0, 1, 2)  # [3, 128, 128, 128]\n",
    "    \n",
    "    return probs  # Tensor [3, 128, 128, 128]\n",
    "\n",
    "# =================================================================================\n",
    "# INICIO: FUNCIONES AÑADIDAS PARA EL CÁLCULO DE MÉTRICAS\n",
    "# =================================================================================\n",
    "\n",
    "# Función para calcular métricas\n",
    "def calculate_metrics(pred, true, prob_maps=None, num_classes=3):\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    auc_scores = []\n",
    "    f1_scores = []\n",
    "    \n",
    "    accuracy = accuracy_score(true.flatten(), pred.flatten())\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "        \n",
    "        f1 = f1_score(true_cls.flatten(), pred_cls.flatten(), zero_division=0)\n",
    "        f1_scores.append(f1)\n",
    "        \n",
    "        if prob_maps is not None:\n",
    "            try:\n",
    "                auc = roc_auc_score(true_cls.flatten(), prob_maps[cls].flatten())\n",
    "                auc_scores.append(auc)\n",
    "            except ValueError:\n",
    "                auc_scores.append(np.nan)\n",
    "        else:\n",
    "            auc_scores.append(np.nan)\n",
    "    \n",
    "    return dice_scores, sensitivity_scores, precision_scores, auc_scores, accuracy, f1_scores\n",
    "\n",
    "# Función para dividir en cubos y obtener clases predominantes\n",
    "def get_cube_labels(volume, cube_size, num_classes=3):\n",
    "    dims = volume.shape\n",
    "    assert all(d % cube_size == 0 for d in dims), \"El tamaño del cubo debe dividir exactamente las dimensiones del volumen\"\n",
    "    \n",
    "    num_cubes_dims = [d // cube_size for d in dims]\n",
    "    \n",
    "    cube_labels = np.zeros(num_cubes_dims, dtype=np.uint8)\n",
    "    cube_probs = np.zeros([num_classes] + num_cubes_dims)\n",
    "    \n",
    "    for i in range(num_cubes_dims[0]):\n",
    "        for j in range(num_cubes_dims[1]):\n",
    "            for k in range(num_cubes_dims[2]):\n",
    "                cube = volume[i*cube_size:(i+1)*cube_size, \n",
    "                              j*cube_size:(j+1)*cube_size, \n",
    "                              k*cube_size:(k+1)*cube_size]\n",
    "                # Clase predominante (modo)\n",
    "                mode_value = stats.mode(cube.flatten(), keepdims=True)[0][0]\n",
    "                cube_labels[i, j, k] = mode_value\n",
    "                # Proporción de cada clase como \"probabilidad\" suavizada\n",
    "                for cls in range(num_classes):\n",
    "                    cube_probs[cls, i, j, k] = np.mean(cube == cls)\n",
    "    \n",
    "    return cube_labels, cube_probs\n",
    "\n",
    "# =================================================================================\n",
    "# FIN: FUNCIONES AÑADIDAS PARA EL CÁLCULO DE MÉTRICAS\n",
    "# =================================================================================\n",
    "\n",
    "# Transformaciones de MONAI\n",
    "roi = (128, 128, 128)\n",
    "source_k = \"label\"\n",
    "# Transformaciones combinadas para imágenes de entrada, etiquetas y recurrencia\n",
    "combined_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\", \"recurrence\"]),\n",
    "        transforms.EnsureChannelFirstD(keys=\"recurrence\"),\n",
    "        # ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            source_key=\"label\",\n",
    "            k_divisible=[128, 128, 128],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\", \"recurrence\"],\n",
    "            roi_size=[128, 128, 128],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=[\"image\", \"recurrence\"], nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dataset y DataLoader\n",
    "dataset_path = './Dataset/Dataset_30_6'\n",
    "train_set = CustomDatasetRec(dataset_path, section=\"test_6\", transform=combined_transform)\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "# Directorios\n",
    "output_dir = \"Dataset/MRIs/contrastive_voxel_wise/combined_results-pipe1\"\n",
    "nifti_output_dir = os.path.join(output_dir, \"nifti_volumes\")\n",
    "probs_output_dir = os.path.join(output_dir, \"probability_maps\")\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(nifti_output_dir, exist_ok=True)\n",
    "os.makedirs(probs_output_dir, exist_ok=True)\n",
    "\n",
    "# Cargar modelos contrastivos preentrenados\n",
    "projection_head1 = ProjectionHead(input_dim=48).to(device)\n",
    "projection_head1.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final_new_pipe1_v01_m1.pth\", map_location=device))\n",
    "\n",
    "# Cargar clasificadores preentrenados\n",
    "classifier1 = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "classifier1.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final_pipe1_v01_m1.pth\", map_location=device))\n",
    "\n",
    "# Hooks para embeddings\n",
    "decoder_features_model1 = None\n",
    "\n",
    "def decoder_hook_fn_model1(module, input, output):\n",
    "    global decoder_features_model1\n",
    "    decoder_features_model1 = output\n",
    "\n",
    "# Asegúrate de que `model1` esté definido y cargado antes de esta línea.\n",
    "# Por ejemplo: model1 = YourModelClass().to(device)\n",
    "# model1.load_state_dict(torch.load(\"path/to/your/model1.pth\"))\n",
    "hook_handle_decoder1 = model1.decoder1.conv_block.register_forward_hook(decoder_hook_fn_model1)\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# INICIO: INICIALIZACIÓN DE VARIABLES PARA MÉTRICAS\n",
    "# =================================================================================\n",
    "# Listas para métricas voxel-wise\n",
    "all_dice = {0: [], 1: [], 2: []}\n",
    "all_sensitivity = {0: [], 1: [], 2: []}\n",
    "all_precision = {0: [], 1: [], 2: []}\n",
    "all_auc = {0: [], 1: [], 2: []}\n",
    "all_accuracy = []\n",
    "all_f1 = {0: [], 1: [], 2: []}\n",
    "all_fpr = {0: [], 1: [], 2: []}\n",
    "all_tpr = {0: [], 1: [], 2: []}\n",
    "all_center_distance_voxel = []\n",
    "\n",
    "# Listas para métricas cube-wise\n",
    "all_dice_cube = {0: [], 1: [], 2: []}\n",
    "all_sensitivity_cube = {0: [], 1: [], 2: []}\n",
    "all_precision_cube = {0: [], 1: [], 2: []}\n",
    "all_auc_cube = {0: [], 1: [], 2: []}\n",
    "all_accuracy_cube = []\n",
    "all_f1_cube = {0: [], 1: [], 2: []}\n",
    "all_center_distance = []\n",
    "all_fpr_cube = {0: [], 1: [], 2: []}\n",
    "all_tpr_cube = {0: [], 1: [], 2: []}\n",
    "\n",
    "# Tamaño del cubo\n",
    "cube_size = 8\n",
    "class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "colors = ['blue', 'green', 'red']\n",
    "\n",
    "# =================================================================================\n",
    "# FIN: INICIALIZACIÓN DE VARIABLES PARA MÉTRICAS\n",
    "# =================================================================================\n",
    "\n",
    "\n",
    "# Procesar y combinar\n",
    "with torch.no_grad():\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        monai.utils.set_determinism(seed=idx)\n",
    "        \n",
    "        print(f\"\\nCaso {idx}:\")\n",
    "        print(f\"image shape: {batch_data['image'].shape}\")\n",
    "        \n",
    "        # Extraer datos\n",
    "        image = batch_data[\"image\"].to(device)\n",
    "        label = batch_data[\"label\"].to(device)\n",
    "        recurrence = batch_data[\"recurrence\"].to(device)\n",
    "        image_meta = batch_data[\"image\"].meta\n",
    "        affine = image_meta.get(\"affine\", np.eye(4)).numpy()\n",
    "\n",
    "        # Convertir recurrencia a numpy\n",
    "        recurrence_np = recurrence.squeeze().cpu().numpy().astype(np.float32)\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas (0, 6, 2)\n",
    "        label_class = torch.zeros(label.shape[2:], dtype=torch.long, device=device)\n",
    "        label_class[label[0, 0] == 1] = 6  # Vasogénico\n",
    "        label_class[label[0, 1] == 1] = 2  # Infiltrado\n",
    "        labels_np = label_class.cpu().numpy().astype(np.int16)\n",
    "        \n",
    "        # Mapear etiquetas a 0, 1, 2 para métricas\n",
    "        labels_metrics = np.zeros_like(labels_np, dtype=np.int16)\n",
    "        labels_metrics[labels_np == 6] = 1  # Vasogénico -> 1\n",
    "        labels_metrics[labels_np == 2] = 2  # Infiltrado -> 2\n",
    "        \n",
    "        # Obtener embeddings\n",
    "        _ = model1(image)\n",
    "        embeddings1 = decoder_features_model1\n",
    "        \n",
    "        # Generar mapas de probabilidad\n",
    "        prob_maps1 = generate_probability_maps(embeddings1, projection_head1, classifier1, device)\n",
    "        \n",
    "        # Normalizar probabilidades\n",
    "        combined_prob_maps = prob_maps1 / (prob_maps1.sum(dim=0, keepdim=True) + 1e-6)\n",
    "        \n",
    "        # Convertir a numpy\n",
    "        prob_maps_np = combined_prob_maps.cpu().numpy()\n",
    "        prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))\n",
    "        \n",
    "        # Generar segmentación semántica (clases 0, 1, 2)\n",
    "        segmentation = np.argmax(prob_maps_np, axis=0)\n",
    "        segmentation_np = segmentation.astype(np.int16)\n",
    "        \n",
    "        # Mapear segmentación a valores originales (0, 6, 2)\n",
    "        segmentation_np_orig = np.zeros_like(segmentation_np, dtype=np.int16)\n",
    "        segmentation_np_orig[segmentation_np == 1] = 6  # Vasogénico\n",
    "        segmentation_np_orig[segmentation_np == 2] = 2  # Infiltrado\n",
    "\n",
    "        # =================================================================================\n",
    "        # INICIO: BLOQUE DE CÁLCULO Y ALMACENAMIENTO DE MÉTRICAS\n",
    "        # =================================================================================\n",
    "\n",
    "        # --- Métricas Voxel-wise ---\n",
    "        dice, sensitivity, precision, auc, accuracy, f1 = calculate_metrics(segmentation_np, labels_metrics, prob_maps=prob_maps_np)\n",
    "        \n",
    "        for cls in range(3):\n",
    "            all_dice[cls].append(dice[cls])\n",
    "            all_sensitivity[cls].append(sensitivity[cls])\n",
    "            all_precision[cls].append(precision[cls])\n",
    "            all_auc[cls].append(auc[cls])\n",
    "            all_f1[cls].append(f1[cls])\n",
    "        all_accuracy.append(accuracy)\n",
    "\n",
    "        # Análisis espacial voxel-wise para la clase Infiltrado (Clase 2)\n",
    "        infiltrado_pred_voxel = (segmentation_np == 2).astype(np.uint8)\n",
    "        infiltrado_true_voxel = (labels_metrics == 2).astype(np.uint8)\n",
    "        pred_center_voxel = np.mean(np.where(infiltrado_pred_voxel), axis=1) if np.sum(infiltrado_pred_voxel) > 0 else np.array([np.nan, np.nan, np.nan])\n",
    "        true_center_voxel = np.mean(np.where(infiltrado_true_voxel), axis=1) if np.sum(infiltrado_true_voxel) > 0 else np.array([np.nan, np.nan, np.nan])\n",
    "        distance_voxel = np.linalg.norm(pred_center_voxel - true_center_voxel) if not np.any(np.isnan(pred_center_voxel)) and not np.any(np.isnan(true_center_voxel)) else np.nan\n",
    "        all_center_distance_voxel.append(distance_voxel)\n",
    "\n",
    "        # Guardar curva ROC individual (voxel-wise)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for cls in range(3):\n",
    "            true_cls = (labels_metrics == cls).flatten()\n",
    "            prob_cls = prob_maps_np[cls].flatten()\n",
    "            fpr, tpr, _ = roc_curve(true_cls, prob_cls)\n",
    "            auc_value = auc[cls]\n",
    "            all_fpr[cls].append(fpr)\n",
    "            all_tpr[cls].append(tpr)\n",
    "            plt.plot(fpr, tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('Tasa de Falsos Positivos (FPR)'); plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "        plt.title(f'Curva ROC Voxel-wise - Caso {idx}'); plt.legend(loc=\"lower right\")\n",
    "        roc_output_path = os.path.join(output_dir, f\"roc_curve_voxel_case_{idx}.png\")\n",
    "        plt.savefig(roc_output_path)\n",
    "        plt.close()\n",
    "\n",
    "        # --- Métricas Cube-wise ---\n",
    "        pred_cube_labels, pred_cube_probs = get_cube_labels(segmentation_np, cube_size)\n",
    "        true_cube_labels, _ = get_cube_labels(labels_metrics, cube_size)\n",
    "        \n",
    "        dice_cube, sens_cube, prec_cube, auc_cube, acc_cube, f1_cube = calculate_metrics(\n",
    "            pred_cube_labels, true_cube_labels, prob_maps=pred_cube_probs\n",
    "        )\n",
    "        \n",
    "        for cls in range(3):\n",
    "            all_dice_cube[cls].append(dice_cube[cls])\n",
    "            all_sensitivity_cube[cls].append(sens_cube[cls])\n",
    "            all_precision_cube[cls].append(prec_cube[cls])\n",
    "            all_auc_cube[cls].append(auc_cube[cls])\n",
    "            all_f1_cube[cls].append(f1_cube[cls])\n",
    "        all_accuracy_cube.append(acc_cube)\n",
    "\n",
    "        # Guardar curva ROC individual (cube-wise)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        for cls in range(3):\n",
    "            true_cls_cube = (true_cube_labels == cls).flatten()\n",
    "            prob_cls_cube = pred_cube_probs[cls].flatten()\n",
    "            fpr_cube, tpr_cube, _ = roc_curve(true_cls_cube, prob_cls_cube)\n",
    "            auc_value_cube = auc_cube[cls]\n",
    "            all_fpr_cube[cls].append(fpr_cube)\n",
    "            all_tpr_cube[cls].append(tpr_cube)\n",
    "            plt.plot(fpr_cube, tpr_cube, color=colors[cls], label=f'{class_names[cls]} (AUC = {auc_value_cube:.4f})')\n",
    "        plt.plot([0, 1], [0, 1], 'k--')\n",
    "        plt.xlabel('Tasa de Falsos Positivos (FPR)'); plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "        plt.title(f'Curva ROC Cube-wise - Caso {idx}'); plt.legend(loc=\"lower right\")\n",
    "        roc_cube_output_path = os.path.join(output_dir, f\"roc_curve_cube_case_{idx}.png\")\n",
    "        plt.savefig(roc_cube_output_path)\n",
    "        plt.close()\n",
    "\n",
    "        # Análisis espacial cube-wise para la clase Infiltrado (Clase 2)\n",
    "        infiltrado_pred_cube = (pred_cube_labels == 2).astype(np.uint8)\n",
    "        infiltrado_true_cube = (true_cube_labels == 2).astype(np.uint8)\n",
    "        pred_center_cube = np.mean(np.where(infiltrado_pred_cube), axis=1) if np.sum(infiltrado_pred_cube) > 0 else np.array([np.nan, np.nan, np.nan])\n",
    "        true_center_cube = np.mean(np.where(infiltrado_true_cube), axis=1) if np.sum(infiltrado_true_cube) > 0 else np.array([np.nan, np.nan, np.nan])\n",
    "        distance_cube = np.linalg.norm(pred_center_cube - true_center_cube) if not np.any(np.isnan(pred_center_cube)) and not np.any(np.isnan(true_center_cube)) else np.nan\n",
    "        all_center_distance.append(distance_cube)\n",
    "        \n",
    "        print(f\"--- Resultados para Caso {idx} ---\")\n",
    "        print(f\"Voxel-wise - Dice: {dice}, Accuracy: {accuracy:.4f}, Distancia Centros (Infiltrado): {distance_voxel:.4f}\")\n",
    "        print(f\"Cube-wise  - Dice: {dice_cube}, Accuracy: {acc_cube:.4f}, Distancia Centros (Infiltrado): {distance_cube:.4f}\")\n",
    "\n",
    "        # =================================================================================\n",
    "        # FIN: BLOQUE DE CÁLCULO Y ALMACENAMIENTO DE MÉTRICAS\n",
    "        # =================================================================================\n",
    "        \n",
    "        # --- Guardado de Archivos NIfTI ---\n",
    "        # Guardar imágenes MRI\n",
    "        image_np = image.squeeze(0).cpu().numpy()\n",
    "        for channel in range(image_np.shape[0]):\n",
    "            nib.save(nib.Nifti1Image(image_np[channel], affine), os.path.join(nifti_output_dir, f\"case_{idx}_modality_{channel}.nii.gz\"))\n",
    "        \n",
    "        # Guardar recurrencia, etiquetas, mapas de probabilidad y segmentación\n",
    "        nib.save(nib.Nifti1Image(recurrence_np, affine), os.path.join(nifti_output_dir, f\"case_{idx}_recurrence.nii.gz\"))\n",
    "        nib.save(nib.Nifti1Image(labels_np, affine), os.path.join(nifti_output_dir, f\"labels_case_{idx}.nii.gz\"))\n",
    "        nib.save(nib.Nifti1Image(prob_maps_np_nifti, affine), os.path.join(probs_output_dir, f\"probability_maps_case_{idx}.nii.gz\"))\n",
    "        nib.save(nib.Nifti1Image(segmentation_np_orig, affine), os.path.join(nifti_output_dir, f\"segmentation_case_{idx}.nii.gz\"))\n",
    "        \n",
    "        print(f\"Archivos NIfTI para caso {idx} guardados en {nifti_output_dir} y {probs_output_dir}\")\n",
    "        \n",
    "        monai.utils.set_determinism(seed=None)\n",
    "\n",
    "# Remover hook\n",
    "hook_handle_decoder1.remove()\n",
    "\n",
    "\n",
    "# =================================================================================\n",
    "# INICIO: ANÁLISIS FINAL Y GUARDADO DE RESULTADOS AGREGADOS\n",
    "# =================================================================================\n",
    "\n",
    "print(\"\\n--- Resultados Finales Agregados ---\")\n",
    "\n",
    "# --- Resultados Voxel-wise ---\n",
    "print(\"\\nResultados Voxel-wise:\")\n",
    "for cls in range(3):\n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice:       {np.nanmean(all_dice[cls]):.4f} ± {np.nanstd(all_dice[cls]):.4f}\")\n",
    "    print(f\"  Sensibilidad: {np.nanmean(all_sensitivity[cls]):.4f} ± {np.nanstd(all_sensitivity[cls]):.4f}\")\n",
    "    print(f\"  Precisión:    {np.nanmean(all_precision[cls]):.4f} ± {np.nanstd(all_precision[cls]):.4f}\")\n",
    "    print(f\"  AUC-ROC:      {np.nanmean(all_auc[cls]):.4f} ± {np.nanstd(all_auc[cls]):.4f}\")\n",
    "    print(f\"  F1 Score:     {np.nanmean(all_f1[cls]):.4f} ± {np.nanstd(all_f1[cls]):.4f}\")\n",
    "\n",
    "print(f\"\\nAccuracy Global (Voxel): {np.nanmean(all_accuracy):.4f} ± {np.nanstd(all_accuracy):.4f}\")\n",
    "print(f\"Distancia Centros (Voxel, Infiltrado): {np.nanmean(all_center_distance_voxel):.4f} ± {np.nanstd(all_center_distance_voxel):.4f}\")\n",
    "\n",
    "# Curva ROC Promedio (Voxel-wise)\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "for cls in range(3):\n",
    "    tprs = [np.interp(mean_fpr, fpr, tpr) for fpr, tpr in zip(all_fpr[cls], all_tpr[cls])]\n",
    "    mean_tpr = np.mean(tprs, axis=0)\n",
    "    mean_tpr[0], mean_tpr[-1] = 0.0, 1.0\n",
    "    mean_auc = np.nanmean(all_auc[cls])\n",
    "    plt.plot(mean_fpr, mean_tpr, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--'); plt.xlabel('Tasa de Falsos Positivos (FPR)'); plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC Promedio Voxel-wise'); plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join(output_dir, \"roc_curve_average_voxel.png\"))\n",
    "plt.close()\n",
    "\n",
    "# --- Resultados Cube-wise ---\n",
    "print(f\"\\nResultados Cube-wise (tamaño de cubo: {cube_size}):\")\n",
    "for cls in range(3):\n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice:       {np.nanmean(all_dice_cube[cls]):.4f} ± {np.nanstd(all_dice_cube[cls]):.4f}\")\n",
    "    print(f\"  Sensibilidad: {np.nanmean(all_sensitivity_cube[cls]):.4f} ± {np.nanstd(all_sensitivity_cube[cls]):.4f}\")\n",
    "    print(f\"  Precisión:    {np.nanmean(all_precision_cube[cls]):.4f} ± {np.nanstd(all_precision_cube[cls]):.4f}\")\n",
    "    print(f\"  AUC-ROC:      {np.nanmean(all_auc_cube[cls]):.4f} ± {np.nanstd(all_auc_cube[cls]):.4f}\")\n",
    "    print(f\"  F1 Score:     {np.nanmean(all_f1_cube[cls]):.4f} ± {np.nanstd(all_f1_cube[cls]):.4f}\")\n",
    "    \n",
    "print(f\"\\nAccuracy Global (Cube): {np.nanmean(all_accuracy_cube):.4f} ± {np.nanstd(all_accuracy_cube):.4f}\")\n",
    "print(f\"Distancia Centros (Cube, Infiltrado): {np.nanmean(all_center_distance):.4f} ± {np.nanstd(all_center_distance):.4f}\")\n",
    "\n",
    "# Curva ROC Promedio (Cube-wise)\n",
    "plt.figure(figsize=(8, 6))\n",
    "mean_fpr_cube = np.linspace(0, 1, 100)\n",
    "for cls in range(3):\n",
    "    tprs_cube = [np.interp(mean_fpr_cube, fpr, tpr) for fpr, tpr in zip(all_fpr_cube[cls], all_tpr_cube[cls])]\n",
    "    mean_tpr_cube = np.mean(tprs_cube, axis=0)\n",
    "    mean_tpr_cube[0], mean_tpr_cube[-1] = 0.0, 1.0\n",
    "    mean_auc_cube = np.nanmean(all_auc_cube[cls])\n",
    "    plt.plot(mean_fpr_cube, mean_tpr_cube, color=colors[cls], label=f'{class_names[cls]} (AUC = {mean_auc_cube:.4f})')\n",
    "plt.plot([0, 1], [0, 1], 'k--'); plt.xlabel('Tasa de Falsos Positivos (FPR)'); plt.ylabel('Tasa de Verdaderos Positivos (TPR)')\n",
    "plt.title('Curva ROC Promedio Cube-wise'); plt.legend(loc=\"lower right\")\n",
    "plt.savefig(os.path.join(output_dir, \"roc_curve_average_cube.png\"))\n",
    "plt.close()\n",
    "\n",
    "print(f\"\\nAnálisis completo. Los resultados y gráficos se han guardado en: {output_dir}\")\n",
    "\n",
    "# =================================================================================\n",
    "# FIN: ANÁLISIS FINAL Y GUARDADO DE RESULTADOS AGREGADOS\n",
    "# ================================================================================="
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
