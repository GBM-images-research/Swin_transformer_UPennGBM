{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Carpetas encontradas: ['00134', '00045', '00352', '00307', '00128', '00285', '00084', '00055', '00129', '00353', '00086']\n",
      "Subset 00134 - infiltracion:\n",
      "  Dice: 0.4050, Precision: 0.4155, Sensitivity: 0.3951, Accuracy: 0.9996\n",
      "Subset 00134 - edema:\n",
      "  Dice: 0.6936, Precision: 0.9145, Sensitivity: 0.5587, Accuracy: 0.9987\n",
      "Subset 00045 - infiltracion:\n",
      "  Dice: 0.5034, Precision: 0.3579, Sensitivity: 0.8483, Accuracy: 0.9989\n",
      "Subset 00045 - edema:\n",
      "  Dice: 0.7049, Precision: 0.8729, Sensitivity: 0.5912, Accuracy: 0.9983\n",
      "Subset 00352 - infiltracion:\n",
      "  Dice: 0.2831, Precision: 0.1833, Sensitivity: 0.6214, Accuracy: 0.9991\n",
      "Subset 00352 - edema:\n",
      "  Dice: 0.5255, Precision: 0.7807, Sensitivity: 0.3960, Accuracy: 0.9985\n",
      "Subset 00307 - infiltracion:\n",
      "  Dice: 0.6184, Precision: 0.6894, Sensitivity: 0.5607, Accuracy: 0.9998\n",
      "Subset 00307 - edema:\n",
      "  Dice: 0.5701, Precision: 0.7719, Sensitivity: 0.4519, Accuracy: 0.9993\n",
      "Subset 00128 - infiltracion:\n",
      "  Dice: 0.2130, Precision: 0.1736, Sensitivity: 0.2755, Accuracy: 0.9992\n",
      "Subset 00128 - edema:\n",
      "  Dice: 0.7588, Precision: 0.7808, Sensitivity: 0.7380, Accuracy: 0.9989\n",
      "Subset 00285 - infiltracion:\n",
      "  Dice: 0.4585, Precision: 0.4601, Sensitivity: 0.4568, Accuracy: 0.9994\n",
      "Subset 00285 - edema:\n",
      "  Dice: 0.7278, Precision: 0.7450, Sensitivity: 0.7115, Accuracy: 0.9989\n",
      "Subset 00084 - infiltracion:\n",
      "  Dice: 0.1446, Precision: 0.0892, Sensitivity: 0.3806, Accuracy: 0.9973\n",
      "Subset 00084 - edema:\n",
      "  Dice: 0.8309, Precision: 0.9512, Sensitivity: 0.7376, Accuracy: 0.9953\n",
      "Subset 00055 - infiltracion:\n",
      "  Dice: 0.6598, Precision: 0.7484, Sensitivity: 0.5900, Accuracy: 0.9987\n",
      "Subset 00055 - edema:\n",
      "  Dice: 0.7228, Precision: 0.6734, Sensitivity: 0.7800, Accuracy: 0.9985\n",
      "Subset 00129 - infiltracion:\n",
      "  Dice: 0.0545, Precision: 0.0288, Sensitivity: 0.5118, Accuracy: 0.9982\n",
      "Subset 00129 - edema:\n",
      "  Dice: 0.6629, Precision: 0.7823, Sensitivity: 0.5752, Accuracy: 0.9954\n",
      "Subset 00353 - infiltracion:\n",
      "  Dice: 0.5460, Precision: 0.7001, Sensitivity: 0.4475, Accuracy: 0.9972\n",
      "Subset 00353 - edema:\n",
      "  Dice: 0.7055, Precision: 0.7020, Sensitivity: 0.7090, Accuracy: 0.9969\n",
      "Subset 00086 - infiltracion:\n",
      "  Dice: 0.4092, Precision: 0.4887, Sensitivity: 0.3520, Accuracy: 0.9980\n",
      "Subset 00086 - edema:\n",
      "  Dice: 0.8129, Precision: 0.9116, Sensitivity: 0.7335, Accuracy: 0.9964\n",
      "\n",
      "===== MÉTRICAS GLOBALES =====\n",
      "\n",
      "Métricas para GT(6) vs Segm(4):\n",
      "  Dice: Media = 0.3905, Std = 0.1866\n",
      "  Precision: Media = 0.3941, Std = 0.2414\n",
      "  Sensitivity: Media = 0.4945, Std = 0.1507\n",
      "  Accuracy: Media = 0.9987, Std = 0.0008\n",
      "\n",
      "Métricas para GT(2) vs Segm(1):\n",
      "  Dice: Media = 0.7014, Std = 0.0871\n",
      "  Precision: Media = 0.8078, Std = 0.0872\n",
      "  Sensitivity: Media = 0.6348, Std = 0.1225\n",
      "  Accuracy: Media = 0.9977, Std = 0.0014\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    return tp / (tp + fp + 1e-6)\n",
    "\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))\n",
    "    return tp / (tp + fn + 1e-6)\n",
    "\n",
    "def accuracy(y_true, y_pred):\n",
    "    tp_tn = np.sum(y_true == y_pred)\n",
    "    return tp_tn / y_true.size\n",
    "\n",
    "def get_metrics(dataset, subset):\n",
    "    GT_path = f\"{dataset}/{subset}/UPENN-GBM-{subset}_11_combined2_approx_segm.nii.gz\"\n",
    "    Segm_path = f\"{dataset}/{subset}/{subset}segmentation.nii.gz\"\n",
    "\n",
    "    # Cargar las imágenes\n",
    "    GT_img = nib.load(GT_path).get_fdata()\n",
    "    Segm_img = nib.load(Segm_path).get_fdata()\n",
    "    GT_img = np.round(GT_img).astype(np.uint8)\n",
    "    Segm_img = Segm_img.astype(np.uint8) \n",
    "\n",
    "    # Definir las etiquetas a evaluar\n",
    "    labels = [(6, 4), (2, 1)]\n",
    "    names= [\"infiltracion\", \"edema\"]\n",
    "\n",
    "    metrics_per_label = {label: {\"Dice\": [], \"Precision\": [], \"Sensitivity\": [], \"Accuracy\": []} for label in labels}\n",
    "    i=0\n",
    "    for gt_label, segm_label in labels:\n",
    "        y_true = (GT_img == gt_label).astype(np.uint8)\n",
    "        y_pred = (Segm_img == segm_label).astype(np.uint8)\n",
    "\n",
    "        dice = dice_coefficient(y_true, y_pred)\n",
    "        prec = precision(y_true, y_pred)\n",
    "        sens = sensitivity(y_true, y_pred)\n",
    "        acc = accuracy(y_true, y_pred)\n",
    "\n",
    "        metrics_per_label[(gt_label, segm_label)][\"Dice\"].append(dice)\n",
    "        metrics_per_label[(gt_label, segm_label)][\"Precision\"].append(prec)\n",
    "        metrics_per_label[(gt_label, segm_label)][\"Sensitivity\"].append(sens)\n",
    "        metrics_per_label[(gt_label, segm_label)][\"Accuracy\"].append(acc)\n",
    "\n",
    "        print(f\"Subset {subset} - {names[i]}:\")\n",
    "        print(f\"  Dice: {dice:.4f}, Precision: {prec:.4f}, Sensitivity: {sens:.4f}, Accuracy: {acc:.4f}\")\n",
    "        i+=1\n",
    "\n",
    "    return metrics_per_label\n",
    "\n",
    "# Dataset y subsets\n",
    "dataset = \"./trained_models/segmentations_scale_GT\"\n",
    "# subsets = ['00045', \"00055\", \"00084\", \"00086\", \"00128\", ]\n",
    "# Obtener todas las carpetas dentro del dataset\n",
    "subsets = [folder for folder in os.listdir(dataset) if os.path.isdir(os.path.join(dataset, folder))]\n",
    "print(\"Carpetas encontradas:\", subsets)\n",
    "\n",
    "# Estructura para acumular todas las métricas\n",
    "all_metrics = {label: {\"Dice\": [], \"Precision\": [], \"Sensitivity\": [], \"Accuracy\": []} for label in [(6, 4), (2, 1)]}\n",
    "\n",
    "# Obtener métricas para cada subset\n",
    "for s in subsets:\n",
    "    subset_metrics = get_metrics(dataset, s)\n",
    "    for label in all_metrics.keys():\n",
    "        for metric in all_metrics[label]:\n",
    "            all_metrics[label][metric].extend(subset_metrics[label][metric])\n",
    "\n",
    "# Calcular promedio y desviación estándar por etiqueta\n",
    "print(\"\\n===== MÉTRICAS GLOBALES =====\")\n",
    "for label in all_metrics:\n",
    "    print(f\"\\nMétricas para GT({label[0]}) vs Segm({label[1]}):\")\n",
    "    for metric, values in all_metrics[label].items():\n",
    "        mean_val = np.mean(values)\n",
    "        std_val = np.std(values)\n",
    "        print(f\"  {metric}: Media = {mean_val:.4f}, Std = {std_val:.4f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subset 00045 - GT(6) vs Segm(4):\n",
      "  Dice: 0.5034, IoU: 0.3363, Precision: 0.3579, Sensitivity: 0.8483, ,Balanced Accuracy: 0.4241\n",
      "Subset 00045 - GT(2) vs Segm(1):\n",
      "  Dice: 0.7049, IoU: 0.5443, Precision: 0.8729, Sensitivity: 0.5912, ,Balanced Accuracy: 0.2956\n",
      "Subset 00055 - GT(6) vs Segm(4):\n",
      "  Dice: 0.6598, IoU: 0.4923, Precision: 0.7484, Sensitivity: 0.5900, ,Balanced Accuracy: 0.2950\n",
      "Subset 00055 - GT(2) vs Segm(1):\n",
      "  Dice: 0.7228, IoU: 0.5659, Precision: 0.6734, Sensitivity: 0.7800, ,Balanced Accuracy: 0.3900\n",
      "Subset 00084 - GT(6) vs Segm(4):\n",
      "  Dice: 0.1446, IoU: 0.0779, Precision: 0.0892, Sensitivity: 0.3806, ,Balanced Accuracy: 0.1903\n",
      "Subset 00084 - GT(2) vs Segm(1):\n",
      "  Dice: 0.8309, IoU: 0.7107, Precision: 0.9512, Sensitivity: 0.7376, ,Balanced Accuracy: 0.3688\n",
      "Subset 00086 - GT(6) vs Segm(4):\n",
      "  Dice: 0.4092, IoU: 0.2573, Precision: 0.4887, Sensitivity: 0.3520, ,Balanced Accuracy: 0.1760\n",
      "Subset 00086 - GT(2) vs Segm(1):\n",
      "  Dice: 0.8129, IoU: 0.6848, Precision: 0.9116, Sensitivity: 0.7335, ,Balanced Accuracy: 0.3668\n",
      "Subset 00128 - GT(6) vs Segm(4):\n",
      "  Dice: 0.2130, IoU: 0.1192, Precision: 0.1736, Sensitivity: 0.2755, ,Balanced Accuracy: 0.1377\n",
      "Subset 00128 - GT(2) vs Segm(1):\n",
      "  Dice: 0.7588, IoU: 0.6114, Precision: 0.7808, Sensitivity: 0.7380, ,Balanced Accuracy: 0.3690\n",
      "Subset 00129 - GT(6) vs Segm(4):\n",
      "  Dice: 0.0545, IoU: 0.0280, Precision: 0.0288, Sensitivity: 0.5118, ,Balanced Accuracy: 0.2559\n",
      "Subset 00129 - GT(2) vs Segm(1):\n",
      "  Dice: 0.6629, IoU: 0.4958, Precision: 0.7823, Sensitivity: 0.5752, ,Balanced Accuracy: 0.2876\n",
      "Subset 00134 - GT(6) vs Segm(4):\n",
      "  Dice: 0.4050, IoU: 0.2539, Precision: 0.4155, Sensitivity: 0.3951, ,Balanced Accuracy: 0.1975\n",
      "Subset 00134 - GT(2) vs Segm(1):\n",
      "  Dice: 0.6936, IoU: 0.5309, Precision: 0.9145, Sensitivity: 0.5587, ,Balanced Accuracy: 0.2793\n",
      "Subset 00285 - GT(6) vs Segm(4):\n",
      "  Dice: 0.4585, IoU: 0.2974, Precision: 0.4601, Sensitivity: 0.4568, ,Balanced Accuracy: 0.2284\n",
      "Subset 00285 - GT(2) vs Segm(1):\n",
      "  Dice: 0.7278, IoU: 0.5721, Precision: 0.7450, Sensitivity: 0.7115, ,Balanced Accuracy: 0.3557\n",
      "Subset 00307 - GT(6) vs Segm(4):\n",
      "  Dice: 0.6184, IoU: 0.4476, Precision: 0.6894, Sensitivity: 0.5607, ,Balanced Accuracy: 0.2803\n",
      "Subset 00307 - GT(2) vs Segm(1):\n",
      "  Dice: 0.5701, IoU: 0.3987, Precision: 0.7719, Sensitivity: 0.4519, ,Balanced Accuracy: 0.2260\n",
      "Subset 00352 - GT(6) vs Segm(4):\n",
      "  Dice: 0.2831, IoU: 0.1649, Precision: 0.1833, Sensitivity: 0.6214, ,Balanced Accuracy: 0.3107\n",
      "Subset 00352 - GT(2) vs Segm(1):\n",
      "  Dice: 0.5255, IoU: 0.3564, Precision: 0.7807, Sensitivity: 0.3960, ,Balanced Accuracy: 0.1980\n",
      "Subset 00353 - GT(6) vs Segm(4):\n",
      "  Dice: 0.5460, IoU: 0.3755, Precision: 0.7001, Sensitivity: 0.4475, ,Balanced Accuracy: 0.2237\n",
      "Subset 00353 - GT(2) vs Segm(1):\n",
      "  Dice: 0.7055, IoU: 0.5450, Precision: 0.7020, Sensitivity: 0.7090, ,Balanced Accuracy: 0.3545\n",
      "\n",
      "🔹 Promedios y Desviaciones Estándar por métrica y etiqueta:\n",
      "\n",
      "🔹 GT(6) vs Segm(4):\n",
      "  Dice: 0.3905 ± 0.1866\n",
      "  IoU: 0.2591 ± 0.1432\n",
      "  Precision: 0.3941 ± 0.2414\n",
      "  Sensitivity: 0.4945 ± 0.1507\n",
      "  Balanced Accuracy: 0.2473 ± 0.0753\n",
      "\n",
      "🔹 GT(2) vs Segm(1):\n",
      "  Dice: 0.7014 ± 0.0871\n",
      "  IoU: 0.5469 ± 0.1010\n",
      "  Precision: 0.8078 ± 0.0872\n",
      "  Sensitivity: 0.6348 ± 0.1225\n",
      "  Balanced Accuracy: 0.3174 ± 0.0613\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# 🔹 Función para calcular el coeficiente Dice\n",
    "def dice_coefficient(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    return (2. * intersection) / (np.sum(y_true) + np.sum(y_pred) + 1e-6)\n",
    "\n",
    "# 🔹 Función para calcular IoU (Intersection over Union)\n",
    "def iou(y_true, y_pred):\n",
    "    intersection = np.sum(y_true * y_pred)\n",
    "    union = np.sum(y_true) + np.sum(y_pred) - intersection\n",
    "    return intersection / (union + 1e-6)\n",
    "\n",
    "# 🔹 Función para calcular precisión\n",
    "def precision(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fp = np.sum((1 - y_true) * y_pred)\n",
    "    return tp / (tp + fp + 1e-6)\n",
    "\n",
    "# 🔹 Función para calcular sensibilidad (Recall)\n",
    "def sensitivity(y_true, y_pred):\n",
    "    tp = np.sum(y_true * y_pred)\n",
    "    fn = np.sum(y_true * (1 - y_pred))\n",
    "    return tp / (tp + fn + 1e-6)\n",
    "\n",
    "# 🔹 Función para calcular Balanced Accuracy (Accuracy por clase, excluyendo fondo)\n",
    "def balanced_accuracy(y_true, y_pred):\n",
    "    recalls = []\n",
    "    specificities = []\n",
    "    unique_labels = np.unique(y_true)\n",
    "    \n",
    "    for label in unique_labels:\n",
    "        if label == 0: continue  # Ignorar fondo\n",
    "        \n",
    "        y_true_bin = (y_true == label).astype(np.uint8)\n",
    "        y_pred_bin = (y_pred == label).astype(np.uint8)\n",
    "\n",
    "        tp = np.sum(y_true_bin * y_pred_bin)\n",
    "        fn = np.sum(y_true_bin * (1 - y_pred_bin))\n",
    "        tn = np.sum((1 - y_true_bin) * (1 - y_pred_bin))\n",
    "        fp = np.sum((1 - y_true_bin) * y_pred_bin)\n",
    "\n",
    "        recall = tp / (tp + fn + 1e-6)\n",
    "        specificity = tn / (tn + fp + 1e-6)\n",
    "        \n",
    "        recalls.append(recall)\n",
    "        specificities.append(specificity)\n",
    "\n",
    "    return np.mean(recalls), np.mean(specificities)  # Retorna ambas métricas\n",
    "\n",
    "\n",
    "# 🔹 Función para calcular métricas\n",
    "def get_metrics(dataset, subset):\n",
    "    GT_path = f\"{dataset}/{subset}/UPENN-GBM-{subset}_11_combined2_approx_segm.nii.gz\"\n",
    "    Segm_path = f\"{dataset}/{subset}/{subset}segmentation.nii.gz\"\n",
    "\n",
    "    # Cargar las imágenes\n",
    "    GT_img = nib.load(GT_path).get_fdata()\n",
    "    Segm_img = nib.load(Segm_path).get_fdata()\n",
    "    GT_img = np.round(GT_img).astype(np.uint8)\n",
    "    Segm_img = Segm_img.astype(np.uint8) \n",
    "\n",
    "    # Definir las etiquetas a evaluar\n",
    "    labels = [(6, 4), (2, 1)]\n",
    "    metrics_results = []\n",
    "\n",
    "    for gt_label, segm_label in labels:\n",
    "        y_true = (GT_img == gt_label).astype(np.uint8)\n",
    "        y_pred = (Segm_img == segm_label).astype(np.uint8)\n",
    "\n",
    "        dice = dice_coefficient(y_true, y_pred)\n",
    "        iou_value = iou(y_true, y_pred)\n",
    "        prec = precision(y_true, y_pred)\n",
    "        sens = sensitivity(y_true, y_pred)\n",
    "        # sensi, spec = balanced_accuracy(y_true, y_pred)\n",
    "        # bal_acc = (sensi + spec) / 2  # Balanced Accuracy real\n",
    "\n",
    "        # Máscara que excluye el fondo\n",
    "        foreground_mask = (y_true > 0) | (y_pred > 0)\n",
    "\n",
    "        # Aplicar la máscara\n",
    "        fp = np.sum((y_true == 0) & (y_pred == 1) & foreground_mask)\n",
    "        tn = np.sum((y_true == 0) & (y_pred == 0) & foreground_mask)\n",
    "\n",
    "        # Evitar división por cero\n",
    "        spec= tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "        bal_acc = (sens + spec) / 2\n",
    "\n",
    "        metrics_results.append([dice, iou_value, prec, sens, bal_acc])\n",
    "\n",
    "        print(f\"Subset {subset} - GT({gt_label}) vs Segm({segm_label}):\")\n",
    "        print(f\"  Dice: {dice:.4f}, IoU: {iou_value:.4f}, Precision: {prec:.4f}, Sensitivity: {sens:.4f}, ,Balanced Accuracy: {bal_acc:.4f}\")\n",
    "\n",
    "    return np.array(metrics_results)\n",
    "\n",
    "\n",
    "# 🔹 Obtener todas las carpetas dentro del dataset\n",
    "dataset = \"./trained_models/segmentations_scale_GT\"\n",
    "subsets = sorted([d for d in os.listdir(dataset) if os.path.isdir(os.path.join(dataset, d))])\n",
    "\n",
    "# 🔹 Almacenar métricas para calcular promedios y desviaciones estándar\n",
    "all_metrics = []\n",
    "\n",
    "for s in subsets:\n",
    "    metrics = get_metrics(dataset, s)\n",
    "    all_metrics.append(metrics)\n",
    "\n",
    "# 🔹 Convertir a numpy para cálculos estadísticos\n",
    "all_metrics = np.array(all_metrics)  # Dimensión: (N_subsets, N_labels, N_métricas)\n",
    "\n",
    "# 🔹 Calcular promedio y desviación estándar por métrica y etiqueta\n",
    "metric_names = [\"Dice\", \"IoU\", \"Precision\", \"Sensitivity\", \"Balanced Accuracy\"]\n",
    "\n",
    "print(\"\\n🔹 Promedios y Desviaciones Estándar por métrica y etiqueta:\\n\")\n",
    "for i, (gt_label, segm_label) in enumerate([(6, 4), (2, 1)]):\n",
    "    print(f\"🔹 GT({gt_label}) vs Segm({segm_label}):\")\n",
    "    for j, metric_name in enumerate(metric_names):\n",
    "        mean_val = np.mean(all_metrics[:, i, j])\n",
    "        std_val = np.std(all_metrics[:, i, j])\n",
    "        print(f\"  {metric_name}: {mean_val:.4f} ± {std_val:.4f}\")\n",
    "    print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
