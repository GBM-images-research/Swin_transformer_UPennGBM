{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading functions\n",
    "import os\n",
    "import time\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "\n",
    "from src.get_data import CustomDataset, CustomDatasetSeg\n",
    "import numpy as np\n",
    "from scipy import ndimage\n",
    "from types import SimpleNamespace\n",
    "import wandb\n",
    "import logging\n",
    "\n",
    "#####\n",
    "import json\n",
    "import shutil\n",
    "import tempfile\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "\n",
    "from monai.losses import DiceLoss\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    "    MapTransform,\n",
    "    Transform,\n",
    ")\n",
    "\n",
    "from monai.config import print_config\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.utils.enums import MetricReduction\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from monai import data\n",
    "\n",
    "# from monai.data import decollate_batch\n",
    "from functools import partial\n",
    "from src.custom_transforms import ConvertToMultiChannelBasedOnN_Froi, ConvertToMultiChannelBasedOnAnotatedInfiltration, masked, ConvertToMultiChannelBasedOnBratsClassesdI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transformaciones Swin UNETR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/training2/miniconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:321: FutureWarning: monai.transforms.croppad.dictionary CropForegroundd.__init__:allow_smaller: Current default value of argument `allow_smaller=True` has been deprecated since version 1.2. It will be changed to `allow_smaller=False` in version 1.5.\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "roi = (128, 128, 128) # (220, 220, 155) (128, 128, 64)\n",
    "source_k=\"label\"\n",
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # ConvertToMultiChannelBasedOnN_Froi(keys=\"label\"),\n",
    "        # masked(keys=\"image\"),\n",
    "        # ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.CropForegroundd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            source_key=source_k,\n",
    "            k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[roi[0], roi[1], roi[2]],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "        \n",
    "    ]\n",
    ")\n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]),\n",
    "        # ConvertToMultiChannelBasedOnN_Froi(keys=\"label\"),\n",
    "        # masked(keys=\"image\"),\n",
    "        # ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        ConvertToMultiChannelBasedOnBratsClassesdI(keys=\"label\"),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[-1, -1, -1], #[224, 224, 128],\n",
    "            random_size=False,\n",
    "        ),\n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/training2/miniconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n",
      "/tmp/ipykernel_47415/1858418605.py:27: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(model_path, map_location=torch.device('cuda:0'))[\"state_dict\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SwinUNETR(\n",
       "  (swinViT): SwinTransformer(\n",
       "    (patch_embed): PatchEmbed(\n",
       "      (proj): Conv3d(11, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2))\n",
       "    )\n",
       "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
       "    (layers1): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=48, out_features=144, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=48, out_features=48, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((48,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=48, out_features=192, bias=True)\n",
       "              (linear2): Linear(in_features=192, out_features=48, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=384, out_features=96, bias=False)\n",
       "          (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers2): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=96, out_features=96, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=96, out_features=384, bias=True)\n",
       "              (linear2): Linear(in_features=384, out_features=96, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=768, out_features=192, bias=False)\n",
       "          (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers3): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=192, out_features=768, bias=True)\n",
       "              (linear2): Linear(in_features=768, out_features=192, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=1536, out_features=384, bias=False)\n",
       "          (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (layers4): ModuleList(\n",
       "      (0): BasicLayer(\n",
       "        (blocks): ModuleList(\n",
       "          (0-1): 2 x SwinTransformerBlock(\n",
       "            (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (attn): WindowAttention(\n",
       "              (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
       "              (attn_drop): Dropout(p=0.0, inplace=False)\n",
       "              (proj): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (proj_drop): Dropout(p=0.0, inplace=False)\n",
       "              (softmax): Softmax(dim=-1)\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): MLPBlock(\n",
       "              (linear1): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (linear2): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (fn): GELU(approximate='none')\n",
       "              (drop1): Dropout(p=0.0, inplace=False)\n",
       "              (drop2): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (downsample): PatchMerging(\n",
       "          (reduction): Linear(in_features=3072, out_features=768, bias=False)\n",
       "          (norm): LayerNorm((3072,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder1): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(11, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(11, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder2): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder3): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder4): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (encoder10): UnetrBasicBlock(\n",
       "    (layer): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(768, 768, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(768, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder5): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(768, 384, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(768, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(384, 384, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(768, 384, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(384, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder4): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(384, 192, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(384, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(192, 192, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(384, 192, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(192, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder3): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(192, 96, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(96, 96, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(192, 96, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(96, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder2): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(96, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (decoder1): UnetrUpBlock(\n",
       "    (transp_conv): Convolution(\n",
       "      (conv): ConvTranspose3d(48, 48, kernel_size=(2, 2, 2), stride=(2, 2, 2), bias=False)\n",
       "    )\n",
       "    (conv_block): UnetResBlock(\n",
       "      (conv1): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (conv2): Convolution(\n",
       "        (conv): Conv3d(48, 48, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (lrelu): LeakyReLU(negative_slope=0.01, inplace=True)\n",
       "      (norm1): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (norm2): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "      (conv3): Convolution(\n",
       "        (conv): Conv3d(96, 48, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
       "      )\n",
       "      (norm3): InstanceNorm3d(48, eps=1e-05, momentum=0.1, affine=False, track_running_stats=False)\n",
       "    )\n",
       "  )\n",
       "  (out): UnetOutBlock(\n",
       "    (conv): Convolution(\n",
       "      (conv): Conv3d(48, 2, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################\n",
    "# Crear el modelo\n",
    "######################\n",
    "\n",
    "### Hyperparameter\n",
    "roi = (128, 128, 128)  # (128, 128, 128)\n",
    "\n",
    "# Create Swin transformer\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=roi,\n",
    "    in_channels=11,\n",
    "    out_channels=2,  # mdificar con edema\n",
    "    feature_size=48, #48\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    use_checkpoint=True,\n",
    ")\n",
    "\n",
    "# Load the best model\n",
    "model_path = \"artifacts/o9kppyr5_best_model:v0/model.pt\"\n",
    "\n",
    "# Load the model on CPU\n",
    "loaded_model = torch.load(model_path, map_location=torch.device('cuda:0'))[\"state_dict\"]\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(loaded_model)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 36 images and 36 labels.\n"
     ]
    }
   ],
   "source": [
    "# Create dataset data loader\n",
    "dataset_path='./Dataset/Dataset_recurrence'\n",
    "train_set=CustomDataset(dataset_path, section=\"train\", transform=train_transform) # v_transform\n",
    "train_loader = DataLoader(train_set, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 0\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 1\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 2\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 3\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 4\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 5\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 6\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 7\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 8\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 9\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 10\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 11\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 12\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 13\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 14\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 15\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 16\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 17\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 18\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 19\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 20\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 21\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 22\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 23\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 24\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 25\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 26\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 27\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 28\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 29\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 30\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 31\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 32\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 33\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 34\n",
      "Image torch.Size([1, 11, 128, 128, 128])\n",
      "label before squeeze torch.Size([1, 2, 128, 128, 128])\n",
      "label (128, 128, 128)\n",
      "decoder_features: torch.Size([1, 48, 128, 128, 128])\n",
      "Guardado embeddings y etiquetas para caso 35\n"
     ]
    }
   ],
   "source": [
    "\n",
    "embedding_dir = \"Dataset/contrastive_voxel_wise/embeddings\"\n",
    "label_output_dir = \"Dataset/contrastive_voxel_wise/labels\"\n",
    "\n",
    "# Crear carpetas si no existen\n",
    "os.makedirs(embedding_dir, exist_ok=True)\n",
    "os.makedirs(label_output_dir, exist_ok=True)\n",
    "\n",
    "# Variable para las características del decoder\n",
    "decoder_features = None\n",
    "\n",
    "# Función hook\n",
    "def decoder_hook_fn(module, input, output):\n",
    "    global decoder_features\n",
    "    decoder_features = output\n",
    "\n",
    "# Registrar el hook en decoder1.conv_block\n",
    "hook_handle_decoder = model.decoder1.conv_block.register_forward_hook(decoder_hook_fn)\n",
    "\n",
    "# Extraer y guardar\n",
    "with torch.no_grad():\n",
    "    for idx, batch_data in enumerate(train_loader):\n",
    "        image, label = batch_data[\"image\"], batch_data[\"label\"]\n",
    "        print(\"Image\", image.shape)  # [1, 11, 128, 128, 128]\n",
    "        print(\"label before squeeze\", label.shape)  # [1, 2, 128, 128, 128]\n",
    "        \n",
    "        image = image.to(device)\n",
    "        label = label.squeeze(0)  # [2, 128, 128, 128]\n",
    "        \n",
    "        # Convertir one-hot a etiquetas únicas\n",
    "        label_sum = label.sum(dim=0)  # [128, 128, 128], suma de canales\n",
    "        label_class = torch.zeros_like(label_sum, dtype=torch.long)  # [128, 128, 128]\n",
    "        \n",
    "        # Asignar clases:\n",
    "        # - Fondo (0, 0) -> 0\n",
    "        # - Vasogénico (1, 0) -> 1\n",
    "        # - Infiltrado (0, 1) -> 2\n",
    "        label_class[label[1] == 1] = 2  # Infiltrado\n",
    "        label_class[(label[0] == 1) & (label[1] == 0)] = 1  # Vasogénico\n",
    "        # Donde label_sum == 0, ya es fondo (0)\n",
    "        \n",
    "        label = label_class.cpu().numpy()  # [128, 128, 128]\n",
    "        print(\"label\", label.shape)\n",
    "        \n",
    "        # Obtener embeddings\n",
    "        _ = model(image)  # Ejecuta el forward para activar el hook\n",
    "        \n",
    "        print(\"decoder_features:\", decoder_features.shape)  # [1, 48, 128, 128, 128]\n",
    "        \n",
    "        # Guardar embeddings y etiquetas\n",
    "        np.save(f\"{embedding_dir}/case_{idx}.npy\", decoder_features.cpu().numpy())\n",
    "        np.save(f\"{label_output_dir}/case_{idx}.npy\", label)\n",
    "        \n",
    "        print(f\"Guardado embeddings y etiquetas para caso {idx}\")\n",
    "\n",
    "# Remover el hook\n",
    "hook_handle_decoder.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar modelo contrastivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/training2/miniconda3/envs/monai_env/lib/python3.11/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embedding_dir, label_dir):\n",
    "        self.embedding_dir = embedding_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.case_files = [f for f in os.listdir(embedding_dir) if f.endswith(\".npy\")]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.case_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embedding_path = os.path.join(self.embedding_dir, f\"case_{idx}.npy\")\n",
    "        label_path = os.path.join(self.label_dir, f\"case_{idx}.npy\")\n",
    "        \n",
    "        embeddings = np.load(embedding_path)\n",
    "        labels = np.load(label_path)\n",
    "        \n",
    "        embeddings = torch.tensor(embeddings, dtype=torch.float32).squeeze(0)\n",
    "        labels = torch.tensor(labels, dtype=torch.long)\n",
    "        \n",
    "        return embeddings, labels\n",
    "\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim=128, output_dim=128):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "def contrastive_loss(z, labels, temperature=0.5, sample_size_per_class=1024):\n",
    "    N_total = z.shape[0]\n",
    "    z = F.normalize(z, dim=1)\n",
    "    \n",
    "    classes = torch.unique(labels)\n",
    "    if len(classes) < 2:\n",
    "        print(f\"Advertencia: Solo una clase presente ({classes.tolist()}), devolviendo pérdida 0\")\n",
    "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    sampled_z = []\n",
    "    sampled_labels = []\n",
    "    \n",
    "    for cls in classes:\n",
    "        cls_indices = (labels == cls).nonzero(as_tuple=True)[0]\n",
    "        cls_size = cls_indices.shape[0]\n",
    "        if cls_size > sample_size_per_class:\n",
    "            indices = torch.randperm(cls_size)[:sample_size_per_class]\n",
    "            cls_indices = cls_indices[indices]\n",
    "        sampled_z.append(z[cls_indices])\n",
    "        sampled_labels.append(labels[cls_indices])\n",
    "    \n",
    "    z = torch.cat(sampled_z, dim=0)\n",
    "    labels = torch.cat(sampled_labels, dim=0)\n",
    "    N = z.shape[0]\n",
    "    \n",
    "    # print(f\"Batch size: {N}, Unique labels: {torch.unique(labels).tolist()}\")\n",
    "    \n",
    "    if N < 2:\n",
    "        print(\"Advertencia: Batch con menos de 2 vóxeles, devolviendo pérdida 0\")\n",
    "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
    "    \n",
    "    similarity = torch.mm(z, z.T) / temperature\n",
    "    labels_eq = labels.unsqueeze(1) == labels.unsqueeze(0)\n",
    "    labels_eq = labels_eq.float()\n",
    "    eye = torch.eye(N, device=device)\n",
    "    labels_eq = labels_eq * (1 - eye)\n",
    "    \n",
    "    exp_sim = torch.exp(similarity)\n",
    "    pos_sum = (exp_sim * labels_eq).sum(dim=1)\n",
    "    neg_sum = exp_sim.sum(dim=1) - exp_sim.diag()\n",
    "    \n",
    "    if pos_sum.sum() == 0:\n",
    "        print(\"Advertencia: No hay pares positivos, pérdida será 0\")\n",
    "    \n",
    "    loss = -torch.log((pos_sum + 1e-6) / (neg_sum + 1e-6))\n",
    "    return loss.mean()\n",
    "\n",
    "# Configuración\n",
    "embedding_dir = \"Dataset/contrastive_voxel_wise/embeddings\"\n",
    "label_dir = \"Dataset/contrastive_voxel_wise/labels\"\n",
    "batch_size = 1\n",
    "sample_size_per_class = 3333\n",
    "temperature = 0.5\n",
    "num_epochs = 100\n",
    "patience = 10  # Early stopping\n",
    "\n",
    "dataset = EmbeddingDataset(embedding_dir, label_dir)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "model = ProjectionHead(input_dim=48).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Batch 0/36, Loss: 0.6511\n",
      "Epoch 1/100, Batch 5/36, Loss: 0.2624\n",
      "Epoch 1/100, Batch 10/36, Loss: 0.2433\n",
      "Epoch 1/100, Batch 15/36, Loss: 0.1702\n",
      "Epoch 1/100, Batch 20/36, Loss: 0.2916\n",
      "Epoch 1/100, Batch 25/36, Loss: 0.1715\n",
      "Epoch 1/100, Batch 30/36, Loss: 0.1910\n",
      "Epoch 1/100, Batch 35/36, Loss: 0.1688\n",
      "Epoch 1/100, Average Loss: 0.2436, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.2436\n",
      "Epoch 2/100, Batch 0/36, Loss: 0.2102\n",
      "Epoch 2/100, Batch 5/36, Loss: 0.1800\n",
      "Epoch 2/100, Batch 10/36, Loss: 0.1297\n",
      "Epoch 2/100, Batch 15/36, Loss: 0.2181\n",
      "Epoch 2/100, Batch 20/36, Loss: 0.2263\n",
      "Epoch 2/100, Batch 25/36, Loss: 0.1841\n",
      "Epoch 2/100, Batch 30/36, Loss: 0.1709\n",
      "Epoch 2/100, Batch 35/36, Loss: 0.1536\n",
      "Epoch 2/100, Average Loss: 0.1795, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1795\n",
      "Epoch 3/100, Batch 0/36, Loss: 0.1973\n",
      "Epoch 3/100, Batch 5/36, Loss: 0.1465\n",
      "Epoch 3/100, Batch 10/36, Loss: 0.1661\n",
      "Epoch 3/100, Batch 15/36, Loss: 0.1390\n",
      "Epoch 3/100, Batch 20/36, Loss: 0.1420\n",
      "Epoch 3/100, Batch 25/36, Loss: 0.2692\n",
      "Epoch 3/100, Batch 30/36, Loss: 0.1569\n",
      "Epoch 3/100, Batch 35/36, Loss: 0.1615\n",
      "Epoch 3/100, Average Loss: 0.1742, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1742\n",
      "Epoch 4/100, Batch 0/36, Loss: 0.1581\n",
      "Epoch 4/100, Batch 5/36, Loss: 0.1473\n",
      "Epoch 4/100, Batch 10/36, Loss: 0.1441\n",
      "Epoch 4/100, Batch 15/36, Loss: 0.1636\n",
      "Epoch 4/100, Batch 20/36, Loss: 0.1704\n",
      "Epoch 4/100, Batch 25/36, Loss: 0.1643\n",
      "Epoch 4/100, Batch 30/36, Loss: 0.2176\n",
      "Epoch 4/100, Batch 35/36, Loss: 0.1186\n",
      "Epoch 4/100, Average Loss: 0.1728, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1728\n",
      "Epoch 5/100, Batch 0/36, Loss: 0.1548\n",
      "Epoch 5/100, Batch 5/36, Loss: 0.1319\n",
      "Epoch 5/100, Batch 10/36, Loss: 0.1681\n",
      "Epoch 5/100, Batch 15/36, Loss: 0.1957\n",
      "Epoch 5/100, Batch 20/36, Loss: 0.1760\n",
      "Epoch 5/100, Batch 25/36, Loss: 0.1896\n",
      "Epoch 5/100, Batch 30/36, Loss: 0.1577\n",
      "Epoch 5/100, Batch 35/36, Loss: 0.1402\n",
      "Epoch 5/100, Average Loss: 0.1728, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 6/100, Batch 0/36, Loss: 0.2035\n",
      "Epoch 6/100, Batch 5/36, Loss: 0.1589\n",
      "Epoch 6/100, Batch 10/36, Loss: 0.1463\n",
      "Epoch 6/100, Batch 15/36, Loss: 0.2392\n",
      "Epoch 6/100, Batch 20/36, Loss: 0.1842\n",
      "Epoch 6/100, Batch 25/36, Loss: 0.0754\n",
      "Epoch 6/100, Batch 30/36, Loss: 0.1705\n",
      "Epoch 6/100, Batch 35/36, Loss: 0.1613\n",
      "Epoch 6/100, Average Loss: 0.1726, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1726\n",
      "Epoch 7/100, Batch 0/36, Loss: 0.1954\n",
      "Epoch 7/100, Batch 5/36, Loss: 0.1802\n",
      "Epoch 7/100, Batch 10/36, Loss: 0.2208\n",
      "Epoch 7/100, Batch 15/36, Loss: 0.1718\n",
      "Epoch 7/100, Batch 20/36, Loss: 0.1374\n",
      "Epoch 7/100, Batch 25/36, Loss: 0.1260\n",
      "Epoch 7/100, Batch 30/36, Loss: 0.1649\n",
      "Epoch 7/100, Batch 35/36, Loss: 0.1851\n",
      "Epoch 7/100, Average Loss: 0.1706, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1706\n",
      "Epoch 8/100, Batch 0/36, Loss: 0.1829\n",
      "Epoch 8/100, Batch 5/36, Loss: 0.1849\n",
      "Epoch 8/100, Batch 10/36, Loss: 0.1615\n",
      "Epoch 8/100, Batch 15/36, Loss: 0.1701\n",
      "Epoch 8/100, Batch 20/36, Loss: 0.1858\n",
      "Epoch 8/100, Batch 25/36, Loss: 0.1623\n",
      "Epoch 8/100, Batch 30/36, Loss: 0.1317\n",
      "Epoch 8/100, Batch 35/36, Loss: 0.1442\n",
      "Epoch 8/100, Average Loss: 0.1720, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 9/100, Batch 0/36, Loss: 0.1264\n",
      "Epoch 9/100, Batch 5/36, Loss: 0.1277\n",
      "Epoch 9/100, Batch 10/36, Loss: 0.1659\n",
      "Epoch 9/100, Batch 15/36, Loss: 0.1694\n",
      "Epoch 9/100, Batch 20/36, Loss: 0.1546\n",
      "Epoch 9/100, Batch 25/36, Loss: 0.1512\n",
      "Epoch 9/100, Batch 30/36, Loss: 0.2022\n",
      "Epoch 9/100, Batch 35/36, Loss: 0.1413\n",
      "Epoch 9/100, Average Loss: 0.1706, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 10/100, Batch 0/36, Loss: 0.2121\n",
      "Epoch 10/100, Batch 5/36, Loss: 0.1572\n",
      "Epoch 10/100, Batch 10/36, Loss: 0.1361\n",
      "Epoch 10/100, Batch 15/36, Loss: 0.1550\n",
      "Epoch 10/100, Batch 20/36, Loss: 0.2339\n",
      "Epoch 10/100, Batch 25/36, Loss: 0.1491\n",
      "Epoch 10/100, Batch 30/36, Loss: 0.1500\n",
      "Epoch 10/100, Batch 35/36, Loss: 0.1955\n",
      "Epoch 10/100, Average Loss: 0.1700, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1700\n",
      "Epoch 11/100, Batch 0/36, Loss: 0.1307\n",
      "Epoch 11/100, Batch 5/36, Loss: 0.2315\n",
      "Epoch 11/100, Batch 10/36, Loss: 0.1357\n",
      "Epoch 11/100, Batch 15/36, Loss: 0.1468\n",
      "Epoch 11/100, Batch 20/36, Loss: 0.0775\n",
      "Epoch 11/100, Batch 25/36, Loss: 0.1623\n",
      "Epoch 11/100, Batch 30/36, Loss: 0.1946\n",
      "Epoch 11/100, Batch 35/36, Loss: 0.2055\n",
      "Epoch 11/100, Average Loss: 0.1711, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 12/100, Batch 0/36, Loss: 0.1223\n",
      "Epoch 12/100, Batch 5/36, Loss: 0.1362\n",
      "Epoch 12/100, Batch 10/36, Loss: 0.1740\n",
      "Epoch 12/100, Batch 15/36, Loss: 0.2147\n",
      "Epoch 12/100, Batch 20/36, Loss: 0.1547\n",
      "Epoch 12/100, Batch 25/36, Loss: 0.1437\n",
      "Epoch 12/100, Batch 30/36, Loss: 0.2018\n",
      "Epoch 12/100, Batch 35/36, Loss: 0.1933\n",
      "Epoch 12/100, Average Loss: 0.1699, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1699\n",
      "Epoch 13/100, Batch 0/36, Loss: 0.1450\n",
      "Epoch 13/100, Batch 5/36, Loss: 0.2036\n",
      "Epoch 13/100, Batch 10/36, Loss: 0.1630\n",
      "Epoch 13/100, Batch 15/36, Loss: 0.1343\n",
      "Epoch 13/100, Batch 20/36, Loss: 0.1343\n",
      "Epoch 13/100, Batch 25/36, Loss: 0.1584\n",
      "Epoch 13/100, Batch 30/36, Loss: 0.2079\n",
      "Epoch 13/100, Batch 35/36, Loss: 0.2400\n",
      "Epoch 13/100, Average Loss: 0.1701, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 14/100, Batch 0/36, Loss: 0.2049\n",
      "Epoch 14/100, Batch 5/36, Loss: 0.2342\n",
      "Epoch 14/100, Batch 10/36, Loss: 0.2294\n",
      "Epoch 14/100, Batch 15/36, Loss: 0.1323\n",
      "Epoch 14/100, Batch 20/36, Loss: 0.2120\n",
      "Epoch 14/100, Batch 25/36, Loss: 0.1673\n",
      "Epoch 14/100, Batch 30/36, Loss: 0.1345\n",
      "Epoch 14/100, Batch 35/36, Loss: 0.1591\n",
      "Epoch 14/100, Average Loss: 0.1687, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1687\n",
      "Epoch 15/100, Batch 0/36, Loss: 0.1668\n",
      "Epoch 15/100, Batch 5/36, Loss: 0.1588\n",
      "Epoch 15/100, Batch 10/36, Loss: 0.1526\n",
      "Epoch 15/100, Batch 15/36, Loss: 0.1738\n",
      "Epoch 15/100, Batch 20/36, Loss: 0.1714\n",
      "Epoch 15/100, Batch 25/36, Loss: 0.1355\n",
      "Epoch 15/100, Batch 30/36, Loss: 0.2589\n",
      "Epoch 15/100, Batch 35/36, Loss: 0.1516\n",
      "Epoch 15/100, Average Loss: 0.1697, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 16/100, Batch 0/36, Loss: 0.1755\n",
      "Epoch 16/100, Batch 5/36, Loss: 0.1993\n",
      "Epoch 16/100, Batch 10/36, Loss: 0.1383\n",
      "Epoch 16/100, Batch 15/36, Loss: 0.1719\n",
      "Epoch 16/100, Batch 20/36, Loss: 0.2287\n",
      "Epoch 16/100, Batch 25/36, Loss: 0.1756\n",
      "Epoch 16/100, Batch 30/36, Loss: 0.1526\n",
      "Epoch 16/100, Batch 35/36, Loss: 0.1326\n",
      "Epoch 16/100, Average Loss: 0.1703, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 17/100, Batch 0/36, Loss: 0.1349\n",
      "Epoch 17/100, Batch 5/36, Loss: 0.1672\n",
      "Epoch 17/100, Batch 10/36, Loss: 0.1971\n",
      "Epoch 17/100, Batch 15/36, Loss: 0.1293\n",
      "Epoch 17/100, Batch 20/36, Loss: 0.1552\n",
      "Epoch 17/100, Batch 25/36, Loss: 0.1766\n",
      "Epoch 17/100, Batch 30/36, Loss: 0.1608\n",
      "Epoch 17/100, Batch 35/36, Loss: 0.1839\n",
      "Epoch 17/100, Average Loss: 0.1679, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1679\n",
      "Epoch 18/100, Batch 0/36, Loss: 0.1597\n",
      "Epoch 18/100, Batch 5/36, Loss: 0.2045\n",
      "Epoch 18/100, Batch 10/36, Loss: 0.2339\n",
      "Epoch 18/100, Batch 15/36, Loss: 0.1846\n",
      "Epoch 18/100, Batch 20/36, Loss: 0.1187\n",
      "Epoch 18/100, Batch 25/36, Loss: 0.1754\n",
      "Epoch 18/100, Batch 30/36, Loss: 0.1446\n",
      "Epoch 18/100, Batch 35/36, Loss: 0.1279\n",
      "Epoch 18/100, Average Loss: 0.1692, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 19/100, Batch 0/36, Loss: 0.1492\n",
      "Epoch 19/100, Batch 5/36, Loss: 0.1883\n",
      "Epoch 19/100, Batch 10/36, Loss: 0.1699\n",
      "Epoch 19/100, Batch 15/36, Loss: 0.1586\n",
      "Epoch 19/100, Batch 20/36, Loss: 0.1599\n",
      "Epoch 19/100, Batch 25/36, Loss: 0.1474\n",
      "Epoch 19/100, Batch 30/36, Loss: 0.1182\n",
      "Epoch 19/100, Batch 35/36, Loss: 0.1849\n",
      "Epoch 19/100, Average Loss: 0.1679, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1679\n",
      "Epoch 20/100, Batch 0/36, Loss: 0.1511\n",
      "Epoch 20/100, Batch 5/36, Loss: 0.2596\n",
      "Epoch 20/100, Batch 10/36, Loss: 0.2285\n",
      "Epoch 20/100, Batch 15/36, Loss: 0.1648\n",
      "Epoch 20/100, Batch 20/36, Loss: 0.1609\n",
      "Epoch 20/100, Batch 25/36, Loss: 0.1369\n",
      "Epoch 20/100, Batch 30/36, Loss: 0.1642\n",
      "Epoch 20/100, Batch 35/36, Loss: 0.1446\n",
      "Epoch 20/100, Average Loss: 0.1688, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 21/100, Batch 0/36, Loss: 0.1307\n",
      "Epoch 21/100, Batch 5/36, Loss: 0.1858\n",
      "Epoch 21/100, Batch 10/36, Loss: 0.1821\n",
      "Epoch 21/100, Batch 15/36, Loss: 0.1553\n",
      "Epoch 21/100, Batch 20/36, Loss: 0.2029\n",
      "Epoch 21/100, Batch 25/36, Loss: 0.1427\n",
      "Epoch 21/100, Batch 30/36, Loss: 0.1637\n",
      "Epoch 21/100, Batch 35/36, Loss: 0.1761\n",
      "Epoch 21/100, Average Loss: 0.1689, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 22/100, Batch 0/36, Loss: 0.1582\n",
      "Epoch 22/100, Batch 5/36, Loss: 0.1635\n",
      "Epoch 22/100, Batch 10/36, Loss: 0.2557\n",
      "Epoch 22/100, Batch 15/36, Loss: 0.1827\n",
      "Epoch 22/100, Batch 20/36, Loss: 0.1921\n",
      "Epoch 22/100, Batch 25/36, Loss: 0.1580\n",
      "Epoch 22/100, Batch 30/36, Loss: 0.1193\n",
      "Epoch 22/100, Batch 35/36, Loss: 0.1821\n",
      "Epoch 22/100, Average Loss: 0.1680, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 23/100, Batch 0/36, Loss: 0.1267\n",
      "Epoch 23/100, Batch 5/36, Loss: 0.1569\n",
      "Epoch 23/100, Batch 10/36, Loss: 0.2075\n",
      "Epoch 23/100, Batch 15/36, Loss: 0.2384\n",
      "Epoch 23/100, Batch 20/36, Loss: 0.1438\n",
      "Epoch 23/100, Batch 25/36, Loss: 0.2105\n",
      "Epoch 23/100, Batch 30/36, Loss: 0.1571\n",
      "Epoch 23/100, Batch 35/36, Loss: 0.1291\n",
      "Epoch 23/100, Average Loss: 0.1679, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1679\n",
      "Epoch 24/100, Batch 0/36, Loss: 0.1879\n",
      "Epoch 24/100, Batch 5/36, Loss: 0.1326\n",
      "Epoch 24/100, Batch 10/36, Loss: 0.1609\n",
      "Epoch 24/100, Batch 15/36, Loss: 0.1679\n",
      "Epoch 24/100, Batch 20/36, Loss: 0.1668\n",
      "Epoch 24/100, Batch 25/36, Loss: 0.1724\n",
      "Epoch 24/100, Batch 30/36, Loss: 0.1835\n",
      "Epoch 24/100, Batch 35/36, Loss: 0.1538\n",
      "Epoch 24/100, Average Loss: 0.1676, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1676\n",
      "Epoch 25/100, Batch 0/36, Loss: 0.1568\n",
      "Epoch 25/100, Batch 5/36, Loss: 0.1905\n",
      "Epoch 25/100, Batch 10/36, Loss: 0.1406\n",
      "Epoch 25/100, Batch 15/36, Loss: 0.1630\n",
      "Epoch 25/100, Batch 20/36, Loss: 0.1543\n",
      "Epoch 25/100, Batch 25/36, Loss: 0.1728\n",
      "Epoch 25/100, Batch 30/36, Loss: 0.1683\n",
      "Epoch 25/100, Batch 35/36, Loss: 0.1482\n",
      "Epoch 25/100, Average Loss: 0.1671, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1671\n",
      "Epoch 26/100, Batch 0/36, Loss: 0.2039\n",
      "Epoch 26/100, Batch 5/36, Loss: 0.1614\n",
      "Epoch 26/100, Batch 10/36, Loss: 0.2269\n",
      "Epoch 26/100, Batch 15/36, Loss: 0.1342\n",
      "Epoch 26/100, Batch 20/36, Loss: 0.1858\n",
      "Epoch 26/100, Batch 25/36, Loss: 0.1600\n",
      "Epoch 26/100, Batch 30/36, Loss: 0.1199\n",
      "Epoch 26/100, Batch 35/36, Loss: 0.1581\n",
      "Epoch 26/100, Average Loss: 0.1669, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1669\n",
      "Epoch 27/100, Batch 0/36, Loss: 0.1434\n",
      "Epoch 27/100, Batch 5/36, Loss: 0.1525\n",
      "Epoch 27/100, Batch 10/36, Loss: 0.2206\n",
      "Epoch 27/100, Batch 15/36, Loss: 0.1723\n",
      "Epoch 27/100, Batch 20/36, Loss: 0.1666\n",
      "Epoch 27/100, Batch 25/36, Loss: 0.1627\n",
      "Epoch 27/100, Batch 30/36, Loss: 0.1854\n",
      "Epoch 27/100, Batch 35/36, Loss: 0.1384\n",
      "Epoch 27/100, Average Loss: 0.1670, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 28/100, Batch 0/36, Loss: 0.2107\n",
      "Epoch 28/100, Batch 5/36, Loss: 0.1859\n",
      "Epoch 28/100, Batch 10/36, Loss: 0.1607\n",
      "Epoch 28/100, Batch 15/36, Loss: 0.1860\n",
      "Epoch 28/100, Batch 20/36, Loss: 0.1569\n",
      "Epoch 28/100, Batch 25/36, Loss: 0.1818\n",
      "Epoch 28/100, Batch 30/36, Loss: 0.1587\n",
      "Epoch 28/100, Batch 35/36, Loss: 0.1257\n",
      "Epoch 28/100, Average Loss: 0.1671, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 29/100, Batch 0/36, Loss: 0.1568\n",
      "Epoch 29/100, Batch 5/36, Loss: 0.1162\n",
      "Epoch 29/100, Batch 10/36, Loss: 0.1716\n",
      "Epoch 29/100, Batch 15/36, Loss: 0.1340\n",
      "Epoch 29/100, Batch 20/36, Loss: 0.1493\n",
      "Epoch 29/100, Batch 25/36, Loss: 0.1698\n",
      "Epoch 29/100, Batch 30/36, Loss: 0.1802\n",
      "Epoch 29/100, Batch 35/36, Loss: 0.1588\n",
      "Epoch 29/100, Average Loss: 0.1678, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 30/100, Batch 0/36, Loss: 0.1532\n",
      "Epoch 30/100, Batch 5/36, Loss: 0.1438\n",
      "Epoch 30/100, Batch 10/36, Loss: 0.1386\n",
      "Epoch 30/100, Batch 15/36, Loss: 0.1944\n",
      "Epoch 30/100, Batch 20/36, Loss: 0.2021\n",
      "Epoch 30/100, Batch 25/36, Loss: 0.1926\n",
      "Epoch 30/100, Batch 30/36, Loss: 0.1654\n",
      "Epoch 30/100, Batch 35/36, Loss: 0.1773\n",
      "Epoch 30/100, Average Loss: 0.1665, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1665\n",
      "Epoch 31/100, Batch 0/36, Loss: 0.1238\n",
      "Epoch 31/100, Batch 5/36, Loss: 0.0728\n",
      "Epoch 31/100, Batch 10/36, Loss: 0.2267\n",
      "Epoch 31/100, Batch 15/36, Loss: 0.1616\n",
      "Epoch 31/100, Batch 20/36, Loss: 0.1688\n",
      "Epoch 31/100, Batch 25/36, Loss: 0.1762\n",
      "Epoch 31/100, Batch 30/36, Loss: 0.1685\n",
      "Epoch 31/100, Batch 35/36, Loss: 0.1486\n",
      "Epoch 31/100, Average Loss: 0.1688, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 32/100, Batch 0/36, Loss: 0.1627\n",
      "Epoch 32/100, Batch 5/36, Loss: 0.2188\n",
      "Epoch 32/100, Batch 10/36, Loss: 0.1773\n",
      "Epoch 32/100, Batch 15/36, Loss: 0.1315\n",
      "Epoch 32/100, Batch 20/36, Loss: 0.1650\n",
      "Epoch 32/100, Batch 25/36, Loss: 0.1901\n",
      "Epoch 32/100, Batch 30/36, Loss: 0.2560\n",
      "Epoch 32/100, Batch 35/36, Loss: 0.1838\n",
      "Epoch 32/100, Average Loss: 0.1671, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 33/100, Batch 0/36, Loss: 0.1806\n",
      "Epoch 33/100, Batch 5/36, Loss: 0.2235\n",
      "Epoch 33/100, Batch 10/36, Loss: 0.1182\n",
      "Epoch 33/100, Batch 15/36, Loss: 0.2168\n",
      "Epoch 33/100, Batch 20/36, Loss: 0.1705\n",
      "Epoch 33/100, Batch 25/36, Loss: 0.1606\n",
      "Epoch 33/100, Batch 30/36, Loss: 0.1747\n",
      "Epoch 33/100, Batch 35/36, Loss: 0.2551\n",
      "Epoch 33/100, Average Loss: 0.1655, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1655\n",
      "Epoch 34/100, Batch 0/36, Loss: 0.1854\n",
      "Epoch 34/100, Batch 5/36, Loss: 0.1468\n",
      "Epoch 34/100, Batch 10/36, Loss: 0.1433\n",
      "Epoch 34/100, Batch 15/36, Loss: 0.1405\n",
      "Epoch 34/100, Batch 20/36, Loss: 0.1758\n",
      "Epoch 34/100, Batch 25/36, Loss: 0.1727\n",
      "Epoch 34/100, Batch 30/36, Loss: 0.1580\n",
      "Epoch 34/100, Batch 35/36, Loss: 0.1273\n",
      "Epoch 34/100, Average Loss: 0.1683, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 35/100, Batch 0/36, Loss: 0.2265\n",
      "Epoch 35/100, Batch 5/36, Loss: 0.2268\n",
      "Epoch 35/100, Batch 10/36, Loss: 0.1562\n",
      "Epoch 35/100, Batch 15/36, Loss: 0.1350\n",
      "Epoch 35/100, Batch 20/36, Loss: 0.1584\n",
      "Epoch 35/100, Batch 25/36, Loss: 0.1892\n",
      "Epoch 35/100, Batch 30/36, Loss: 0.1581\n",
      "Epoch 35/100, Batch 35/36, Loss: 0.1625\n",
      "Epoch 35/100, Average Loss: 0.1664, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 36/100, Batch 0/36, Loss: 0.2117\n",
      "Epoch 36/100, Batch 5/36, Loss: 0.1273\n",
      "Epoch 36/100, Batch 10/36, Loss: 0.1576\n",
      "Epoch 36/100, Batch 15/36, Loss: 0.1646\n",
      "Epoch 36/100, Batch 20/36, Loss: 0.2393\n",
      "Epoch 36/100, Batch 25/36, Loss: 0.2062\n",
      "Epoch 36/100, Batch 30/36, Loss: 0.1278\n",
      "Epoch 36/100, Batch 35/36, Loss: 0.1400\n",
      "Epoch 36/100, Average Loss: 0.1661, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 37/100, Batch 0/36, Loss: 0.1597\n",
      "Epoch 37/100, Batch 5/36, Loss: 0.1411\n",
      "Epoch 37/100, Batch 10/36, Loss: 0.1582\n",
      "Epoch 37/100, Batch 15/36, Loss: 0.1394\n",
      "Epoch 37/100, Batch 20/36, Loss: 0.1951\n",
      "Epoch 37/100, Batch 25/36, Loss: 0.1607\n",
      "Epoch 37/100, Batch 30/36, Loss: 0.0691\n",
      "Epoch 37/100, Batch 35/36, Loss: 0.1891\n",
      "Epoch 37/100, Average Loss: 0.1668, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 4/10\n",
      "Epoch 38/100, Batch 0/36, Loss: 0.1294\n",
      "Epoch 38/100, Batch 5/36, Loss: 0.1428\n",
      "Epoch 38/100, Batch 10/36, Loss: 0.1537\n",
      "Epoch 38/100, Batch 15/36, Loss: 0.1607\n",
      "Epoch 38/100, Batch 20/36, Loss: 0.1548\n",
      "Epoch 38/100, Batch 25/36, Loss: 0.1875\n",
      "Epoch 38/100, Batch 30/36, Loss: 0.1567\n",
      "Epoch 38/100, Batch 35/36, Loss: 0.1578\n",
      "Epoch 38/100, Average Loss: 0.1656, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 5/10\n",
      "Epoch 39/100, Batch 0/36, Loss: 0.1551\n",
      "Epoch 39/100, Batch 5/36, Loss: 0.1284\n",
      "Epoch 39/100, Batch 10/36, Loss: 0.1859\n",
      "Epoch 39/100, Batch 15/36, Loss: 0.1607\n",
      "Epoch 39/100, Batch 20/36, Loss: 0.1288\n",
      "Epoch 39/100, Batch 25/36, Loss: 0.1343\n",
      "Epoch 39/100, Batch 30/36, Loss: 0.1638\n",
      "Epoch 39/100, Batch 35/36, Loss: 0.1232\n",
      "Epoch 39/100, Average Loss: 0.1645, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Guardado checkpoint con mejor pérdida: 0.1645\n",
      "Epoch 40/100, Batch 0/36, Loss: 0.2229\n",
      "Epoch 40/100, Batch 5/36, Loss: 0.1342\n",
      "Epoch 40/100, Batch 10/36, Loss: 0.1667\n",
      "Epoch 40/100, Batch 15/36, Loss: 0.1305\n",
      "Epoch 40/100, Batch 20/36, Loss: 0.1360\n",
      "Epoch 40/100, Batch 25/36, Loss: 0.1866\n",
      "Epoch 40/100, Batch 30/36, Loss: 0.2545\n",
      "Epoch 40/100, Batch 35/36, Loss: 0.1681\n",
      "Epoch 40/100, Average Loss: 0.1644, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Guardado checkpoint con mejor pérdida: 0.1644\n",
      "Epoch 41/100, Batch 0/36, Loss: 0.1597\n",
      "Epoch 41/100, Batch 5/36, Loss: 0.1531\n",
      "Epoch 41/100, Batch 10/36, Loss: 0.1759\n",
      "Epoch 41/100, Batch 15/36, Loss: 0.1246\n",
      "Epoch 41/100, Batch 20/36, Loss: 0.1318\n",
      "Epoch 41/100, Batch 25/36, Loss: 0.1261\n",
      "Epoch 41/100, Batch 30/36, Loss: 0.1935\n",
      "Epoch 41/100, Batch 35/36, Loss: 0.1838\n",
      "Epoch 41/100, Average Loss: 0.1651, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 42/100, Batch 0/36, Loss: 0.2186\n",
      "Epoch 42/100, Batch 5/36, Loss: 0.1630\n",
      "Epoch 42/100, Batch 10/36, Loss: 0.1707\n",
      "Epoch 42/100, Batch 15/36, Loss: 0.1307\n",
      "Epoch 42/100, Batch 20/36, Loss: 0.1287\n",
      "Epoch 42/100, Batch 25/36, Loss: 0.1888\n",
      "Epoch 42/100, Batch 30/36, Loss: 0.2166\n",
      "Epoch 42/100, Batch 35/36, Loss: 0.1511\n",
      "Epoch 42/100, Average Loss: 0.1644, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 43/100, Batch 0/36, Loss: 0.1684\n",
      "Epoch 43/100, Batch 5/36, Loss: 0.2169\n",
      "Epoch 43/100, Batch 10/36, Loss: 0.1183\n",
      "Epoch 43/100, Batch 15/36, Loss: 0.1551\n",
      "Epoch 43/100, Batch 20/36, Loss: 0.1318\n",
      "Epoch 43/100, Batch 25/36, Loss: 0.1909\n",
      "Epoch 43/100, Batch 30/36, Loss: 0.1736\n",
      "Epoch 43/100, Batch 35/36, Loss: 0.1574\n",
      "Epoch 43/100, Average Loss: 0.1652, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 44/100, Batch 0/36, Loss: 0.1668\n",
      "Epoch 44/100, Batch 5/36, Loss: 0.1837\n",
      "Epoch 44/100, Batch 10/36, Loss: 0.1785\n",
      "Epoch 44/100, Batch 15/36, Loss: 0.1374\n",
      "Epoch 44/100, Batch 20/36, Loss: 0.1963\n",
      "Epoch 44/100, Batch 25/36, Loss: 0.1612\n",
      "Epoch 44/100, Batch 30/36, Loss: 0.1336\n",
      "Epoch 44/100, Batch 35/36, Loss: 0.1573\n",
      "Epoch 44/100, Average Loss: 0.1650, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 4/10\n",
      "Epoch 45/100, Batch 0/36, Loss: 0.1368\n",
      "Epoch 45/100, Batch 5/36, Loss: 0.0758\n",
      "Epoch 45/100, Batch 10/36, Loss: 0.1670\n",
      "Epoch 45/100, Batch 15/36, Loss: 0.1411\n",
      "Epoch 45/100, Batch 20/36, Loss: 0.1250\n",
      "Epoch 45/100, Batch 25/36, Loss: 0.1320\n",
      "Epoch 45/100, Batch 30/36, Loss: 0.1573\n",
      "Epoch 45/100, Batch 35/36, Loss: 0.2527\n",
      "Epoch 45/100, Average Loss: 0.1647, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 5/10\n",
      "Epoch 46/100, Batch 0/36, Loss: 0.1802\n",
      "Epoch 46/100, Batch 5/36, Loss: 0.2133\n",
      "Epoch 46/100, Batch 10/36, Loss: 0.1789\n",
      "Epoch 46/100, Batch 15/36, Loss: 0.1344\n",
      "Epoch 46/100, Batch 20/36, Loss: 0.0687\n",
      "Epoch 46/100, Batch 25/36, Loss: 0.1247\n",
      "Epoch 46/100, Batch 30/36, Loss: 0.1302\n",
      "Epoch 46/100, Batch 35/36, Loss: 0.1788\n",
      "Epoch 46/100, Average Loss: 0.1639, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Guardado checkpoint con mejor pérdida: 0.1639\n",
      "Epoch 47/100, Batch 0/36, Loss: 0.2485\n",
      "Epoch 47/100, Batch 5/36, Loss: 0.2100\n",
      "Epoch 47/100, Batch 10/36, Loss: 0.1271\n",
      "Epoch 47/100, Batch 15/36, Loss: 0.2275\n",
      "Epoch 47/100, Batch 20/36, Loss: 0.1553\n",
      "Epoch 47/100, Batch 25/36, Loss: 0.1564\n",
      "Epoch 47/100, Batch 30/36, Loss: 0.1809\n",
      "Epoch 47/100, Batch 35/36, Loss: 0.1753\n",
      "Epoch 47/100, Average Loss: 0.1645, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 48/100, Batch 0/36, Loss: 0.1856\n",
      "Epoch 48/100, Batch 5/36, Loss: 0.1498\n",
      "Epoch 48/100, Batch 10/36, Loss: 0.1181\n",
      "Epoch 48/100, Batch 15/36, Loss: 0.1355\n",
      "Epoch 48/100, Batch 20/36, Loss: 0.1877\n",
      "Epoch 48/100, Batch 25/36, Loss: 0.2325\n",
      "Epoch 48/100, Batch 30/36, Loss: 0.1821\n",
      "Epoch 48/100, Batch 35/36, Loss: 0.1700\n",
      "Epoch 48/100, Average Loss: 0.1654, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 49/100, Batch 0/36, Loss: 0.1261\n",
      "Epoch 49/100, Batch 5/36, Loss: 0.1619\n",
      "Epoch 49/100, Batch 10/36, Loss: 0.1884\n",
      "Epoch 49/100, Batch 15/36, Loss: 0.2268\n",
      "Epoch 49/100, Batch 20/36, Loss: 0.1393\n",
      "Epoch 49/100, Batch 25/36, Loss: 0.1770\n",
      "Epoch 49/100, Batch 30/36, Loss: 0.1304\n",
      "Epoch 49/100, Batch 35/36, Loss: 0.1802\n",
      "Epoch 49/100, Average Loss: 0.1645, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 50/100, Batch 0/36, Loss: 0.1773\n",
      "Epoch 50/100, Batch 5/36, Loss: 0.1641\n",
      "Epoch 50/100, Batch 10/36, Loss: 0.2463\n",
      "Epoch 50/100, Batch 15/36, Loss: 0.1331\n",
      "Epoch 50/100, Batch 20/36, Loss: 0.1623\n",
      "Epoch 50/100, Batch 25/36, Loss: 0.1985\n",
      "Epoch 50/100, Batch 30/36, Loss: 0.1316\n",
      "Epoch 50/100, Batch 35/36, Loss: 0.1376\n",
      "Epoch 50/100, Average Loss: 0.1635, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Guardado checkpoint con mejor pérdida: 0.1635\n",
      "Epoch 51/100, Batch 0/36, Loss: 0.1882\n",
      "Epoch 51/100, Batch 5/36, Loss: 0.1251\n",
      "Epoch 51/100, Batch 10/36, Loss: 0.1523\n",
      "Epoch 51/100, Batch 15/36, Loss: 0.0671\n",
      "Epoch 51/100, Batch 20/36, Loss: 0.1616\n",
      "Epoch 51/100, Batch 25/36, Loss: 0.1694\n",
      "Epoch 51/100, Batch 30/36, Loss: 0.1831\n",
      "Epoch 51/100, Batch 35/36, Loss: 0.1504\n",
      "Epoch 51/100, Average Loss: 0.1638, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 52/100, Batch 0/36, Loss: 0.1869\n",
      "Epoch 52/100, Batch 5/36, Loss: 0.1516\n",
      "Epoch 52/100, Batch 10/36, Loss: 0.1516\n",
      "Epoch 52/100, Batch 15/36, Loss: 0.1389\n",
      "Epoch 52/100, Batch 20/36, Loss: 0.1899\n",
      "Epoch 52/100, Batch 25/36, Loss: 0.1564\n",
      "Epoch 52/100, Batch 30/36, Loss: 0.1867\n",
      "Epoch 52/100, Batch 35/36, Loss: 0.2240\n",
      "Epoch 52/100, Average Loss: 0.1640, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 53/100, Batch 0/36, Loss: 0.1288\n",
      "Epoch 53/100, Batch 5/36, Loss: 0.1345\n",
      "Epoch 53/100, Batch 10/36, Loss: 0.2256\n",
      "Epoch 53/100, Batch 15/36, Loss: 0.1507\n",
      "Epoch 53/100, Batch 20/36, Loss: 0.0672\n",
      "Epoch 53/100, Batch 25/36, Loss: 0.1809\n",
      "Epoch 53/100, Batch 30/36, Loss: 0.1568\n",
      "Epoch 53/100, Batch 35/36, Loss: 0.1649\n",
      "Epoch 53/100, Average Loss: 0.1640, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 54/100, Batch 0/36, Loss: 0.1636\n",
      "Epoch 54/100, Batch 5/36, Loss: 0.1582\n",
      "Epoch 54/100, Batch 10/36, Loss: 0.1609\n",
      "Epoch 54/100, Batch 15/36, Loss: 0.1320\n",
      "Epoch 54/100, Batch 20/36, Loss: 0.2118\n",
      "Epoch 54/100, Batch 25/36, Loss: 0.1624\n",
      "Epoch 54/100, Batch 30/36, Loss: 0.1373\n",
      "Epoch 54/100, Batch 35/36, Loss: 0.1761\n",
      "Epoch 54/100, Average Loss: 0.1639, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 4/10\n",
      "Epoch 55/100, Batch 0/36, Loss: 0.1570\n",
      "Epoch 55/100, Batch 5/36, Loss: 0.1860\n",
      "Epoch 55/100, Batch 10/36, Loss: 0.1330\n",
      "Epoch 55/100, Batch 15/36, Loss: 0.1585\n",
      "Epoch 55/100, Batch 20/36, Loss: 0.1867\n",
      "Epoch 55/100, Batch 25/36, Loss: 0.1277\n",
      "Epoch 55/100, Batch 30/36, Loss: 0.0691\n",
      "Epoch 55/100, Batch 35/36, Loss: 0.1556\n",
      "Epoch 55/100, Average Loss: 0.1634, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Guardado checkpoint con mejor pérdida: 0.1634\n",
      "Epoch 56/100, Batch 0/36, Loss: 0.1771\n",
      "Epoch 56/100, Batch 5/36, Loss: 0.1823\n",
      "Epoch 56/100, Batch 10/36, Loss: 0.2210\n",
      "Epoch 56/100, Batch 15/36, Loss: 0.1674\n",
      "Epoch 56/100, Batch 20/36, Loss: 0.0617\n",
      "Epoch 56/100, Batch 25/36, Loss: 0.1922\n",
      "Epoch 56/100, Batch 30/36, Loss: 0.1826\n",
      "Epoch 56/100, Batch 35/36, Loss: 0.1498\n",
      "Epoch 56/100, Average Loss: 0.1631, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Guardado checkpoint con mejor pérdida: 0.1631\n",
      "Epoch 57/100, Batch 0/36, Loss: 0.1884\n",
      "Epoch 57/100, Batch 5/36, Loss: 0.2501\n",
      "Epoch 57/100, Batch 10/36, Loss: 0.1723\n",
      "Epoch 57/100, Batch 15/36, Loss: 0.1313\n",
      "Epoch 57/100, Batch 20/36, Loss: 0.1243\n",
      "Epoch 57/100, Batch 25/36, Loss: 0.1838\n",
      "Epoch 57/100, Batch 30/36, Loss: 0.2108\n",
      "Epoch 57/100, Batch 35/36, Loss: 0.1773\n",
      "Epoch 57/100, Average Loss: 0.1644, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 58/100, Batch 0/36, Loss: 0.2185\n",
      "Epoch 58/100, Batch 5/36, Loss: 0.1758\n",
      "Epoch 58/100, Batch 10/36, Loss: 0.1784\n",
      "Epoch 58/100, Batch 15/36, Loss: 0.1909\n",
      "Epoch 58/100, Batch 20/36, Loss: 0.1330\n",
      "Epoch 58/100, Batch 25/36, Loss: 0.2245\n",
      "Epoch 58/100, Batch 30/36, Loss: 0.1533\n",
      "Epoch 58/100, Batch 35/36, Loss: 0.1547\n",
      "Epoch 58/100, Average Loss: 0.1645, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 59/100, Batch 0/36, Loss: 0.2250\n",
      "Epoch 59/100, Batch 5/36, Loss: 0.1395\n",
      "Epoch 59/100, Batch 10/36, Loss: 0.1259\n",
      "Epoch 59/100, Batch 15/36, Loss: 0.1356\n",
      "Epoch 59/100, Batch 20/36, Loss: 0.1860\n",
      "Epoch 59/100, Batch 25/36, Loss: 0.0725\n",
      "Epoch 59/100, Batch 30/36, Loss: 0.1635\n",
      "Epoch 59/100, Batch 35/36, Loss: 0.1723\n",
      "Epoch 59/100, Average Loss: 0.1641, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 60/100, Batch 0/36, Loss: 0.1787\n",
      "Epoch 60/100, Batch 5/36, Loss: 0.1554\n",
      "Epoch 60/100, Batch 10/36, Loss: 0.1508\n",
      "Epoch 60/100, Batch 15/36, Loss: 0.1391\n",
      "Epoch 60/100, Batch 20/36, Loss: 0.1539\n",
      "Epoch 60/100, Batch 25/36, Loss: 0.1876\n",
      "Epoch 60/100, Batch 30/36, Loss: 0.1660\n",
      "Epoch 60/100, Batch 35/36, Loss: 0.2127\n",
      "Epoch 60/100, Average Loss: 0.1636, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Épocas sin mejora: 4/10\n",
      "Epoch 61/100, Batch 0/36, Loss: 0.0707\n",
      "Epoch 61/100, Batch 5/36, Loss: 0.1822\n",
      "Epoch 61/100, Batch 10/36, Loss: 0.1272\n",
      "Epoch 61/100, Batch 15/36, Loss: 0.1600\n",
      "Epoch 61/100, Batch 20/36, Loss: 0.1384\n",
      "Epoch 61/100, Batch 25/36, Loss: 0.1470\n",
      "Epoch 61/100, Batch 30/36, Loss: 0.1367\n",
      "Epoch 61/100, Batch 35/36, Loss: 0.1645\n",
      "Epoch 61/100, Average Loss: 0.1640, Valid Batches: 36/36, Learning Rate: 0.000063\n",
      "Épocas sin mejora: 5/10\n",
      "Epoch 62/100, Batch 0/36, Loss: 0.1526\n",
      "Epoch 62/100, Batch 5/36, Loss: 0.1656\n",
      "Epoch 62/100, Batch 10/36, Loss: 0.1806\n",
      "Epoch 62/100, Batch 15/36, Loss: 0.1327\n",
      "Epoch 62/100, Batch 20/36, Loss: 0.1572\n",
      "Epoch 62/100, Batch 25/36, Loss: 0.1416\n",
      "Epoch 62/100, Batch 30/36, Loss: 0.1420\n",
      "Epoch 62/100, Batch 35/36, Loss: 0.1319\n",
      "Epoch 62/100, Average Loss: 0.1644, Valid Batches: 36/36, Learning Rate: 0.000063\n",
      "Épocas sin mejora: 6/10\n",
      "Epoch 63/100, Batch 0/36, Loss: 0.1565\n",
      "Epoch 63/100, Batch 5/36, Loss: 0.1916\n",
      "Epoch 63/100, Batch 10/36, Loss: 0.1533\n",
      "Epoch 63/100, Batch 15/36, Loss: 0.1529\n",
      "Epoch 63/100, Batch 20/36, Loss: 0.1689\n",
      "Epoch 63/100, Batch 25/36, Loss: 0.2541\n",
      "Epoch 63/100, Batch 30/36, Loss: 0.2158\n",
      "Epoch 63/100, Batch 35/36, Loss: 0.0716\n",
      "Epoch 63/100, Average Loss: 0.1637, Valid Batches: 36/36, Learning Rate: 0.000063\n",
      "Épocas sin mejora: 7/10\n",
      "Epoch 64/100, Batch 0/36, Loss: 0.1510\n",
      "Epoch 64/100, Batch 5/36, Loss: 0.1664\n",
      "Epoch 64/100, Batch 10/36, Loss: 0.1308\n",
      "Epoch 64/100, Batch 15/36, Loss: 0.1822\n",
      "Epoch 64/100, Batch 20/36, Loss: 0.1367\n",
      "Epoch 64/100, Batch 25/36, Loss: 0.2296\n",
      "Epoch 64/100, Batch 30/36, Loss: 0.1531\n",
      "Epoch 64/100, Batch 35/36, Loss: 0.1660\n",
      "Epoch 64/100, Average Loss: 0.1636, Valid Batches: 36/36, Learning Rate: 0.000063\n",
      "Épocas sin mejora: 8/10\n",
      "Epoch 65/100, Batch 0/36, Loss: 0.1349\n",
      "Epoch 65/100, Batch 5/36, Loss: 0.2148\n",
      "Epoch 65/100, Batch 10/36, Loss: 0.1564\n",
      "Epoch 65/100, Batch 15/36, Loss: 0.1529\n",
      "Epoch 65/100, Batch 20/36, Loss: 0.1768\n",
      "Epoch 65/100, Batch 25/36, Loss: 0.1653\n",
      "Epoch 65/100, Batch 30/36, Loss: 0.2496\n",
      "Epoch 65/100, Batch 35/36, Loss: 0.2176\n",
      "Epoch 65/100, Average Loss: 0.1641, Valid Batches: 36/36, Learning Rate: 0.000031\n",
      "Épocas sin mejora: 9/10\n",
      "Epoch 66/100, Batch 0/36, Loss: 0.1338\n",
      "Epoch 66/100, Batch 5/36, Loss: 0.2246\n",
      "Epoch 66/100, Batch 10/36, Loss: 0.1355\n",
      "Epoch 66/100, Batch 15/36, Loss: 0.1698\n",
      "Epoch 66/100, Batch 20/36, Loss: 0.1601\n",
      "Epoch 66/100, Batch 25/36, Loss: 0.1878\n",
      "Epoch 66/100, Batch 30/36, Loss: 0.1617\n",
      "Epoch 66/100, Batch 35/36, Loss: 0.0702\n",
      "Epoch 66/100, Average Loss: 0.1637, Valid Batches: 36/36, Learning Rate: 0.000031\n",
      "Épocas sin mejora: 10/10\n",
      "Early stopping activado tras 66 épocas. Mejor pérdida: 0.1631\n",
      "Cargado el mejor modelo desde trained_models/checkpoints_contrastive/best_contrastive_projection_head.pth con pérdida: 0.1631\n",
      "Modelo final guardado en 'trained_models/checkpoints_contrastive/contrastive_projection_head_final.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2658900/1500752681.py:82: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Directorio para checkpoints\n",
    "output_dir = \"trained_models/checkpoints_contrastive\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Variables para early stopping y checkpoints\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_path = os.path.join(output_dir, \"best_contrastive_projection_head.pth\")\n",
    "\n",
    "# Entrenamiento con scheduler, checkpoints y early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    valid_batches = 0\n",
    "    \n",
    "    model.train()  # Modo entrenamiento\n",
    "    \n",
    "    for batch_idx, (embeddings, labels) in enumerate(loader):\n",
    "        embeddings = embeddings.to(device)  # [1, 48, 128, 128, 128]\n",
    "        labels = labels.to(device)  # [1, 128, 128, 128]\n",
    "        \n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        labels = labels.squeeze(0)  # [128, 128, 128]\n",
    "        \n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        labels_flat = labels.reshape(-1)  # [2097152]\n",
    "        \n",
    "        valid_mask = labels_flat >= 0\n",
    "        embeddings_valid = embeddings_flat[valid_mask]\n",
    "        labels_valid = labels_flat[valid_mask]\n",
    "        \n",
    "        if embeddings_valid.shape[0] < 2:\n",
    "            print(f\"Batch {batch_idx}: Insuficientes vóxeles válidos\")\n",
    "            continue\n",
    "        \n",
    "        # Forward\n",
    "        z = model(embeddings_valid)\n",
    "        loss = contrastive_loss(z, labels_valid, temperature, sample_size_per_class)\n",
    "        \n",
    "        if loss.item() == 0:\n",
    "            continue  # No contar batches con pérdida 0\n",
    "        \n",
    "        # Optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        valid_batches += 1\n",
    "        \n",
    "        if batch_idx % 5 == 0:  # Imprimir cada 5 batches\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    # Calcular pérdida promedio\n",
    "    avg_loss = total_loss / max(valid_batches, 1)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}, Valid Batches: {valid_batches}/{len(loader)}, \"\n",
    "          f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Scheduler: ajustar tasa de aprendizaje\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Checkpoint: guardar el mejor modelo\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "        }, best_model_path)\n",
    "        print(f\"Guardado checkpoint con mejor pérdida: {best_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"Épocas sin mejora: {epochs_no_improve}/{patience}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping activado tras {epoch+1} épocas. Mejor pérdida: {best_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "# Cargar el mejor modelo al final (opcional)\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Cargado el mejor modelo desde {best_model_path} con pérdida: {checkpoint['loss']:.4f}\")\n",
    "\n",
    "# Guardar el modelo final (opcional)\n",
    "torch.save(model.state_dict(), os.path.join(output_dir, \"contrastive_projection_head_final.pth\"))\n",
    "print(\"Modelo final guardado en 'trained_models/checkpoints_contrastive/contrastive_projection_head_final.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 0/36, Loss: 0.8219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 1/36, Loss: 0.7822\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 2/36, Loss: 0.7484\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 3/36, Loss: 0.7338\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 4/36, Loss: 0.6744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 5/36, Loss: 0.6506\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 6/36, Loss: 0.5996\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 7/36, Loss: 0.3945\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 8/36, Loss: 0.6113\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 9/36, Loss: 0.3738\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 10/36, Loss: 0.4886\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 11/36, Loss: 0.5332\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 12/36, Loss: 0.5163\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 13/36, Loss: 0.5027\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 14/36, Loss: 0.5161\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 15/36, Loss: 0.5146\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 16/36, Loss: 0.5276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 17/36, Loss: 0.5260\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 18/36, Loss: 0.1145\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 19/36, Loss: 0.4175\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 1/100, Batch 20/36, Loss: 0.1141\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 21/36, Loss: 0.5067\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 22/36, Loss: 0.4900\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 23/36, Loss: 0.5481\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 24/36, Loss: 0.4665\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 25/36, Loss: 0.3591\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 26/36, Loss: 0.4875\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 27/36, Loss: 0.4656\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 28/36, Loss: 0.4644\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 29/36, Loss: 0.4691\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 30/36, Loss: 0.4937\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 31/36, Loss: 0.4106\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 32/36, Loss: 0.0687\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 33/36, Loss: 0.4635\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 34/36, Loss: 0.5078\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 1/100, Batch 35/36, Loss: 0.3504\n",
      "Epoch 1/100, Average Loss: 0.4920, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 0/36, Loss: 0.4995\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 1/36, Loss: 0.4575\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 2/36, Loss: 0.5081\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 3/36, Loss: 0.5345\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 4/36, Loss: 0.4336\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 5/36, Loss: 0.3285\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 2/100, Batch 6/36, Loss: 0.1002\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 7/36, Loss: 0.4419\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 8/36, Loss: 0.4598\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 9/36, Loss: 0.5101\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 10/36, Loss: 0.5275\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 11/36, Loss: 0.4246\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 12/36, Loss: 0.4511\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 13/36, Loss: 0.4562\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 14/36, Loss: 0.4590\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 15/36, Loss: 0.5417\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 16/36, Loss: 0.5044\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 17/36, Loss: 0.4339\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 18/36, Loss: 0.3133\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 19/36, Loss: 0.2885\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 20/36, Loss: 0.4743\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 21/36, Loss: 0.5098\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 22/36, Loss: 0.4499\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 23/36, Loss: 0.5425\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 24/36, Loss: 0.3472\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 25/36, Loss: 0.5076\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 26/36, Loss: 0.1347\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 27/36, Loss: 0.4639\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 28/36, Loss: 0.0828\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 29/36, Loss: 0.5450\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 30/36, Loss: 0.3312\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 31/36, Loss: 0.5393\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 32/36, Loss: 0.4870\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 33/36, Loss: 0.4114\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 34/36, Loss: 0.3869\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 2/100, Batch 35/36, Loss: 0.3392\n",
      "Epoch 2/100, Average Loss: 0.4230, Valid Batches: 36/36\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 0/36, Loss: 0.3786\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 1/36, Loss: 0.3371\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 2/36, Loss: 0.4824\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 3/36, Loss: 0.4558\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 4/36, Loss: 0.5186\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 5/36, Loss: 0.5320\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 6/36, Loss: 0.5169\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 7/36, Loss: 0.3213\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 8/36, Loss: 0.4517\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 9/36, Loss: 0.5298\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 10/36, Loss: 0.3116\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 11/36, Loss: 0.4798\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 12/36, Loss: 0.4344\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 13/36, Loss: 0.4048\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 14/36, Loss: 0.4845\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 15/36, Loss: 0.4208\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 16/36, Loss: 0.0791\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 17/36, Loss: 0.1285\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 18/36, Loss: 0.5021\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 19/36, Loss: 0.4542\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 20/36, Loss: 0.5442\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 21/36, Loss: 0.5319\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 22/36, Loss: 0.4671\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 23/36, Loss: 0.4410\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 24/36, Loss: 0.4406\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 25/36, Loss: 0.2828\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 3/100, Batch 26/36, Loss: 0.0920\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 27/36, Loss: 0.3070\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 28/36, Loss: 0.5141\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 29/36, Loss: 0.4137\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 30/36, Loss: 0.4946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 31/36, Loss: 0.4276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 32/36, Loss: 0.5320\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 33/36, Loss: 0.4588\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 34/36, Loss: 0.4565\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 3/100, Batch 35/36, Loss: 0.3332\n",
      "Epoch 3/100, Average Loss: 0.4156, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 0/36, Loss: 0.4170\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 1/36, Loss: 0.4807\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 2/36, Loss: 0.3103\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 3/36, Loss: 0.4452\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 4/36, Loss: 0.4547\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 5/36, Loss: 0.4338\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 6/36, Loss: 0.5177\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 7/36, Loss: 0.4019\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 8/36, Loss: 0.2923\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 9/36, Loss: 0.5298\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 10/36, Loss: 0.5405\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 11/36, Loss: 0.4155\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 12/36, Loss: 0.3182\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 13/36, Loss: 0.3601\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 14/36, Loss: 0.5243\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 15/36, Loss: 0.4284\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 16/36, Loss: 0.5008\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 17/36, Loss: 0.0780\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 18/36, Loss: 0.5224\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 19/36, Loss: 0.3285\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 20/36, Loss: 0.4626\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 21/36, Loss: 0.2832\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 22/36, Loss: 0.4978\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 4/100, Batch 23/36, Loss: 0.0946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 24/36, Loss: 0.4743\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 25/36, Loss: 0.4343\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 26/36, Loss: 0.4760\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 27/36, Loss: 0.5150\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 28/36, Loss: 0.3341\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 29/36, Loss: 0.4562\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 30/36, Loss: 0.5038\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 31/36, Loss: 0.4538\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 32/36, Loss: 0.1193\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 33/36, Loss: 0.4584\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 34/36, Loss: 0.5228\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 4/100, Batch 35/36, Loss: 0.4285\n",
      "Epoch 4/100, Average Loss: 0.4115, Valid Batches: 36/36\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 0/36, Loss: 0.3736\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 1/36, Loss: 0.4817\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 2/36, Loss: 0.4788\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 3/36, Loss: 0.4500\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 4/36, Loss: 0.0771\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 5/36, Loss: 0.5000\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 6/36, Loss: 0.3195\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 5/100, Batch 7/36, Loss: 0.1016\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 8/36, Loss: 0.2951\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 9/36, Loss: 0.1299\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 10/36, Loss: 0.4410\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 11/36, Loss: 0.3345\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 12/36, Loss: 0.4956\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 13/36, Loss: 0.5080\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 14/36, Loss: 0.4748\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 15/36, Loss: 0.3136\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 16/36, Loss: 0.4616\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 17/36, Loss: 0.5290\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 18/36, Loss: 0.4300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 19/36, Loss: 0.5298\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 20/36, Loss: 0.5303\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 21/36, Loss: 0.4399\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 22/36, Loss: 0.3277\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 23/36, Loss: 0.4280\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 24/36, Loss: 0.3917\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 25/36, Loss: 0.4455\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 26/36, Loss: 0.5073\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 27/36, Loss: 0.4547\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 28/36, Loss: 0.5075\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 29/36, Loss: 0.4536\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 30/36, Loss: 0.4557\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 31/36, Loss: 0.4265\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 32/36, Loss: 0.5050\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 33/36, Loss: 0.2796\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 34/36, Loss: 0.4013\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 5/100, Batch 35/36, Loss: 0.5152\n",
      "Epoch 5/100, Average Loss: 0.4110, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 0/36, Loss: 0.4417\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 1/36, Loss: 0.0691\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 2/36, Loss: 0.4490\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 3/36, Loss: 0.4062\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 4/36, Loss: 0.4689\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 5/36, Loss: 0.4242\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 6/36, Loss: 0.3191\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 7/36, Loss: 0.5370\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 8/36, Loss: 0.4412\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 9/36, Loss: 0.4252\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 10/36, Loss: 0.5031\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 11/36, Loss: 0.1287\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 6/100, Batch 12/36, Loss: 0.0928\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 13/36, Loss: 0.4176\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 14/36, Loss: 0.5269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 15/36, Loss: 0.5271\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 16/36, Loss: 0.4647\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 17/36, Loss: 0.4503\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 18/36, Loss: 0.3249\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 19/36, Loss: 0.4935\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 20/36, Loss: 0.5138\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 21/36, Loss: 0.4728\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 22/36, Loss: 0.5103\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 23/36, Loss: 0.3810\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 24/36, Loss: 0.3279\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 25/36, Loss: 0.4744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 26/36, Loss: 0.4501\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 27/36, Loss: 0.4407\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 28/36, Loss: 0.4353\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 29/36, Loss: 0.5111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 30/36, Loss: 0.3019\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 31/36, Loss: 0.3320\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 32/36, Loss: 0.4132\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 33/36, Loss: 0.5304\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 34/36, Loss: 0.5205\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 6/100, Batch 35/36, Loss: 0.2711\n",
      "Epoch 6/100, Average Loss: 0.4110, Valid Batches: 36/36\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 7/100, Batch 0/36, Loss: 0.0971\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 1/36, Loss: 0.3206\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 2/36, Loss: 0.2721\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 3/36, Loss: 0.3108\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 4/36, Loss: 0.5254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 5/36, Loss: 0.4977\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 6/36, Loss: 0.3181\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 7/36, Loss: 0.4442\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 8/36, Loss: 0.4017\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 9/36, Loss: 0.4535\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 10/36, Loss: 0.4078\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 11/36, Loss: 0.5199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 12/36, Loss: 0.4126\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 13/36, Loss: 0.4548\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 14/36, Loss: 0.4652\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 15/36, Loss: 0.4286\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 16/36, Loss: 0.4261\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 17/36, Loss: 0.5199\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 18/36, Loss: 0.3450\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 19/36, Loss: 0.4775\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 20/36, Loss: 0.4265\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 21/36, Loss: 0.2908\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 22/36, Loss: 0.1269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 23/36, Loss: 0.4405\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 24/36, Loss: 0.4991\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 25/36, Loss: 0.4936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 26/36, Loss: 0.5356\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 27/36, Loss: 0.4367\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 28/36, Loss: 0.5247\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 29/36, Loss: 0.3342\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 30/36, Loss: 0.4454\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 31/36, Loss: 0.5147\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 32/36, Loss: 0.4767\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 33/36, Loss: 0.0690\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 34/36, Loss: 0.5103\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 7/100, Batch 35/36, Loss: 0.4559\n",
      "Epoch 7/100, Average Loss: 0.4078, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 0/36, Loss: 0.5077\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 1/36, Loss: 0.1178\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 2/36, Loss: 0.4371\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 3/36, Loss: 0.2898\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 4/36, Loss: 0.4491\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 5/36, Loss: 0.4287\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 6/36, Loss: 0.3089\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 7/36, Loss: 0.3177\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 8/36, Loss: 0.5255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 9/36, Loss: 0.4351\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 10/36, Loss: 0.4370\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 11/36, Loss: 0.5223\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 12/36, Loss: 0.5222\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 13/36, Loss: 0.4358\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 14/36, Loss: 0.4437\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 15/36, Loss: 0.4107\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 16/36, Loss: 0.4704\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 17/36, Loss: 0.4938\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 18/36, Loss: 0.4336\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 19/36, Loss: 0.0675\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 20/36, Loss: 0.4793\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 21/36, Loss: 0.4928\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 22/36, Loss: 0.3302\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 23/36, Loss: 0.4564\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 24/36, Loss: 0.3499\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 25/36, Loss: 0.4151\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 26/36, Loss: 0.3121\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 27/36, Loss: 0.4779\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 28/36, Loss: 0.2951\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 29/36, Loss: 0.5028\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 30/36, Loss: 0.5198\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 31/36, Loss: 0.4513\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 32/36, Loss: 0.3801\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 33/36, Loss: 0.4965\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 8/100, Batch 34/36, Loss: 0.5147\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 8/100, Batch 35/36, Loss: 0.0913\n",
      "Epoch 8/100, Average Loss: 0.4061, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 0/36, Loss: 0.4373\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 9/100, Batch 1/36, Loss: 0.0897\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 2/36, Loss: 0.4100\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 3/36, Loss: 0.4429\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 4/36, Loss: 0.0685\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 5/36, Loss: 0.4929\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 6/36, Loss: 0.1232\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 7/36, Loss: 0.4719\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 8/36, Loss: 0.4255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 9/36, Loss: 0.5182\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 10/36, Loss: 0.2834\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 11/36, Loss: 0.3284\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 12/36, Loss: 0.4404\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 13/36, Loss: 0.3096\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 14/36, Loss: 0.4492\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 15/36, Loss: 0.4238\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 16/36, Loss: 0.3146\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 17/36, Loss: 0.3189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 18/36, Loss: 0.4757\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 19/36, Loss: 0.4226\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 20/36, Loss: 0.4953\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 21/36, Loss: 0.4588\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 22/36, Loss: 0.3584\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 23/36, Loss: 0.4997\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 24/36, Loss: 0.4909\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 25/36, Loss: 0.5254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 26/36, Loss: 0.5070\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 27/36, Loss: 0.4426\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 28/36, Loss: 0.3980\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 29/36, Loss: 0.5177\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 30/36, Loss: 0.5229\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 31/36, Loss: 0.3886\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 32/36, Loss: 0.5173\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 33/36, Loss: 0.4777\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 34/36, Loss: 0.4540\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 9/100, Batch 35/36, Loss: 0.2953\n",
      "Epoch 9/100, Average Loss: 0.4054, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 0/36, Loss: 0.4949\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 1/36, Loss: 0.4525\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 2/36, Loss: 0.4364\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 3/36, Loss: 0.5333\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 4/36, Loss: 0.1239\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 5/36, Loss: 0.0709\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 6/36, Loss: 0.3998\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 7/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 8/36, Loss: 0.4486\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 9/36, Loss: 0.4291\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 10/36, Loss: 0.4054\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 11/36, Loss: 0.4663\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 12/36, Loss: 0.3164\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 13/36, Loss: 0.2691\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 14/36, Loss: 0.5081\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 15/36, Loss: 0.3094\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 16/36, Loss: 0.4652\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 17/36, Loss: 0.4770\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 18/36, Loss: 0.4349\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 19/36, Loss: 0.5062\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 20/36, Loss: 0.3978\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 21/36, Loss: 0.3440\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 22/36, Loss: 0.5169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 23/36, Loss: 0.4626\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 24/36, Loss: 0.4121\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 10/100, Batch 25/36, Loss: 0.0897\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 26/36, Loss: 0.3372\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 27/36, Loss: 0.4328\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 28/36, Loss: 0.4951\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 29/36, Loss: 0.4415\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 30/36, Loss: 0.5300\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 31/36, Loss: 0.5058\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 32/36, Loss: 0.3161\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 33/36, Loss: 0.4436\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 34/36, Loss: 0.5120\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 10/100, Batch 35/36, Loss: 0.5087\n",
      "Epoch 10/100, Average Loss: 0.4052, Valid Batches: 36/36\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 0/36, Loss: 0.3166\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 1/36, Loss: 0.4426\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 2/36, Loss: 0.4995\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 3/36, Loss: 0.3208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 4/36, Loss: 0.4784\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 5/36, Loss: 0.5057\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 6/36, Loss: 0.4678\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 7/36, Loss: 0.4356\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 8/36, Loss: 0.4433\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 9/36, Loss: 0.4208\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 10/36, Loss: 0.3432\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 11/36, Loss: 0.4194\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 12/36, Loss: 0.3948\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 13/36, Loss: 0.3230\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 14/36, Loss: 0.3037\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 15/36, Loss: 0.4967\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 16/36, Loss: 0.5267\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 17/36, Loss: 0.4471\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 18/36, Loss: 0.0770\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 19/36, Loss: 0.1314\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 20/36, Loss: 0.4940\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 21/36, Loss: 0.4295\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 22/36, Loss: 0.2843\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 23/36, Loss: 0.5146\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 24/36, Loss: 0.4710\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 25/36, Loss: 0.4511\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 26/36, Loss: 0.5112\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 27/36, Loss: 0.5257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 28/36, Loss: 0.5225\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 29/36, Loss: 0.4568\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 30/36, Loss: 0.4954\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 11/100, Batch 31/36, Loss: 0.0872\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 32/36, Loss: 0.3931\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 33/36, Loss: 0.4537\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 34/36, Loss: 0.4140\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 11/100, Batch 35/36, Loss: 0.3191\n",
      "Epoch 11/100, Average Loss: 0.4060, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 0/36, Loss: 0.5095\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 1/36, Loss: 0.5187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 2/36, Loss: 0.4133\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 3/36, Loss: 0.4519\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 4/36, Loss: 0.4322\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 5/36, Loss: 0.4351\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 6/36, Loss: 0.3153\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 7/36, Loss: 0.3202\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 8/36, Loss: 0.5092\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 9/36, Loss: 0.3280\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 10/36, Loss: 0.4091\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 11/36, Loss: 0.4601\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 12/36, Loss: 0.4486\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 13/36, Loss: 0.3452\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 14/36, Loss: 0.4987\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 15/36, Loss: 0.3774\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 16/36, Loss: 0.3106\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 12/100, Batch 17/36, Loss: 0.0931\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 18/36, Loss: 0.5314\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 19/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 20/36, Loss: 0.4380\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 21/36, Loss: 0.4884\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 22/36, Loss: 0.4896\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 23/36, Loss: 0.2781\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 24/36, Loss: 0.4401\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 25/36, Loss: 0.4936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 26/36, Loss: 0.4706\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 27/36, Loss: 0.4944\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 28/36, Loss: 0.0795\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 29/36, Loss: 0.5244\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 30/36, Loss: 0.4318\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 31/36, Loss: 0.1211\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 32/36, Loss: 0.4465\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 33/36, Loss: 0.3962\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 34/36, Loss: 0.5270\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 12/100, Batch 35/36, Loss: 0.4461\n",
      "Epoch 12/100, Average Loss: 0.4047, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 0/36, Loss: 0.5115\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 13/100, Batch 1/36, Loss: 0.0874\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 2/36, Loss: 0.4981\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 3/36, Loss: 0.4783\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 4/36, Loss: 0.4549\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 5/36, Loss: 0.3017\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 6/36, Loss: 0.0626\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 7/36, Loss: 0.3257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 8/36, Loss: 0.4939\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 9/36, Loss: 0.4390\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 10/36, Loss: 0.4794\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 11/36, Loss: 0.2797\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 12/36, Loss: 0.1219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 13/36, Loss: 0.5331\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 14/36, Loss: 0.5115\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 15/36, Loss: 0.3374\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 16/36, Loss: 0.5155\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 17/36, Loss: 0.4521\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 18/36, Loss: 0.3880\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 19/36, Loss: 0.4090\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 20/36, Loss: 0.4251\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 21/36, Loss: 0.4955\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 22/36, Loss: 0.4314\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 23/36, Loss: 0.2835\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 24/36, Loss: 0.4336\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 25/36, Loss: 0.5270\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 26/36, Loss: 0.3143\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 27/36, Loss: 0.3176\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 28/36, Loss: 0.4480\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 29/36, Loss: 0.4710\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 30/36, Loss: 0.4946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 31/36, Loss: 0.4195\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 32/36, Loss: 0.4422\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 33/36, Loss: 0.5236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 34/36, Loss: 0.3888\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 13/100, Batch 35/36, Loss: 0.4306\n",
      "Epoch 13/100, Average Loss: 0.4035, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 0/36, Loss: 0.5017\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 1/36, Loss: 0.0748\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 2/36, Loss: 0.4610\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 14/100, Batch 3/36, Loss: 0.0856\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 4/36, Loss: 0.4202\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 5/36, Loss: 0.4298\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 6/36, Loss: 0.3113\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 7/36, Loss: 0.3103\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 8/36, Loss: 0.4607\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 9/36, Loss: 0.4539\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 10/36, Loss: 0.4139\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 11/36, Loss: 0.3172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 12/36, Loss: 0.5343\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 13/36, Loss: 0.5172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 14/36, Loss: 0.4798\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 15/36, Loss: 0.4000\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 16/36, Loss: 0.3316\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 17/36, Loss: 0.4502\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 18/36, Loss: 0.4441\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 19/36, Loss: 0.4417\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 20/36, Loss: 0.5215\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 21/36, Loss: 0.3046\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 22/36, Loss: 0.5010\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 23/36, Loss: 0.4390\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 24/36, Loss: 0.5148\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 25/36, Loss: 0.4877\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 26/36, Loss: 0.4200\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 27/36, Loss: 0.1201\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 28/36, Loss: 0.4939\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 29/36, Loss: 0.3475\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 30/36, Loss: 0.4800\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 31/36, Loss: 0.3934\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 32/36, Loss: 0.4273\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 33/36, Loss: 0.2655\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 34/36, Loss: 0.5052\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 14/100, Batch 35/36, Loss: 0.4881\n",
      "Epoch 14/100, Average Loss: 0.4041, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 0/36, Loss: 0.3961\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 1/36, Loss: 0.4152\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 2/36, Loss: 0.4733\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 3/36, Loss: 0.4290\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 4/36, Loss: 0.4906\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 5/36, Loss: 0.0714\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 6/36, Loss: 0.4698\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 7/36, Loss: 0.4336\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 8/36, Loss: 0.4616\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 9/36, Loss: 0.5238\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 10/36, Loss: 0.3239\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 11/36, Loss: 0.4277\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 12/36, Loss: 0.4927\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 13/36, Loss: 0.4487\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 14/36, Loss: 0.3028\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 15/36, Loss: 0.3939\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 16/36, Loss: 0.4893\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 17/36, Loss: 0.5161\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 18/36, Loss: 0.4531\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 19/36, Loss: 0.4313\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 15/100, Batch 20/36, Loss: 0.0851\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 21/36, Loss: 0.4722\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 22/36, Loss: 0.5125\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 23/36, Loss: 0.4425\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 24/36, Loss: 0.2755\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 25/36, Loss: 0.5315\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 26/36, Loss: 0.5014\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 27/36, Loss: 0.3088\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 28/36, Loss: 0.3065\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 29/36, Loss: 0.4283\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 30/36, Loss: 0.5152\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 31/36, Loss: 0.3149\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 32/36, Loss: 0.1176\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 33/36, Loss: 0.3175\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 34/36, Loss: 0.4097\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 15/100, Batch 35/36, Loss: 0.5056\n",
      "Epoch 15/100, Average Loss: 0.4025, Valid Batches: 36/36\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 0/36, Loss: 0.3087\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 1/36, Loss: 0.3025\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 2/36, Loss: 0.4172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 3/36, Loss: 0.5071\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 4/36, Loss: 0.4558\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 5/36, Loss: 0.0756\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 6/36, Loss: 0.4366\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 7/36, Loss: 0.5339\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 8/36, Loss: 0.3881\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 9/36, Loss: 0.5189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 10/36, Loss: 0.4920\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 11/36, Loss: 0.4055\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 12/36, Loss: 0.4641\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 13/36, Loss: 0.4452\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 14/36, Loss: 0.3134\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 15/36, Loss: 0.3940\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 16/36, Loss: 0.4534\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 17/36, Loss: 0.4253\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 18/36, Loss: 0.4843\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 19/36, Loss: 0.4869\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 20/36, Loss: 0.4551\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 21/36, Loss: 0.4253\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 22/36, Loss: 0.3045\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 16/100, Batch 23/36, Loss: 0.0997\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 24/36, Loss: 0.4729\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 25/36, Loss: 0.5106\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 26/36, Loss: 0.2713\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 27/36, Loss: 0.3067\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 28/36, Loss: 0.3455\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 29/36, Loss: 0.5166\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 30/36, Loss: 0.4374\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 31/36, Loss: 0.5181\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 32/36, Loss: 0.4331\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 33/36, Loss: 0.5040\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 34/36, Loss: 0.4318\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 16/100, Batch 35/36, Loss: 0.1209\n",
      "Epoch 16/100, Average Loss: 0.4017, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 0/36, Loss: 0.4416\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 1/36, Loss: 0.1287\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 2/36, Loss: 0.2970\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 3/36, Loss: 0.4883\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 4/36, Loss: 0.5254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 5/36, Loss: 0.3036\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 6/36, Loss: 0.4903\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 7/36, Loss: 0.4234\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 8/36, Loss: 0.3128\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 9/36, Loss: 0.4261\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 10/36, Loss: 0.3147\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 11/36, Loss: 0.4512\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 12/36, Loss: 0.5104\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 17/100, Batch 13/36, Loss: 0.0947\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 14/36, Loss: 0.4284\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 15/36, Loss: 0.4110\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 16/36, Loss: 0.5154\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 17/36, Loss: 0.4217\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 18/36, Loss: 0.0697\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 19/36, Loss: 0.4468\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 20/36, Loss: 0.4119\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 21/36, Loss: 0.4434\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 22/36, Loss: 0.5173\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 23/36, Loss: 0.3340\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 24/36, Loss: 0.2794\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 25/36, Loss: 0.3101\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 26/36, Loss: 0.3859\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 27/36, Loss: 0.4640\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 28/36, Loss: 0.5231\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 29/36, Loss: 0.4073\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 30/36, Loss: 0.5039\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 31/36, Loss: 0.4663\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 32/36, Loss: 0.4902\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 33/36, Loss: 0.4640\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 34/36, Loss: 0.5223\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 17/100, Batch 35/36, Loss: 0.4766\n",
      "Epoch 17/100, Average Loss: 0.4028, Valid Batches: 36/36\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 0/36, Loss: 0.1300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 1/36, Loss: 0.4127\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 2/36, Loss: 0.3073\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 3/36, Loss: 0.4998\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 4/36, Loss: 0.3854\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 5/36, Loss: 0.5144\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 6/36, Loss: 0.5252\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 7/36, Loss: 0.4323\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 8/36, Loss: 0.5085\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 9/36, Loss: 0.4446\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 10/36, Loss: 0.4845\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 11/36, Loss: 0.5139\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 12/36, Loss: 0.4448\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 13/36, Loss: 0.5157\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 14/36, Loss: 0.3061\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 15/36, Loss: 0.4270\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 18/100, Batch 16/36, Loss: 0.0920\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 17/36, Loss: 0.4356\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 18/36, Loss: 0.4781\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 19/36, Loss: 0.3427\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 20/36, Loss: 0.4578\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 21/36, Loss: 0.4526\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 22/36, Loss: 0.2832\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 23/36, Loss: 0.5113\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 24/36, Loss: 0.2938\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 25/36, Loss: 0.0652\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 26/36, Loss: 0.4901\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 27/36, Loss: 0.4666\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 28/36, Loss: 0.4362\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 29/36, Loss: 0.3130\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 30/36, Loss: 0.3846\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 31/36, Loss: 0.3181\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 32/36, Loss: 0.4979\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 33/36, Loss: 0.4217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 34/36, Loss: 0.4664\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 18/100, Batch 35/36, Loss: 0.4083\n",
      "Epoch 18/100, Average Loss: 0.4019, Valid Batches: 36/36\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 0/36, Loss: 0.2775\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 1/36, Loss: 0.5176\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 2/36, Loss: 0.4213\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 3/36, Loss: 0.4911\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 4/36, Loss: 0.5256\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 5/36, Loss: 0.4655\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 6/36, Loss: 0.3917\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 7/36, Loss: 0.4306\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 8/36, Loss: 0.4320\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 9/36, Loss: 0.3057\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 10/36, Loss: 0.3837\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 11/36, Loss: 0.4886\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 12/36, Loss: 0.4525\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 13/36, Loss: 0.4132\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 14/36, Loss: 0.2964\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 15/36, Loss: 0.2841\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 16/36, Loss: 0.4889\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 17/36, Loss: 0.4404\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 18/36, Loss: 0.5107\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 19/36, Loss: 0.1258\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 20/36, Loss: 0.4649\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 21/36, Loss: 0.3116\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 22/36, Loss: 0.5219\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 23/36, Loss: 0.3385\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 24/36, Loss: 0.5110\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 25/36, Loss: 0.4198\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 26/36, Loss: 0.0710\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 27/36, Loss: 0.4740\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 19/100, Batch 28/36, Loss: 0.0860\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 29/36, Loss: 0.4259\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 30/36, Loss: 0.4098\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 31/36, Loss: 0.4939\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 32/36, Loss: 0.3043\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 33/36, Loss: 0.5044\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 34/36, Loss: 0.4391\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 19/100, Batch 35/36, Loss: 0.4564\n",
      "Epoch 19/100, Average Loss: 0.3993, Valid Batches: 36/36\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 0/36, Loss: 0.4887\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 1/36, Loss: 0.3003\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 2/36, Loss: 0.4580\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 3/36, Loss: 0.4230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 4/36, Loss: 0.5210\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 5/36, Loss: 0.3075\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 6/36, Loss: 0.5070\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 7/36, Loss: 0.3005\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 8/36, Loss: 0.5169\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 9/36, Loss: 0.3188\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 10/36, Loss: 0.4437\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 11/36, Loss: 0.4639\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 12/36, Loss: 0.2879\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 13/36, Loss: 0.4526\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 14/36, Loss: 0.5172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 15/36, Loss: 0.4946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 16/36, Loss: 0.4262\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 17/36, Loss: 0.1310\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 18/36, Loss: 0.4267\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 19/36, Loss: 0.4180\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 20/36, Loss: 0.4534\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 21/36, Loss: 0.5116\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 22/36, Loss: 0.4725\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 23/36, Loss: 0.4632\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 24/36, Loss: 0.5186\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 25/36, Loss: 0.0716\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 20/100, Batch 26/36, Loss: 0.0897\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 27/36, Loss: 0.3203\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 28/36, Loss: 0.4881\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 29/36, Loss: 0.5237\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 30/36, Loss: 0.2991\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 31/36, Loss: 0.4221\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 32/36, Loss: 0.3937\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 33/36, Loss: 0.4591\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 34/36, Loss: 0.4186\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 20/100, Batch 35/36, Loss: 0.4280\n",
      "Epoch 20/100, Average Loss: 0.4038, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 0/36, Loss: 0.4018\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 1/36, Loss: 0.4330\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 2/36, Loss: 0.0608\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 3/36, Loss: 0.4375\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 4/36, Loss: 0.3119\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 5/36, Loss: 0.4767\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 6/36, Loss: 0.5188\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 7/36, Loss: 0.5300\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 8/36, Loss: 0.3197\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 9/36, Loss: 0.4307\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 10/36, Loss: 0.4620\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 11/36, Loss: 0.1279\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 12/36, Loss: 0.3000\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 13/36, Loss: 0.5151\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 14/36, Loss: 0.4572\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 15/36, Loss: 0.4915\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 16/36, Loss: 0.3199\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 17/36, Loss: 0.4609\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 18/36, Loss: 0.4142\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 19/36, Loss: 0.4374\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 20/36, Loss: 0.4000\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 21/36, Loss: 0.4208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 22/36, Loss: 0.4193\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 23/36, Loss: 0.2836\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 24/36, Loss: 0.5274\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 25/36, Loss: 0.5009\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 26/36, Loss: 0.5105\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 27/36, Loss: 0.4639\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 21/100, Batch 28/36, Loss: 0.0932\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 29/36, Loss: 0.4853\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 30/36, Loss: 0.4961\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 31/36, Loss: 0.2995\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 32/36, Loss: 0.3169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 33/36, Loss: 0.4303\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 34/36, Loss: 0.5021\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 21/100, Batch 35/36, Loss: 0.4300\n",
      "Epoch 21/100, Average Loss: 0.4024, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 0/36, Loss: 0.4692\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 1/36, Loss: 0.4245\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 2/36, Loss: 0.4174\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 3/36, Loss: 0.4928\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 4/36, Loss: 0.3743\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 5/36, Loss: 0.4936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 6/36, Loss: 0.4321\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 7/36, Loss: 0.3138\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 8/36, Loss: 0.4891\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 9/36, Loss: 0.5076\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 10/36, Loss: 0.4436\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 11/36, Loss: 0.4599\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 12/36, Loss: 0.4691\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 13/36, Loss: 0.5214\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 14/36, Loss: 0.3088\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 15/36, Loss: 0.4560\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 16/36, Loss: 0.5270\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 17/36, Loss: 0.0644\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 18/36, Loss: 0.3040\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 19/36, Loss: 0.2988\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 20/36, Loss: 0.3129\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 21/36, Loss: 0.3933\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 22/100, Batch 22/36, Loss: 0.0899\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 23/36, Loss: 0.4236\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 24/36, Loss: 0.1192\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 25/36, Loss: 0.3308\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 26/36, Loss: 0.4216\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 27/36, Loss: 0.5062\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 28/36, Loss: 0.4570\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 29/36, Loss: 0.5107\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 30/36, Loss: 0.4541\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 31/36, Loss: 0.4175\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 32/36, Loss: 0.5125\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 33/36, Loss: 0.4416\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 34/36, Loss: 0.2842\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 22/100, Batch 35/36, Loss: 0.4795\n",
      "Epoch 22/100, Average Loss: 0.4006, Valid Batches: 36/36\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 0/36, Loss: 0.3131\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 1/36, Loss: 0.2946\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 2/36, Loss: 0.2813\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 3/36, Loss: 0.4552\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 4/36, Loss: 0.3677\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 5/36, Loss: 0.4642\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 6/36, Loss: 0.5205\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 7/36, Loss: 0.3155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 8/36, Loss: 0.4268\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 9/36, Loss: 0.3956\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 10/36, Loss: 0.5134\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 11/36, Loss: 0.5246\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 12/36, Loss: 0.4231\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 23/100, Batch 13/36, Loss: 0.0858\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 14/36, Loss: 0.4071\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 15/36, Loss: 0.2955\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 16/36, Loss: 0.4745\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 17/36, Loss: 0.4947\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 18/36, Loss: 0.5182\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 19/36, Loss: 0.4292\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 20/36, Loss: 0.4417\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 21/36, Loss: 0.3243\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 22/36, Loss: 0.5158\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 23/36, Loss: 0.4302\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 24/36, Loss: 0.3016\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 25/36, Loss: 0.0617\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 26/36, Loss: 0.4134\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 27/36, Loss: 0.5070\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 28/36, Loss: 0.1192\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 29/36, Loss: 0.4943\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 30/36, Loss: 0.4367\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 31/36, Loss: 0.4840\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 32/36, Loss: 0.4382\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 33/36, Loss: 0.4727\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 34/36, Loss: 0.4862\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 23/100, Batch 35/36, Loss: 0.4514\n",
      "Epoch 23/100, Average Loss: 0.3994, Valid Batches: 36/36\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 0/36, Loss: 0.2819\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 1/36, Loss: 0.3079\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 24/100, Batch 2/36, Loss: 0.0812\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 3/36, Loss: 0.4595\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 4/36, Loss: 0.4191\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 5/36, Loss: 0.2984\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 6/36, Loss: 0.4405\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 7/36, Loss: 0.5087\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 8/36, Loss: 0.3046\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 9/36, Loss: 0.5147\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 10/36, Loss: 0.3389\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 11/36, Loss: 0.3872\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 12/36, Loss: 0.4865\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 13/36, Loss: 0.4592\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 14/36, Loss: 0.4200\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 15/36, Loss: 0.5066\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 16/36, Loss: 0.4177\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 17/36, Loss: 0.4347\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 18/36, Loss: 0.4123\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 19/36, Loss: 0.4691\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 20/36, Loss: 0.1220\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 21/36, Loss: 0.4384\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 22/36, Loss: 0.4435\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 23/36, Loss: 0.4598\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 24/36, Loss: 0.2979\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 25/36, Loss: 0.4957\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 26/36, Loss: 0.5279\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 27/36, Loss: 0.3910\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 28/36, Loss: 0.4384\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 29/36, Loss: 0.3006\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 30/36, Loss: 0.4906\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 31/36, Loss: 0.5089\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 32/36, Loss: 0.5028\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 33/36, Loss: 0.0692\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 34/36, Loss: 0.4785\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 24/100, Batch 35/36, Loss: 0.5160\n",
      "Epoch 24/100, Average Loss: 0.4008, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 0/36, Loss: 0.4538\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 1/36, Loss: 0.5237\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 2/36, Loss: 0.4749\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 3/36, Loss: 0.4998\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 4/36, Loss: 0.1184\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 5/36, Loss: 0.5001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 6/36, Loss: 0.4382\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 7/36, Loss: 0.2933\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 8/36, Loss: 0.3167\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 9/36, Loss: 0.5146\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 10/36, Loss: 0.4274\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 11/36, Loss: 0.5041\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 12/36, Loss: 0.4172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 13/36, Loss: 0.3892\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 14/36, Loss: 0.4399\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 15/36, Loss: 0.4908\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 16/36, Loss: 0.5139\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 17/36, Loss: 0.3930\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 18/36, Loss: 0.4694\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 19/36, Loss: 0.2982\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 20/36, Loss: 0.4869\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 21/36, Loss: 0.5335\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 22/36, Loss: 0.3024\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 23/36, Loss: 0.4255\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 24/36, Loss: 0.3074\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 25/36, Loss: 0.3149\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 26/36, Loss: 0.4364\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 27/36, Loss: 0.4652\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 28/36, Loss: 0.4107\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 29/36, Loss: 0.3160\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 30/36, Loss: 0.4111\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 25/100, Batch 31/36, Loss: 0.0847\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 32/36, Loss: 0.4293\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 33/36, Loss: 0.4919\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 34/36, Loss: 0.0696\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 25/100, Batch 35/36, Loss: 0.4531\n",
      "Epoch 25/100, Average Loss: 0.4004, Valid Batches: 36/36\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 0/36, Loss: 0.1220\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 1/36, Loss: 0.4257\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 2/36, Loss: 0.0693\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 3/36, Loss: 0.4394\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 4/36, Loss: 0.3100\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 5/36, Loss: 0.4986\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 6/36, Loss: 0.4374\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 7/36, Loss: 0.3152\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 8/36, Loss: 0.3907\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 26/100, Batch 9/36, Loss: 0.0820\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 10/36, Loss: 0.4793\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 11/36, Loss: 0.5262\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 12/36, Loss: 0.3291\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 13/36, Loss: 0.5129\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 14/36, Loss: 0.4104\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 15/36, Loss: 0.4613\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 16/36, Loss: 0.4201\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 17/36, Loss: 0.3032\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 18/36, Loss: 0.4687\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 19/36, Loss: 0.3025\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 20/36, Loss: 0.5137\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 21/36, Loss: 0.4906\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 22/36, Loss: 0.5221\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 23/36, Loss: 0.4279\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 24/36, Loss: 0.4498\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 25/36, Loss: 0.5062\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 26/36, Loss: 0.3884\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 27/36, Loss: 0.4251\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 28/36, Loss: 0.4680\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 29/36, Loss: 0.4827\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 30/36, Loss: 0.4518\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 31/36, Loss: 0.5186\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 32/36, Loss: 0.4998\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 33/36, Loss: 0.4404\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 34/36, Loss: 0.2753\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 26/100, Batch 35/36, Loss: 0.3030\n",
      "Epoch 26/100, Average Loss: 0.4019, Valid Batches: 36/36\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 0/36, Loss: 0.2996\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 1/36, Loss: 0.5091\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 2/36, Loss: 0.1279\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 3/36, Loss: 0.4362\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 4/36, Loss: 0.4735\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 5/36, Loss: 0.5240\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 6/36, Loss: 0.4595\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 7/36, Loss: 0.3784\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 8/36, Loss: 0.4321\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 9/36, Loss: 0.4249\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 10/36, Loss: 0.3030\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 11/36, Loss: 0.4792\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 12/36, Loss: 0.4135\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 13/36, Loss: 0.2775\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 14/36, Loss: 0.4969\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 15/36, Loss: 0.5257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 16/36, Loss: 0.4549\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 17/36, Loss: 0.4910\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 18/36, Loss: 0.4186\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 19/36, Loss: 0.4340\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 20/36, Loss: 0.5151\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 27/100, Batch 21/36, Loss: 0.0874\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 22/36, Loss: 0.4565\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 23/36, Loss: 0.2901\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 24/36, Loss: 0.4375\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 25/36, Loss: 0.3029\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 26/36, Loss: 0.3750\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 27/36, Loss: 0.4096\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 28/36, Loss: 0.0666\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 29/36, Loss: 0.4911\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 30/36, Loss: 0.3143\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 31/36, Loss: 0.5123\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 32/36, Loss: 0.4266\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 33/36, Loss: 0.5234\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 34/36, Loss: 0.4935\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 27/100, Batch 35/36, Loss: 0.3097\n",
      "Epoch 27/100, Average Loss: 0.3992, Valid Batches: 36/36\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 28/100, Batch 0/36, Loss: 0.0766\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 1/36, Loss: 0.5033\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 2/36, Loss: 0.2747\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 3/36, Loss: 0.4367\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 4/36, Loss: 0.4982\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 5/36, Loss: 0.4214\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 6/36, Loss: 0.3228\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 7/36, Loss: 0.3080\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 8/36, Loss: 0.4564\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 9/36, Loss: 0.2908\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 10/36, Loss: 0.4875\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 11/36, Loss: 0.4147\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 12/36, Loss: 0.4665\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 13/36, Loss: 0.0742\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 14/36, Loss: 0.4165\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 15/36, Loss: 0.4134\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 16/36, Loss: 0.4600\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 17/36, Loss: 0.4287\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 18/36, Loss: 0.3025\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 19/36, Loss: 0.3884\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 20/36, Loss: 0.3155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 21/36, Loss: 0.4960\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 22/36, Loss: 0.3162\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 23/36, Loss: 0.4513\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 24/36, Loss: 0.4938\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 25/36, Loss: 0.5204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 26/36, Loss: 0.4606\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 27/36, Loss: 0.4950\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 28/36, Loss: 0.5006\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 29/36, Loss: 0.1255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 30/36, Loss: 0.4264\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 31/36, Loss: 0.3998\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 32/36, Loss: 0.5196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 33/36, Loss: 0.4283\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 34/36, Loss: 0.4719\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 28/100, Batch 35/36, Loss: 0.5185\n",
      "Epoch 28/100, Average Loss: 0.3995, Valid Batches: 36/36\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 0/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 1/36, Loss: 0.4552\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 2/36, Loss: 0.5046\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 3/36, Loss: 0.3823\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 4/36, Loss: 0.4543\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 5/36, Loss: 0.5122\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 6/36, Loss: 0.4334\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 7/36, Loss: 0.4172\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 8/36, Loss: 0.1199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 9/36, Loss: 0.4325\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 29/100, Batch 10/36, Loss: 0.0793\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 11/36, Loss: 0.5081\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 12/36, Loss: 0.4650\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 13/36, Loss: 0.5055\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 14/36, Loss: 0.5269\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 15/36, Loss: 0.3258\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 16/36, Loss: 0.4164\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 17/36, Loss: 0.4851\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 18/36, Loss: 0.4417\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 19/36, Loss: 0.4969\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 20/36, Loss: 0.4804\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 21/36, Loss: 0.4215\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 22/36, Loss: 0.0683\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 23/36, Loss: 0.3874\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 24/36, Loss: 0.3095\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 25/36, Loss: 0.4254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 26/36, Loss: 0.4318\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 27/36, Loss: 0.4600\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 28/36, Loss: 0.5182\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 29/36, Loss: 0.5039\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 30/36, Loss: 0.3016\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 31/36, Loss: 0.4705\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 32/36, Loss: 0.2778\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 33/36, Loss: 0.4493\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 34/36, Loss: 0.3073\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 29/100, Batch 35/36, Loss: 0.2968\n",
      "Epoch 29/100, Average Loss: 0.3991, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 0/36, Loss: 0.3820\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 1/36, Loss: 0.5226\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 2/36, Loss: 0.4279\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 3/36, Loss: 0.3055\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 4/36, Loss: 0.4285\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 5/36, Loss: 0.3829\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 6/36, Loss: 0.4377\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 7/36, Loss: 0.0712\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 8/36, Loss: 0.4079\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 9/36, Loss: 0.4944\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 10/36, Loss: 0.5077\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 11/36, Loss: 0.2908\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 12/36, Loss: 0.4898\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 13/36, Loss: 0.4235\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 14/36, Loss: 0.4018\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 15/36, Loss: 0.4801\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 16/36, Loss: 0.4485\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 17/36, Loss: 0.4731\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 18/36, Loss: 0.4925\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 30/100, Batch 19/36, Loss: 0.0833\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 20/36, Loss: 0.3065\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 21/36, Loss: 0.4103\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 22/36, Loss: 0.5144\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 23/36, Loss: 0.4830\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 24/36, Loss: 0.2959\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 25/36, Loss: 0.5102\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 26/36, Loss: 0.4257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 27/36, Loss: 0.5031\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 28/36, Loss: 0.1112\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 29/36, Loss: 0.3120\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 30/36, Loss: 0.3433\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 31/36, Loss: 0.2951\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 32/36, Loss: 0.5250\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 33/36, Loss: 0.4601\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 34/36, Loss: 0.4334\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 30/100, Batch 35/36, Loss: 0.4553\n",
      "Epoch 30/100, Average Loss: 0.3982, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 0/36, Loss: 0.4932\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 1/36, Loss: 0.3076\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 2/36, Loss: 0.3008\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 3/36, Loss: 0.2953\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 4/36, Loss: 0.4156\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 5/36, Loss: 0.4620\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 6/36, Loss: 0.1229\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 7/36, Loss: 0.3039\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 8/36, Loss: 0.4269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 9/36, Loss: 0.4312\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 10/36, Loss: 0.4887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 11/36, Loss: 0.4514\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 12/36, Loss: 0.4508\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 13/36, Loss: 0.5122\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 14/36, Loss: 0.5301\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 15/36, Loss: 0.3179\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 16/36, Loss: 0.5014\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 17/36, Loss: 0.5219\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 18/36, Loss: 0.4747\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 19/36, Loss: 0.3854\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 20/36, Loss: 0.5097\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 21/36, Loss: 0.2839\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 22/36, Loss: 0.4724\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 23/36, Loss: 0.4978\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 24/36, Loss: 0.4224\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 31/100, Batch 25/36, Loss: 0.0936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 26/36, Loss: 0.4550\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 27/36, Loss: 0.5221\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 28/36, Loss: 0.0722\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 29/36, Loss: 0.4167\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 30/36, Loss: 0.2968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 31/36, Loss: 0.4623\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 32/36, Loss: 0.4130\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 33/36, Loss: 0.4403\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 34/36, Loss: 0.4318\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 31/100, Batch 35/36, Loss: 0.4276\n",
      "Epoch 31/100, Average Loss: 0.4003, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 0/36, Loss: 0.4732\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 1/36, Loss: 0.5199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 2/36, Loss: 0.4490\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 3/36, Loss: 0.2936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 4/36, Loss: 0.4127\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 5/36, Loss: 0.5287\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 6/36, Loss: 0.4363\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 7/36, Loss: 0.5244\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 8/36, Loss: 0.3083\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 9/36, Loss: 0.4912\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 10/36, Loss: 0.5065\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 11/36, Loss: 0.0607\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 12/36, Loss: 0.4522\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 13/36, Loss: 0.4282\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 14/36, Loss: 0.4207\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 15/36, Loss: 0.5051\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 16/36, Loss: 0.3962\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 17/36, Loss: 0.5073\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 18/36, Loss: 0.4437\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 32/100, Batch 19/36, Loss: 0.0840\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 20/36, Loss: 0.4219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 21/36, Loss: 0.4336\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 22/36, Loss: 0.4187\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 23/36, Loss: 0.3368\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 24/36, Loss: 0.4658\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 25/36, Loss: 0.3030\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 26/36, Loss: 0.4442\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 27/36, Loss: 0.4771\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 28/36, Loss: 0.2794\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 29/36, Loss: 0.3824\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 30/36, Loss: 0.4941\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 31/36, Loss: 0.1334\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 32/36, Loss: 0.4934\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 33/36, Loss: 0.3006\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 34/36, Loss: 0.4207\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 32/100, Batch 35/36, Loss: 0.3044\n",
      "Epoch 32/100, Average Loss: 0.3986, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 0/36, Loss: 0.3619\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 1/36, Loss: 0.2775\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 2/36, Loss: 0.4539\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 3/36, Loss: 0.4584\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 33/100, Batch 4/36, Loss: 0.0982\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 5/36, Loss: 0.5210\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 6/36, Loss: 0.5187\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 7/36, Loss: 0.0715\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 8/36, Loss: 0.4579\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 9/36, Loss: 0.2961\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 10/36, Loss: 0.4076\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 11/36, Loss: 0.4957\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 12/36, Loss: 0.4141\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 13/36, Loss: 0.3304\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 14/36, Loss: 0.5116\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 15/36, Loss: 0.3107\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 16/36, Loss: 0.4388\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 17/36, Loss: 0.5022\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 18/36, Loss: 0.4738\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 19/36, Loss: 0.4893\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 20/36, Loss: 0.4782\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 21/36, Loss: 0.5255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 22/36, Loss: 0.4119\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 23/36, Loss: 0.3812\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 24/36, Loss: 0.5149\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 25/36, Loss: 0.2889\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 26/36, Loss: 0.4232\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 27/36, Loss: 0.4276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 28/36, Loss: 0.3166\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 29/36, Loss: 0.2897\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 30/36, Loss: 0.4109\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 31/36, Loss: 0.4488\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 32/36, Loss: 0.4937\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 33/36, Loss: 0.4727\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 34/36, Loss: 0.1229\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 33/100, Batch 35/36, Loss: 0.4402\n",
      "Epoch 33/100, Average Loss: 0.3982, Valid Batches: 36/36\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 0/36, Loss: 0.0661\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 1/36, Loss: 0.5216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 2/36, Loss: 0.4941\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 3/36, Loss: 0.4659\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 4/36, Loss: 0.4106\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 5/36, Loss: 0.4493\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 34/100, Batch 6/36, Loss: 0.0926\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 7/36, Loss: 0.4259\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 8/36, Loss: 0.4300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 9/36, Loss: 0.4206\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 10/36, Loss: 0.3059\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 11/36, Loss: 0.4278\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 12/36, Loss: 0.3912\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 13/36, Loss: 0.4768\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 14/36, Loss: 0.5086\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 15/36, Loss: 0.2949\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 16/36, Loss: 0.3153\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 17/36, Loss: 0.3212\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 18/36, Loss: 0.2910\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 19/36, Loss: 0.3840\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 20/36, Loss: 0.4595\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 21/36, Loss: 0.4170\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 22/36, Loss: 0.4870\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 23/36, Loss: 0.3043\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 24/36, Loss: 0.4389\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 25/36, Loss: 0.5079\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 26/36, Loss: 0.4807\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 27/36, Loss: 0.4632\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 28/36, Loss: 0.4827\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 29/36, Loss: 0.5096\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 30/36, Loss: 0.5257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 31/36, Loss: 0.4994\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 32/36, Loss: 0.1134\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 33/36, Loss: 0.4319\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 34/36, Loss: 0.2908\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 34/100, Batch 35/36, Loss: 0.4475\n",
      "Epoch 34/100, Average Loss: 0.3987, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 0/36, Loss: 0.4662\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 1/36, Loss: 0.4507\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 2/36, Loss: 0.4216\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 3/36, Loss: 0.4474\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 4/36, Loss: 0.1169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 5/36, Loss: 0.3876\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 6/36, Loss: 0.4988\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 7/36, Loss: 0.2943\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 8/36, Loss: 0.4260\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 9/36, Loss: 0.3100\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 10/36, Loss: 0.5206\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 11/36, Loss: 0.4222\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 12/36, Loss: 0.5019\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 13/36, Loss: 0.4393\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 14/36, Loss: 0.4849\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 15/36, Loss: 0.3180\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 16/36, Loss: 0.4134\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 17/36, Loss: 0.4370\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 18/36, Loss: 0.3936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 19/36, Loss: 0.4117\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 20/36, Loss: 0.4792\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 21/36, Loss: 0.4443\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 22/36, Loss: 0.3171\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 35/100, Batch 23/36, Loss: 0.0966\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 24/36, Loss: 0.5276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 25/36, Loss: 0.5122\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 26/36, Loss: 0.4893\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 27/36, Loss: 0.5117\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 28/36, Loss: 0.4942\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 29/36, Loss: 0.4872\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 30/36, Loss: 0.2694\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 31/36, Loss: 0.3058\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 32/36, Loss: 0.4695\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 33/36, Loss: 0.4213\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 34/36, Loss: 0.0741\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 35/100, Batch 35/36, Loss: 0.3095\n",
      "Epoch 35/100, Average Loss: 0.3992, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 0/36, Loss: 0.4255\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 1/36, Loss: 0.4876\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 2/36, Loss: 0.4836\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 3/36, Loss: 0.4569\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 4/36, Loss: 0.4927\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 5/36, Loss: 0.5088\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 6/36, Loss: 0.3726\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 7/36, Loss: 0.3259\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 8/36, Loss: 0.5097\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 9/36, Loss: 0.3064\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 10/36, Loss: 0.4233\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 11/36, Loss: 0.5002\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 12/36, Loss: 0.4086\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 13/36, Loss: 0.4629\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 14/36, Loss: 0.4745\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 15/36, Loss: 0.1232\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 16/36, Loss: 0.4068\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 17/36, Loss: 0.2963\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 18/36, Loss: 0.2812\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 19/36, Loss: 0.0632\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 20/36, Loss: 0.4482\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 21/36, Loss: 0.4394\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 22/36, Loss: 0.3053\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 23/36, Loss: 0.5266\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 24/36, Loss: 0.4084\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 36/100, Batch 25/36, Loss: 0.0807\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 26/36, Loss: 0.4355\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 27/36, Loss: 0.4640\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 28/36, Loss: 0.2973\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 29/36, Loss: 0.5153\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 30/36, Loss: 0.3774\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 31/36, Loss: 0.4851\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 32/36, Loss: 0.5356\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 33/36, Loss: 0.3208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 34/36, Loss: 0.4327\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 36/100, Batch 35/36, Loss: 0.4460\n",
      "Epoch 36/100, Average Loss: 0.3980, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 0/36, Loss: 0.5055\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 1/36, Loss: 0.5242\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 2/36, Loss: 0.3726\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 3/36, Loss: 0.3028\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 4/36, Loss: 0.4382\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 5/36, Loss: 0.5065\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 6/36, Loss: 0.4624\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 7/36, Loss: 0.4927\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 8/36, Loss: 0.4779\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 9/36, Loss: 0.3072\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 10/36, Loss: 0.2786\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 11/36, Loss: 0.4241\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 12/36, Loss: 0.4057\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 13/36, Loss: 0.4266\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 14/36, Loss: 0.4182\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 15/36, Loss: 0.4305\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 37/100, Batch 16/36, Loss: 0.0908\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 17/36, Loss: 0.0686\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 18/36, Loss: 0.4386\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 19/36, Loss: 0.4371\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 20/36, Loss: 0.2970\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 21/36, Loss: 0.3040\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 22/36, Loss: 0.4706\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 23/36, Loss: 0.3249\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 24/36, Loss: 0.4880\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 25/36, Loss: 0.4538\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 26/36, Loss: 0.2962\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 27/36, Loss: 0.4977\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 28/36, Loss: 0.1215\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 29/36, Loss: 0.5126\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 30/36, Loss: 0.4585\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 31/36, Loss: 0.5307\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 32/36, Loss: 0.4291\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 33/36, Loss: 0.5138\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 34/36, Loss: 0.3870\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 37/100, Batch 35/36, Loss: 0.4747\n",
      "Epoch 37/100, Average Loss: 0.3991, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 0/36, Loss: 0.5142\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 1/36, Loss: 0.3937\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 2/36, Loss: 0.4342\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 3/36, Loss: 0.4111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 4/36, Loss: 0.2970\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 5/36, Loss: 0.3223\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 6/36, Loss: 0.5203\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 7/36, Loss: 0.4172\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 8/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 9/36, Loss: 0.3845\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 10/36, Loss: 0.4267\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 11/36, Loss: 0.4816\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 12/36, Loss: 0.4680\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 13/36, Loss: 0.4930\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 14/36, Loss: 0.4516\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 15/36, Loss: 0.3123\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 16/36, Loss: 0.4055\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 17/36, Loss: 0.3123\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 18/36, Loss: 0.4314\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 19/36, Loss: 0.5054\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 20/36, Loss: 0.5082\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 21/36, Loss: 0.4778\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 22/36, Loss: 0.4886\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 23/36, Loss: 0.5185\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 24/36, Loss: 0.5046\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 38/100, Batch 25/36, Loss: 0.0809\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 26/36, Loss: 0.4206\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 27/36, Loss: 0.4323\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 28/36, Loss: 0.1184\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 29/36, Loss: 0.4589\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 30/36, Loss: 0.4540\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 31/36, Loss: 0.2859\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 32/36, Loss: 0.3131\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 33/36, Loss: 0.5007\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 34/36, Loss: 0.0679\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 38/100, Batch 35/36, Loss: 0.4205\n",
      "Epoch 38/100, Average Loss: 0.3980, Valid Batches: 36/36\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 0/36, Loss: 0.3359\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 1/36, Loss: 0.3875\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 2/36, Loss: 0.4924\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 3/36, Loss: 0.4048\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 4/36, Loss: 0.4623\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 5/36, Loss: 0.4519\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 6/36, Loss: 0.3890\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 7/36, Loss: 0.4136\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 8/36, Loss: 0.1292\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 9/36, Loss: 0.3147\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 10/36, Loss: 0.0759\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 11/36, Loss: 0.4967\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 12/36, Loss: 0.5184\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 13/36, Loss: 0.4309\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 14/36, Loss: 0.2978\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 15/36, Loss: 0.4158\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 16/36, Loss: 0.2771\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 17/36, Loss: 0.5205\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 18/36, Loss: 0.2958\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 39/100, Batch 19/36, Loss: 0.0835\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 20/36, Loss: 0.3140\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 21/36, Loss: 0.4687\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 22/36, Loss: 0.2996\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 23/36, Loss: 0.4601\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 24/36, Loss: 0.4217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 25/36, Loss: 0.5214\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 26/36, Loss: 0.4233\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 27/36, Loss: 0.4394\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 28/36, Loss: 0.4273\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 29/36, Loss: 0.5173\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 30/36, Loss: 0.4559\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 31/36, Loss: 0.4336\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 32/36, Loss: 0.4756\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 33/36, Loss: 0.5135\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 34/36, Loss: 0.5135\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 39/100, Batch 35/36, Loss: 0.4871\n",
      "Epoch 39/100, Average Loss: 0.3990, Valid Batches: 36/36\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 0/36, Loss: 0.3284\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 1/36, Loss: 0.4998\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 2/36, Loss: 0.4278\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 40/100, Batch 3/36, Loss: 0.0823\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 4/36, Loss: 0.4785\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 5/36, Loss: 0.4318\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 6/36, Loss: 0.4695\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 7/36, Loss: 0.4010\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 8/36, Loss: 0.4438\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 9/36, Loss: 0.3995\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 10/36, Loss: 0.2950\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 11/36, Loss: 0.4396\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 12/36, Loss: 0.4870\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 13/36, Loss: 0.4944\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 14/36, Loss: 0.4841\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 15/36, Loss: 0.5023\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 16/36, Loss: 0.1211\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 17/36, Loss: 0.3159\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 18/36, Loss: 0.5182\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 19/36, Loss: 0.0647\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 20/36, Loss: 0.2764\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 21/36, Loss: 0.4222\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 22/36, Loss: 0.4187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 23/36, Loss: 0.4226\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 24/36, Loss: 0.5187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 25/36, Loss: 0.5162\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 26/36, Loss: 0.4702\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 27/36, Loss: 0.4497\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 28/36, Loss: 0.2950\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 29/36, Loss: 0.4320\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 30/36, Loss: 0.3009\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 31/36, Loss: 0.5035\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 32/36, Loss: 0.4251\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 33/36, Loss: 0.4465\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 34/36, Loss: 0.3060\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 40/100, Batch 35/36, Loss: 0.3799\n",
      "Epoch 40/100, Average Loss: 0.3963, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 0/36, Loss: 0.3751\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 1/36, Loss: 0.4985\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 2/36, Loss: 0.5026\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 3/36, Loss: 0.1238\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 4/36, Loss: 0.2844\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 5/36, Loss: 0.0671\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 6/36, Loss: 0.4155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 7/36, Loss: 0.5198\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 8/36, Loss: 0.4338\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 9/36, Loss: 0.4229\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 10/36, Loss: 0.2945\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 11/36, Loss: 0.2893\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 12/36, Loss: 0.4375\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 13/36, Loss: 0.4700\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 14/36, Loss: 0.4516\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 15/36, Loss: 0.4613\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 16/36, Loss: 0.5058\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 17/36, Loss: 0.3302\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 18/36, Loss: 0.3053\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 19/36, Loss: 0.4623\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 20/36, Loss: 0.3868\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 21/36, Loss: 0.2992\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 22/36, Loss: 0.3001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 23/36, Loss: 0.4564\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 24/36, Loss: 0.5178\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 25/36, Loss: 0.5329\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 26/36, Loss: 0.4926\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 41/100, Batch 27/36, Loss: 0.0927\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 28/36, Loss: 0.4266\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 29/36, Loss: 0.4047\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 30/36, Loss: 0.5152\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 31/36, Loss: 0.4805\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 32/36, Loss: 0.4264\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 33/36, Loss: 0.4871\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 34/36, Loss: 0.4229\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 41/100, Batch 35/36, Loss: 0.4325\n",
      "Epoch 41/100, Average Loss: 0.3979, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 0/36, Loss: 0.3764\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 1/36, Loss: 0.4183\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 42/100, Batch 2/36, Loss: 0.0931\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 3/36, Loss: 0.4990\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 4/36, Loss: 0.4177\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 5/36, Loss: 0.4103\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 6/36, Loss: 0.4991\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 7/36, Loss: 0.4423\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 8/36, Loss: 0.3847\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 9/36, Loss: 0.2983\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 10/36, Loss: 0.3131\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 11/36, Loss: 0.0640\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 12/36, Loss: 0.4976\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 13/36, Loss: 0.4710\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 14/36, Loss: 0.4896\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 15/36, Loss: 0.4750\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 16/36, Loss: 0.3198\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 17/36, Loss: 0.2881\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 18/36, Loss: 0.4119\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 19/36, Loss: 0.4587\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 20/36, Loss: 0.4395\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 21/36, Loss: 0.2970\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 22/36, Loss: 0.4887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 23/36, Loss: 0.2932\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 24/36, Loss: 0.5118\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 25/36, Loss: 0.5283\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 26/36, Loss: 0.4427\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 27/36, Loss: 0.2996\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 28/36, Loss: 0.4311\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 29/36, Loss: 0.1324\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 30/36, Loss: 0.5064\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 31/36, Loss: 0.4665\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 32/36, Loss: 0.4514\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 33/36, Loss: 0.4472\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 34/36, Loss: 0.5238\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 42/100, Batch 35/36, Loss: 0.4153\n",
      "Epoch 42/100, Average Loss: 0.3973, Valid Batches: 36/36\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 0/36, Loss: 0.4759\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 1/36, Loss: 0.4864\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 2/36, Loss: 0.3165\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 3/36, Loss: 0.3011\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 4/36, Loss: 0.4397\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 5/36, Loss: 0.5225\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 6/36, Loss: 0.4246\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 7/36, Loss: 0.4308\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 8/36, Loss: 0.1162\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 9/36, Loss: 0.4250\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 10/36, Loss: 0.4592\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 11/36, Loss: 0.4946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 12/36, Loss: 0.5199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 13/36, Loss: 0.4186\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 14/36, Loss: 0.2926\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 15/36, Loss: 0.4341\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 16/36, Loss: 0.4214\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 17/36, Loss: 0.2953\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 18/36, Loss: 0.3856\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 19/36, Loss: 0.4045\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 20/36, Loss: 0.4556\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 21/36, Loss: 0.4157\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 22/36, Loss: 0.3035\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 23/36, Loss: 0.4488\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 24/36, Loss: 0.5112\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 25/36, Loss: 0.4632\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 43/100, Batch 26/36, Loss: 0.0908\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 27/36, Loss: 0.3084\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 28/36, Loss: 0.5106\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 29/36, Loss: 0.2711\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 30/36, Loss: 0.4744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 31/36, Loss: 0.5077\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 32/36, Loss: 0.3924\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 33/36, Loss: 0.5144\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 34/36, Loss: 0.5021\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 43/100, Batch 35/36, Loss: 0.0715\n",
      "Epoch 43/100, Average Loss: 0.3974, Valid Batches: 36/36\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 0/36, Loss: 0.2744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 1/36, Loss: 0.3764\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 2/36, Loss: 0.4539\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 44/100, Batch 3/36, Loss: 0.0959\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 4/36, Loss: 0.4425\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 5/36, Loss: 0.4170\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 6/36, Loss: 0.5061\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 7/36, Loss: 0.4133\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 8/36, Loss: 0.4136\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 9/36, Loss: 0.4629\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 10/36, Loss: 0.5106\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 11/36, Loss: 0.0688\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 12/36, Loss: 0.1191\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 13/36, Loss: 0.4527\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 14/36, Loss: 0.4337\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 15/36, Loss: 0.3009\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 16/36, Loss: 0.4617\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 17/36, Loss: 0.4866\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 18/36, Loss: 0.4889\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 19/36, Loss: 0.3021\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 20/36, Loss: 0.3011\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 21/36, Loss: 0.4353\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 22/36, Loss: 0.5079\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 23/36, Loss: 0.4694\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 24/36, Loss: 0.3827\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 25/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 26/36, Loss: 0.4100\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 27/36, Loss: 0.5039\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 28/36, Loss: 0.4898\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 29/36, Loss: 0.3115\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 30/36, Loss: 0.5192\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 31/36, Loss: 0.2850\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 32/36, Loss: 0.4180\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 33/36, Loss: 0.4968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 34/36, Loss: 0.5218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 44/100, Batch 35/36, Loss: 0.4278\n",
      "Epoch 44/100, Average Loss: 0.3960, Valid Batches: 36/36\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 0/36, Loss: 0.4758\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 1/36, Loss: 0.3070\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 2/36, Loss: 0.5275\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 3/36, Loss: 0.2932\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 4/36, Loss: 0.4956\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 5/36, Loss: 0.1218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 6/36, Loss: 0.4398\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 7/36, Loss: 0.5174\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 8/36, Loss: 0.4869\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 9/36, Loss: 0.4801\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 10/36, Loss: 0.5193\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 11/36, Loss: 0.4948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 12/36, Loss: 0.4018\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 13/36, Loss: 0.2884\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 14/36, Loss: 0.4882\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 15/36, Loss: 0.3930\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 16/36, Loss: 0.3030\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 17/36, Loss: 0.2782\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 18/36, Loss: 0.3285\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 19/36, Loss: 0.4329\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 20/36, Loss: 0.4178\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 21/36, Loss: 0.4492\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 22/36, Loss: 0.4534\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 23/36, Loss: 0.4857\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 24/36, Loss: 0.4243\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 25/36, Loss: 0.3048\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 26/36, Loss: 0.4297\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 27/36, Loss: 0.4263\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 28/36, Loss: 0.4611\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 29/36, Loss: 0.4559\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 30/36, Loss: 0.5136\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 31/36, Loss: 0.3771\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 45/100, Batch 32/36, Loss: 0.0974\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 33/36, Loss: 0.4429\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 34/36, Loss: 0.0712\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 45/100, Batch 35/36, Loss: 0.4227\n",
      "Epoch 45/100, Average Loss: 0.3974, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 0/36, Loss: 0.4014\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 1/36, Loss: 0.2986\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 2/36, Loss: 0.4845\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 3/36, Loss: 0.2968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 4/36, Loss: 0.5246\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 5/36, Loss: 0.4762\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 6/36, Loss: 0.4432\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 7/36, Loss: 0.5084\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 8/36, Loss: 0.4485\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 9/36, Loss: 0.4107\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 10/36, Loss: 0.2853\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 11/36, Loss: 0.4892\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 12/36, Loss: 0.4384\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 13/36, Loss: 0.0627\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 14/36, Loss: 0.4669\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 15/36, Loss: 0.4888\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 16/36, Loss: 0.2806\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 17/36, Loss: 0.4651\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 18/36, Loss: 0.4311\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 19/36, Loss: 0.3221\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 20/36, Loss: 0.4273\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 21/36, Loss: 0.4201\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 22/36, Loss: 0.4301\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 23/36, Loss: 0.4211\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 24/36, Loss: 0.5083\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 25/36, Loss: 0.5099\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 26/36, Loss: 0.1221\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 27/36, Loss: 0.4198\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 28/36, Loss: 0.5232\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 29/36, Loss: 0.3196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 30/36, Loss: 0.3771\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 46/100, Batch 31/36, Loss: 0.0929\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 32/36, Loss: 0.3819\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 33/36, Loss: 0.5236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 34/36, Loss: 0.2999\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 46/100, Batch 35/36, Loss: 0.4674\n",
      "Epoch 46/100, Average Loss: 0.3963, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 0/36, Loss: 0.5056\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 1/36, Loss: 0.5148\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 2/36, Loss: 0.4469\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 3/36, Loss: 0.4366\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 4/36, Loss: 0.2985\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 5/36, Loss: 0.4508\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 6/36, Loss: 0.4659\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 7/36, Loss: 0.3944\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 8/36, Loss: 0.2996\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 9/36, Loss: 0.4952\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 10/36, Loss: 0.2787\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 11/36, Loss: 0.4851\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 12/36, Loss: 0.4625\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 13/36, Loss: 0.1246\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 14/36, Loss: 0.5162\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 15/36, Loss: 0.4186\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 16/36, Loss: 0.0656\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 17/36, Loss: 0.3669\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 18/36, Loss: 0.4970\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 19/36, Loss: 0.2896\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 20/36, Loss: 0.4883\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 21/36, Loss: 0.4174\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 22/36, Loss: 0.3087\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 23/36, Loss: 0.4833\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 24/36, Loss: 0.2932\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 47/100, Batch 25/36, Loss: 0.0927\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 26/36, Loss: 0.5284\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 27/36, Loss: 0.4050\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 28/36, Loss: 0.3202\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 29/36, Loss: 0.4350\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 30/36, Loss: 0.3935\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 31/36, Loss: 0.5236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 32/36, Loss: 0.4324\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 33/36, Loss: 0.4356\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 34/36, Loss: 0.4696\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 47/100, Batch 35/36, Loss: 0.4305\n",
      "Epoch 47/100, Average Loss: 0.3964, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 0/36, Loss: 0.5267\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 1/36, Loss: 0.2847\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 2/36, Loss: 0.4742\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 3/36, Loss: 0.4291\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 4/36, Loss: 0.3845\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 5/36, Loss: 0.4250\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 6/36, Loss: 0.4306\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 7/36, Loss: 0.4232\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 8/36, Loss: 0.4246\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 9/36, Loss: 0.4863\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 10/36, Loss: 0.4803\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 11/36, Loss: 0.5275\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 12/36, Loss: 0.0691\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 13/36, Loss: 0.3038\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 14/36, Loss: 0.4700\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 15/36, Loss: 0.3061\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 16/36, Loss: 0.4711\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 17/36, Loss: 0.2988\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 18/36, Loss: 0.5006\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 19/36, Loss: 0.4937\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 20/36, Loss: 0.4467\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 21/36, Loss: 0.3748\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 22/36, Loss: 0.3231\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 23/36, Loss: 0.4616\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 24/36, Loss: 0.4165\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 25/36, Loss: 0.1151\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 26/36, Loss: 0.2797\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 27/36, Loss: 0.3988\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 28/36, Loss: 0.3042\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 29/36, Loss: 0.4595\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 30/36, Loss: 0.5101\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 31/36, Loss: 0.5114\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 48/100, Batch 32/36, Loss: 0.0821\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 33/36, Loss: 0.4129\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 34/36, Loss: 0.5058\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 48/100, Batch 35/36, Loss: 0.4182\n",
      "Epoch 48/100, Average Loss: 0.3953, Valid Batches: 36/36\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 0/36, Loss: 0.2976\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 1/36, Loss: 0.3000\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 2/36, Loss: 0.4396\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 3/36, Loss: 0.5049\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 4/36, Loss: 0.0732\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 5/36, Loss: 0.4373\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 6/36, Loss: 0.4099\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 7/36, Loss: 0.2950\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 8/36, Loss: 0.4276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 9/36, Loss: 0.5133\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 10/36, Loss: 0.3723\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 11/36, Loss: 0.3192\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 12/36, Loss: 0.4202\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 13/36, Loss: 0.1289\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 14/36, Loss: 0.5142\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 15/36, Loss: 0.4559\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 16/36, Loss: 0.4401\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 17/36, Loss: 0.2826\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 18/36, Loss: 0.5047\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 19/36, Loss: 0.5231\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 20/36, Loss: 0.4681\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 21/36, Loss: 0.4078\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 22/36, Loss: 0.5269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 23/36, Loss: 0.4320\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 24/36, Loss: 0.4814\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 25/36, Loss: 0.2941\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 26/36, Loss: 0.4758\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 27/36, Loss: 0.4566\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 28/36, Loss: 0.2920\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 29/36, Loss: 0.4896\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 30/36, Loss: 0.4357\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 31/36, Loss: 0.4807\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 49/100, Batch 32/36, Loss: 0.0781\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 33/36, Loss: 0.4984\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 34/36, Loss: 0.4279\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 49/100, Batch 35/36, Loss: 0.3717\n",
      "Epoch 49/100, Average Loss: 0.3966, Valid Batches: 36/36\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 0/36, Loss: 0.0551\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 1/36, Loss: 0.4505\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 2/36, Loss: 0.4725\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 50/100, Batch 3/36, Loss: 0.0753\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 4/36, Loss: 0.4216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 5/36, Loss: 0.3903\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 6/36, Loss: 0.4120\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 7/36, Loss: 0.4955\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 8/36, Loss: 0.5196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 9/36, Loss: 0.4369\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 10/36, Loss: 0.2930\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 11/36, Loss: 0.4542\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 12/36, Loss: 0.4327\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 13/36, Loss: 0.3144\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 14/36, Loss: 0.4228\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 15/36, Loss: 0.3660\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 16/36, Loss: 0.4863\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 17/36, Loss: 0.4201\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 18/36, Loss: 0.4215\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 19/36, Loss: 0.2980\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 20/36, Loss: 0.4259\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 21/36, Loss: 0.4240\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 22/36, Loss: 0.4633\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 23/36, Loss: 0.5192\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 24/36, Loss: 0.5079\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 25/36, Loss: 0.2755\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 26/36, Loss: 0.3064\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 27/36, Loss: 0.2962\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 28/36, Loss: 0.5280\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 29/36, Loss: 0.5065\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 30/36, Loss: 0.4620\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 31/36, Loss: 0.1230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 32/36, Loss: 0.4878\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 33/36, Loss: 0.4985\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 34/36, Loss: 0.4675\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 50/100, Batch 35/36, Loss: 0.3081\n",
      "Epoch 50/100, Average Loss: 0.3955, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 0/36, Loss: 0.4621\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 1/36, Loss: 0.4911\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 2/36, Loss: 0.4721\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 3/36, Loss: 0.4952\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 4/36, Loss: 0.4166\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 5/36, Loss: 0.4471\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 6/36, Loss: 0.4429\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 7/36, Loss: 0.4092\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 8/36, Loss: 0.4225\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 9/36, Loss: 0.1192\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 10/36, Loss: 0.4122\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 11/36, Loss: 0.0636\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 12/36, Loss: 0.3761\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 13/36, Loss: 0.5085\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 14/36, Loss: 0.4013\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 15/36, Loss: 0.2930\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 16/36, Loss: 0.4865\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 17/36, Loss: 0.3014\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 18/36, Loss: 0.5020\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 19/36, Loss: 0.3028\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 51/100, Batch 20/36, Loss: 0.0833\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 21/36, Loss: 0.5062\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 22/36, Loss: 0.4358\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 23/36, Loss: 0.4555\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 24/36, Loss: 0.4879\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 25/36, Loss: 0.4174\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 26/36, Loss: 0.4560\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 27/36, Loss: 0.5055\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 28/36, Loss: 0.2807\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 29/36, Loss: 0.5269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 30/36, Loss: 0.3135\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 31/36, Loss: 0.5229\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 32/36, Loss: 0.3155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 33/36, Loss: 0.3762\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 34/36, Loss: 0.4759\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 51/100, Batch 35/36, Loss: 0.3024\n",
      "Epoch 51/100, Average Loss: 0.3969, Valid Batches: 36/36\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 0/36, Loss: 0.4485\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 1/36, Loss: 0.3732\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 2/36, Loss: 0.4257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 3/36, Loss: 0.3855\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 4/36, Loss: 0.3001\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 5/36, Loss: 0.0710\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 6/36, Loss: 0.2976\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 7/36, Loss: 0.5258\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 8/36, Loss: 0.4759\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 9/36, Loss: 0.4195\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 10/36, Loss: 0.4285\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 11/36, Loss: 0.5212\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 12/36, Loss: 0.5034\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 13/36, Loss: 0.4835\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 14/36, Loss: 0.4148\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 15/36, Loss: 0.4734\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 16/36, Loss: 0.5119\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 17/36, Loss: 0.2816\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 18/36, Loss: 0.4861\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 19/36, Loss: 0.4998\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 20/36, Loss: 0.4796\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 21/36, Loss: 0.1144\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 22/36, Loss: 0.4466\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 23/36, Loss: 0.3493\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 24/36, Loss: 0.4633\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 25/36, Loss: 0.2866\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 26/36, Loss: 0.4482\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 27/36, Loss: 0.4444\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 28/36, Loss: 0.4925\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 52/100, Batch 29/36, Loss: 0.0822\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 30/36, Loss: 0.2786\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 31/36, Loss: 0.4165\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 32/36, Loss: 0.3084\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 33/36, Loss: 0.4334\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 34/36, Loss: 0.5104\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 52/100, Batch 35/36, Loss: 0.4201\n",
      "Epoch 52/100, Average Loss: 0.3973, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 0/36, Loss: 0.4162\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 1/36, Loss: 0.4967\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 2/36, Loss: 0.5196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 3/36, Loss: 0.4636\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 4/36, Loss: 0.4239\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 5/36, Loss: 0.3027\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 53/100, Batch 6/36, Loss: 0.0982\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 7/36, Loss: 0.3038\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 8/36, Loss: 0.4231\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 9/36, Loss: 0.3819\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 10/36, Loss: 0.4352\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 11/36, Loss: 0.4736\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 12/36, Loss: 0.3043\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 13/36, Loss: 0.5228\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 14/36, Loss: 0.5163\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 15/36, Loss: 0.5114\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 16/36, Loss: 0.4863\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 17/36, Loss: 0.4739\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 18/36, Loss: 0.0707\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 19/36, Loss: 0.3018\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 20/36, Loss: 0.4147\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 21/36, Loss: 0.2838\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 22/36, Loss: 0.4300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 23/36, Loss: 0.5214\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 24/36, Loss: 0.4452\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 25/36, Loss: 0.3024\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 26/36, Loss: 0.3780\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 27/36, Loss: 0.5010\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 28/36, Loss: 0.4090\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 29/36, Loss: 0.2720\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 30/36, Loss: 0.4212\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 31/36, Loss: 0.4609\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 32/36, Loss: 0.4349\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 33/36, Loss: 0.4770\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 34/36, Loss: 0.1216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 53/100, Batch 35/36, Loss: 0.4829\n",
      "Epoch 53/100, Average Loss: 0.3967, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 0/36, Loss: 0.4868\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 54/100, Batch 1/36, Loss: 0.0855\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 2/36, Loss: 0.4930\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 3/36, Loss: 0.4343\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 4/36, Loss: 0.2938\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 5/36, Loss: 0.5080\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 6/36, Loss: 0.4757\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 7/36, Loss: 0.4164\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 8/36, Loss: 0.2873\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 9/36, Loss: 0.0641\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 10/36, Loss: 0.4402\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 11/36, Loss: 0.5009\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 12/36, Loss: 0.4243\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 13/36, Loss: 0.4068\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 14/36, Loss: 0.4839\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 15/36, Loss: 0.4688\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 16/36, Loss: 0.5018\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 17/36, Loss: 0.4243\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 18/36, Loss: 0.3782\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 19/36, Loss: 0.5198\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 20/36, Loss: 0.1251\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 21/36, Loss: 0.4335\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 22/36, Loss: 0.4957\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 23/36, Loss: 0.2704\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 24/36, Loss: 0.3198\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 25/36, Loss: 0.4786\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 26/36, Loss: 0.4080\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 27/36, Loss: 0.4070\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 28/36, Loss: 0.5250\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 29/36, Loss: 0.2995\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 30/36, Loss: 0.3019\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 31/36, Loss: 0.3754\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 32/36, Loss: 0.4587\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 33/36, Loss: 0.4257\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 34/36, Loss: 0.2983\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 54/100, Batch 35/36, Loss: 0.4452\n",
      "Epoch 54/100, Average Loss: 0.3934, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 0/36, Loss: 0.4756\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 1/36, Loss: 0.3881\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 2/36, Loss: 0.4422\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 3/36, Loss: 0.4552\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 4/36, Loss: 0.3012\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 5/36, Loss: 0.3223\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 6/36, Loss: 0.2792\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 7/36, Loss: 0.4646\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 8/36, Loss: 0.5241\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 9/36, Loss: 0.4479\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 10/36, Loss: 0.2717\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 11/36, Loss: 0.5001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 12/36, Loss: 0.5028\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 13/36, Loss: 0.4093\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 14/36, Loss: 0.4318\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 15/36, Loss: 0.4234\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 16/36, Loss: 0.4868\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 17/36, Loss: 0.0684\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 18/36, Loss: 0.4192\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 19/36, Loss: 0.4548\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 20/36, Loss: 0.4187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 21/36, Loss: 0.3060\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 22/36, Loss: 0.4987\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 23/36, Loss: 0.4230\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 24/36, Loss: 0.1188\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 25/36, Loss: 0.4804\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 26/36, Loss: 0.4409\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 27/36, Loss: 0.2950\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 28/36, Loss: 0.4216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 29/36, Loss: 0.3684\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 30/36, Loss: 0.4676\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 31/36, Loss: 0.5044\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 32/36, Loss: 0.5191\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 55/100, Batch 33/36, Loss: 0.0811\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 34/36, Loss: 0.5100\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 55/100, Batch 35/36, Loss: 0.3037\n",
      "Epoch 55/100, Average Loss: 0.3952, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 0/36, Loss: 0.4177\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 1/36, Loss: 0.3005\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 2/36, Loss: 0.2814\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 3/36, Loss: 0.4826\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 4/36, Loss: 0.2997\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 5/36, Loss: 0.4223\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 6/36, Loss: 0.3019\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 7/36, Loss: 0.3692\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 8/36, Loss: 0.4158\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 9/36, Loss: 0.2807\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 10/36, Loss: 0.4042\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 11/36, Loss: 0.4341\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 12/36, Loss: 0.2874\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 13/36, Loss: 0.1276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 14/36, Loss: 0.4831\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 15/36, Loss: 0.3207\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 16/36, Loss: 0.5110\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 17/36, Loss: 0.0747\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 18/36, Loss: 0.5107\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 19/36, Loss: 0.5014\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 56/100, Batch 20/36, Loss: 0.0812\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 21/36, Loss: 0.5023\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 22/36, Loss: 0.4877\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 23/36, Loss: 0.4512\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 24/36, Loss: 0.4908\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 25/36, Loss: 0.4365\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 26/36, Loss: 0.4209\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 27/36, Loss: 0.5189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 28/36, Loss: 0.4659\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 29/36, Loss: 0.4203\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 30/36, Loss: 0.5138\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 31/36, Loss: 0.4217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 32/36, Loss: 0.4700\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 33/36, Loss: 0.3791\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 34/36, Loss: 0.4445\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 56/100, Batch 35/36, Loss: 0.4979\n",
      "Epoch 56/100, Average Loss: 0.3953, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 0/36, Loss: 0.4176\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 1/36, Loss: 0.4218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 2/36, Loss: 0.4995\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 3/36, Loss: 0.4896\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 4/36, Loss: 0.5176\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 5/36, Loss: 0.3058\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 6/36, Loss: 0.4349\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 7/36, Loss: 0.0659\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 8/36, Loss: 0.3180\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 9/36, Loss: 0.4268\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 10/36, Loss: 0.4286\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 11/36, Loss: 0.5035\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 12/36, Loss: 0.4882\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 13/36, Loss: 0.5166\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 14/36, Loss: 0.4321\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 15/36, Loss: 0.4970\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 16/36, Loss: 0.2950\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 17/36, Loss: 0.5026\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 18/36, Loss: 0.4764\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 19/36, Loss: 0.4011\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 20/36, Loss: 0.4653\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 21/36, Loss: 0.4698\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 22/36, Loss: 0.4452\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 23/36, Loss: 0.5225\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 24/36, Loss: 0.4460\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 25/36, Loss: 0.2904\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 26/36, Loss: 0.3722\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 27/36, Loss: 0.3902\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 28/36, Loss: 0.4583\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 29/36, Loss: 0.2729\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 30/36, Loss: 0.3035\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 31/36, Loss: 0.2896\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 32/36, Loss: 0.4109\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 33/36, Loss: 0.1128\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 57/100, Batch 34/36, Loss: 0.4201\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 57/100, Batch 35/36, Loss: 0.0800\n",
      "Epoch 57/100, Average Loss: 0.3941, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 0/36, Loss: 0.4887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 1/36, Loss: 0.5077\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 2/36, Loss: 0.5234\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 3/36, Loss: 0.4518\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 4/36, Loss: 0.4028\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 5/36, Loss: 0.4273\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 6/36, Loss: 0.0645\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 7/36, Loss: 0.5036\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 8/36, Loss: 0.2934\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 9/36, Loss: 0.4267\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 10/36, Loss: 0.2917\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 11/36, Loss: 0.3237\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 12/36, Loss: 0.4042\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 13/36, Loss: 0.1334\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 14/36, Loss: 0.3837\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 15/36, Loss: 0.4422\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 16/36, Loss: 0.5276\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 17/36, Loss: 0.5066\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 18/36, Loss: 0.3599\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 19/36, Loss: 0.5054\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 20/36, Loss: 0.4236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 21/36, Loss: 0.5035\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 22/36, Loss: 0.3019\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 23/36, Loss: 0.4322\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 24/36, Loss: 0.4787\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 25/36, Loss: 0.4835\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 26/36, Loss: 0.4783\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 27/36, Loss: 0.2787\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 28/36, Loss: 0.2796\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 29/36, Loss: 0.4155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 30/36, Loss: 0.4554\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 31/36, Loss: 0.4196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 32/36, Loss: 0.4273\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 33/36, Loss: 0.4718\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 58/100, Batch 34/36, Loss: 0.3207\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 58/100, Batch 35/36, Loss: 0.0873\n",
      "Epoch 58/100, Average Loss: 0.3952, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 0/36, Loss: 0.4280\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 1/36, Loss: 0.4468\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 2/36, Loss: 0.4413\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 3/36, Loss: 0.4116\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 4/36, Loss: 0.4999\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 5/36, Loss: 0.4909\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 6/36, Loss: 0.4280\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 7/36, Loss: 0.4681\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 8/36, Loss: 0.2753\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 9/36, Loss: 0.4624\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 10/36, Loss: 0.2976\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 11/36, Loss: 0.4902\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 12/36, Loss: 0.3814\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 13/36, Loss: 0.5148\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 14/36, Loss: 0.5267\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 15/36, Loss: 0.1204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 16/36, Loss: 0.3089\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 17/36, Loss: 0.3749\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 18/36, Loss: 0.4206\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 59/100, Batch 19/36, Loss: 0.0865\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 20/36, Loss: 0.4259\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 21/36, Loss: 0.4051\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 22/36, Loss: 0.5021\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 23/36, Loss: 0.2831\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 24/36, Loss: 0.4151\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 25/36, Loss: 0.4991\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 26/36, Loss: 0.5259\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 27/36, Loss: 0.4792\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 28/36, Loss: 0.4524\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 29/36, Loss: 0.3192\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 30/36, Loss: 0.0601\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 31/36, Loss: 0.4631\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 32/36, Loss: 0.3247\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 33/36, Loss: 0.2895\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 34/36, Loss: 0.4123\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 59/100, Batch 35/36, Loss: 0.4945\n",
      "Epoch 59/100, Average Loss: 0.3952, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 0/36, Loss: 0.3148\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 1/36, Loss: 0.4107\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 2/36, Loss: 0.2748\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 3/36, Loss: 0.5041\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 4/36, Loss: 0.4743\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 5/36, Loss: 0.4245\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 6/36, Loss: 0.4190\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 7/36, Loss: 0.4074\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 8/36, Loss: 0.4234\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 9/36, Loss: 0.4977\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 10/36, Loss: 0.0676\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 11/36, Loss: 0.5189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 12/36, Loss: 0.2946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 13/36, Loss: 0.5261\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 14/36, Loss: 0.4379\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 15/36, Loss: 0.4810\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 16/36, Loss: 0.4495\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 17/36, Loss: 0.2752\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 18/36, Loss: 0.4674\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 19/36, Loss: 0.4669\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 20/36, Loss: 0.4718\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 21/36, Loss: 0.4175\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 22/36, Loss: 0.1171\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 23/36, Loss: 0.3019\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 24/36, Loss: 0.4813\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 25/36, Loss: 0.3731\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 26/36, Loss: 0.4280\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 27/36, Loss: 0.4424\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 28/36, Loss: 0.3005\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 60/100, Batch 29/36, Loss: 0.0812\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 30/36, Loss: 0.4919\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 31/36, Loss: 0.3165\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 32/36, Loss: 0.3669\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 33/36, Loss: 0.5126\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 34/36, Loss: 0.4452\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 60/100, Batch 35/36, Loss: 0.5102\n",
      "Epoch 60/100, Average Loss: 0.3943, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 0/36, Loss: 0.4200\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 1/36, Loss: 0.3509\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 2/36, Loss: 0.4872\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 3/36, Loss: 0.3047\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 4/36, Loss: 0.5097\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 5/36, Loss: 0.4247\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 61/100, Batch 6/36, Loss: 0.0868\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 7/36, Loss: 0.4072\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 8/36, Loss: 0.4914\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 9/36, Loss: 0.5247\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 10/36, Loss: 0.2846\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 11/36, Loss: 0.3773\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 12/36, Loss: 0.4714\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 13/36, Loss: 0.4540\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 14/36, Loss: 0.4494\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 15/36, Loss: 0.4672\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 16/36, Loss: 0.2994\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 17/36, Loss: 0.4230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 18/36, Loss: 0.4425\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 19/36, Loss: 0.4823\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 20/36, Loss: 0.2804\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 21/36, Loss: 0.5108\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 22/36, Loss: 0.3048\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 23/36, Loss: 0.4381\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 24/36, Loss: 0.4398\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 25/36, Loss: 0.4260\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 26/36, Loss: 0.4793\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 27/36, Loss: 0.0577\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 28/36, Loss: 0.1164\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 29/36, Loss: 0.4384\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 30/36, Loss: 0.3107\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 31/36, Loss: 0.3208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 32/36, Loss: 0.5077\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 33/36, Loss: 0.4282\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 34/36, Loss: 0.5159\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 61/100, Batch 35/36, Loss: 0.5220\n",
      "Epoch 61/100, Average Loss: 0.3960, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 0/36, Loss: 0.4294\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 1/36, Loss: 0.4770\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 2/36, Loss: 0.4216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 3/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 4/36, Loss: 0.2813\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 5/36, Loss: 0.5026\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 6/36, Loss: 0.4192\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 7/36, Loss: 0.4461\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 8/36, Loss: 0.0705\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 9/36, Loss: 0.3220\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 10/36, Loss: 0.2677\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 11/36, Loss: 0.3045\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 12/36, Loss: 0.4272\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 13/36, Loss: 0.4458\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 14/36, Loss: 0.4292\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 15/36, Loss: 0.5217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 16/36, Loss: 0.4132\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 17/36, Loss: 0.3671\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 18/36, Loss: 0.1213\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 19/36, Loss: 0.2795\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 20/36, Loss: 0.4985\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 21/36, Loss: 0.5172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 22/36, Loss: 0.4864\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 23/36, Loss: 0.4948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 24/36, Loss: 0.4334\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 25/36, Loss: 0.4806\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 26/36, Loss: 0.4133\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 27/36, Loss: 0.3001\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 28/36, Loss: 0.5000\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 29/36, Loss: 0.4614\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 30/36, Loss: 0.4697\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 31/36, Loss: 0.3810\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 32/36, Loss: 0.3059\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 62/100, Batch 33/36, Loss: 0.0867\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 34/36, Loss: 0.4658\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 62/100, Batch 35/36, Loss: 0.5127\n",
      "Epoch 62/100, Average Loss: 0.3937, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 0/36, Loss: 0.4316\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 1/36, Loss: 0.4764\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 2/36, Loss: 0.4644\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 3/36, Loss: 0.2954\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 4/36, Loss: 0.4203\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 63/100, Batch 5/36, Loss: 0.0804\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 6/36, Loss: 0.5113\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 7/36, Loss: 0.4747\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 8/36, Loss: 0.2917\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 9/36, Loss: 0.4244\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 10/36, Loss: 0.4882\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 11/36, Loss: 0.1172\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 12/36, Loss: 0.4208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 13/36, Loss: 0.3806\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 14/36, Loss: 0.4947\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 15/36, Loss: 0.4104\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 16/36, Loss: 0.0636\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 17/36, Loss: 0.4786\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 18/36, Loss: 0.4172\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 19/36, Loss: 0.3300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 20/36, Loss: 0.4315\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 21/36, Loss: 0.4392\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 22/36, Loss: 0.4495\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 23/36, Loss: 0.3010\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 24/36, Loss: 0.2689\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 25/36, Loss: 0.2941\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 26/36, Loss: 0.5219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 27/36, Loss: 0.4535\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 28/36, Loss: 0.3692\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 29/36, Loss: 0.5291\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 30/36, Loss: 0.5070\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 31/36, Loss: 0.5115\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 32/36, Loss: 0.4246\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 33/36, Loss: 0.2795\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 34/36, Loss: 0.4247\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 63/100, Batch 35/36, Loss: 0.5051\n",
      "Epoch 63/100, Average Loss: 0.3939, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 0/36, Loss: 0.4073\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 1/36, Loss: 0.4886\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 2/36, Loss: 0.0679\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 3/36, Loss: 0.4627\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 4/36, Loss: 0.4872\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 5/36, Loss: 0.2719\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 6/36, Loss: 0.5212\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 7/36, Loss: 0.4183\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 8/36, Loss: 0.4737\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 9/36, Loss: 0.4242\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 10/36, Loss: 0.4985\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 11/36, Loss: 0.4219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 12/36, Loss: 0.3167\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 13/36, Loss: 0.4401\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 14/36, Loss: 0.4213\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 15/36, Loss: 0.4597\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 16/36, Loss: 0.2814\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 17/36, Loss: 0.3900\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 18/36, Loss: 0.5018\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 19/36, Loss: 0.4150\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 20/36, Loss: 0.4199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 21/36, Loss: 0.3041\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 22/36, Loss: 0.3029\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 23/36, Loss: 0.4371\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 24/36, Loss: 0.3170\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 25/36, Loss: 0.2989\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 26/36, Loss: 0.4696\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 27/36, Loss: 0.1258\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 28/36, Loss: 0.5013\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 29/36, Loss: 0.3770\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 30/36, Loss: 0.4494\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 31/36, Loss: 0.5020\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 32/36, Loss: 0.4055\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 64/100, Batch 33/36, Loss: 0.0808\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 34/36, Loss: 0.5225\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 64/100, Batch 35/36, Loss: 0.5215\n",
      "Epoch 64/100, Average Loss: 0.3946, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 0/36, Loss: 0.4731\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 1/36, Loss: 0.4960\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 2/36, Loss: 0.2804\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 3/36, Loss: 0.4332\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 4/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 5/36, Loss: 0.5159\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 6/36, Loss: 0.3084\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 65/100, Batch 7/36, Loss: 0.0815\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 8/36, Loss: 0.3164\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 9/36, Loss: 0.4519\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 10/36, Loss: 0.4952\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 11/36, Loss: 0.4424\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 12/36, Loss: 0.4223\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 13/36, Loss: 0.4145\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 14/36, Loss: 0.1222\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 15/36, Loss: 0.4607\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 16/36, Loss: 0.5083\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 17/36, Loss: 0.4869\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 18/36, Loss: 0.4661\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 19/36, Loss: 0.3138\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 20/36, Loss: 0.4177\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 21/36, Loss: 0.0680\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 22/36, Loss: 0.3753\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 23/36, Loss: 0.3701\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 24/36, Loss: 0.5081\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 25/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 26/36, Loss: 0.4236\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 27/36, Loss: 0.2956\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 28/36, Loss: 0.4783\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 29/36, Loss: 0.4906\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 30/36, Loss: 0.4124\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 31/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 32/36, Loss: 0.5120\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 33/36, Loss: 0.5265\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 34/36, Loss: 0.2807\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 65/100, Batch 35/36, Loss: 0.4230\n",
      "Epoch 65/100, Average Loss: 0.3946, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 0/36, Loss: 0.5033\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 1/36, Loss: 0.4350\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 2/36, Loss: 0.4736\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 3/36, Loss: 0.4356\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 4/36, Loss: 0.3002\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 66/100, Batch 5/36, Loss: 0.0859\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 6/36, Loss: 0.2707\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 7/36, Loss: 0.2824\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 8/36, Loss: 0.5243\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 9/36, Loss: 0.5157\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 10/36, Loss: 0.3160\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 11/36, Loss: 0.4999\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 12/36, Loss: 0.4239\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 13/36, Loss: 0.4911\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 14/36, Loss: 0.4278\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 15/36, Loss: 0.2974\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 16/36, Loss: 0.0668\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 17/36, Loss: 0.3816\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 18/36, Loss: 0.4401\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 19/36, Loss: 0.2874\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 20/36, Loss: 0.4582\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 21/36, Loss: 0.5071\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 22/36, Loss: 0.4732\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 23/36, Loss: 0.4984\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 24/36, Loss: 0.4132\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 25/36, Loss: 0.1156\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 26/36, Loss: 0.5170\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 27/36, Loss: 0.3214\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 28/36, Loss: 0.4678\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 29/36, Loss: 0.4225\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 30/36, Loss: 0.4203\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 31/36, Loss: 0.4788\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 32/36, Loss: 0.4389\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 33/36, Loss: 0.4169\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 34/36, Loss: 0.4476\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 66/100, Batch 35/36, Loss: 0.3646\n",
      "Epoch 66/100, Average Loss: 0.3950, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 0/36, Loss: 0.4899\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 1/36, Loss: 0.4421\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 2/36, Loss: 0.4423\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 3/36, Loss: 0.4230\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 4/36, Loss: 0.0686\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 5/36, Loss: 0.4434\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 6/36, Loss: 0.2916\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 7/36, Loss: 0.4823\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 8/36, Loss: 0.3122\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 9/36, Loss: 0.4582\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 10/36, Loss: 0.5140\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 11/36, Loss: 0.4894\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 12/36, Loss: 0.4782\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 13/36, Loss: 0.1198\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 14/36, Loss: 0.5214\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 15/36, Loss: 0.5005\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 16/36, Loss: 0.5091\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 17/36, Loss: 0.4169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 18/36, Loss: 0.4169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 19/36, Loss: 0.4255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 20/36, Loss: 0.3825\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 21/36, Loss: 0.2814\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 22/36, Loss: 0.3023\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 23/36, Loss: 0.2743\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 24/36, Loss: 0.2772\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 25/36, Loss: 0.4282\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 26/36, Loss: 0.5044\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 27/36, Loss: 0.4420\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 67/100, Batch 28/36, Loss: 0.0860\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 29/36, Loss: 0.3780\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 30/36, Loss: 0.4191\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 31/36, Loss: 0.4265\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 32/36, Loss: 0.5195\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 33/36, Loss: 0.4646\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 34/36, Loss: 0.5001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 67/100, Batch 35/36, Loss: 0.3055\n",
      "Epoch 67/100, Average Loss: 0.3955, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 0/36, Loss: 0.5293\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 1/36, Loss: 0.0701\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 2/36, Loss: 0.4966\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 3/36, Loss: 0.2981\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 4/36, Loss: 0.4266\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 5/36, Loss: 0.3036\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 6/36, Loss: 0.2802\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 7/36, Loss: 0.2883\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 8/36, Loss: 0.3612\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 9/36, Loss: 0.4371\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 10/36, Loss: 0.1219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 11/36, Loss: 0.4206\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 12/36, Loss: 0.4040\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 13/36, Loss: 0.4660\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 14/36, Loss: 0.4817\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 15/36, Loss: 0.4523\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 16/36, Loss: 0.3006\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 17/36, Loss: 0.4364\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 18/36, Loss: 0.5037\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 19/36, Loss: 0.4911\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 20/36, Loss: 0.4216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 21/36, Loss: 0.3811\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 22/36, Loss: 0.4570\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 23/36, Loss: 0.4982\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 24/36, Loss: 0.4645\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 68/100, Batch 25/36, Loss: 0.0910\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 26/36, Loss: 0.4992\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 27/36, Loss: 0.3018\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 28/36, Loss: 0.5158\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 29/36, Loss: 0.2791\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 30/36, Loss: 0.5111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 31/36, Loss: 0.4363\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 32/36, Loss: 0.4097\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 33/36, Loss: 0.4785\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 34/36, Loss: 0.4234\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 68/100, Batch 35/36, Loss: 0.4497\n",
      "Epoch 68/100, Average Loss: 0.3941, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 0/36, Loss: 0.5047\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 1/36, Loss: 0.4290\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 2/36, Loss: 0.2944\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 3/36, Loss: 0.2772\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 4/36, Loss: 0.4617\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 5/36, Loss: 0.4426\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 6/36, Loss: 0.3685\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 7/36, Loss: 0.1191\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 8/36, Loss: 0.5206\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 9/36, Loss: 0.4345\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 10/36, Loss: 0.4102\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 11/36, Loss: 0.2830\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 12/36, Loss: 0.4870\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 13/36, Loss: 0.4282\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 14/36, Loss: 0.4327\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 69/100, Batch 15/36, Loss: 0.0797\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 16/36, Loss: 0.4169\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 17/36, Loss: 0.4499\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 18/36, Loss: 0.4154\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 19/36, Loss: 0.4694\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 20/36, Loss: 0.5036\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 21/36, Loss: 0.3187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 22/36, Loss: 0.4698\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 23/36, Loss: 0.3041\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 24/36, Loss: 0.4969\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 25/36, Loss: 0.4816\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 26/36, Loss: 0.3674\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 27/36, Loss: 0.5116\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 28/36, Loss: 0.4082\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 29/36, Loss: 0.4828\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 30/36, Loss: 0.3111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 31/36, Loss: 0.4338\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 32/36, Loss: 0.0692\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 33/36, Loss: 0.4997\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 34/36, Loss: 0.2814\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 69/100, Batch 35/36, Loss: 0.5312\n",
      "Epoch 69/100, Average Loss: 0.3943, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 0/36, Loss: 0.5156\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 1/36, Loss: 0.2987\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 2/36, Loss: 0.4213\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 3/36, Loss: 0.4467\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 4/36, Loss: 0.5150\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 5/36, Loss: 0.4599\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 6/36, Loss: 0.2992\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 7/36, Loss: 0.5168\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 70/100, Batch 8/36, Loss: 0.0818\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 9/36, Loss: 0.3146\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 10/36, Loss: 0.2934\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 11/36, Loss: 0.4280\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 12/36, Loss: 0.3061\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 13/36, Loss: 0.4705\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 14/36, Loss: 0.5148\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 15/36, Loss: 0.4455\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 16/36, Loss: 0.4318\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 17/36, Loss: 0.4276\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 18/36, Loss: 0.4288\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 19/36, Loss: 0.2779\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 20/36, Loss: 0.4091\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 21/36, Loss: 0.4956\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 22/36, Loss: 0.4883\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 23/36, Loss: 0.4121\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 24/36, Loss: 0.3809\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 25/36, Loss: 0.1191\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 26/36, Loss: 0.4863\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 27/36, Loss: 0.4930\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 28/36, Loss: 0.5123\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 29/36, Loss: 0.4700\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 30/36, Loss: 0.4705\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 31/36, Loss: 0.4274\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 32/36, Loss: 0.2790\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 33/36, Loss: 0.4178\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 34/36, Loss: 0.3800\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 70/100, Batch 35/36, Loss: 0.0660\n",
      "Epoch 70/100, Average Loss: 0.3945, Valid Batches: 36/36\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 0/36, Loss: 0.2891\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 1/36, Loss: 0.4961\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 2/36, Loss: 0.1208\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 3/36, Loss: 0.3130\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 4/36, Loss: 0.4680\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 5/36, Loss: 0.4261\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 6/36, Loss: 0.5142\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 7/36, Loss: 0.3669\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 8/36, Loss: 0.5039\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 9/36, Loss: 0.3059\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 10/36, Loss: 0.4191\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 11/36, Loss: 0.4662\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 12/36, Loss: 0.4445\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 13/36, Loss: 0.4981\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 14/36, Loss: 0.2943\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 15/36, Loss: 0.4612\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 16/36, Loss: 0.4883\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 17/36, Loss: 0.4881\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 18/36, Loss: 0.2763\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 19/36, Loss: 0.4410\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 20/36, Loss: 0.4163\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 21/36, Loss: 0.4147\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 22/36, Loss: 0.4947\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 23/36, Loss: 0.4415\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 71/100, Batch 24/36, Loss: 0.0833\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 25/36, Loss: 0.4480\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 26/36, Loss: 0.4207\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 27/36, Loss: 0.4245\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 28/36, Loss: 0.5229\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 29/36, Loss: 0.2814\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 30/36, Loss: 0.2980\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 31/36, Loss: 0.4859\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 32/36, Loss: 0.5107\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 33/36, Loss: 0.0672\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 34/36, Loss: 0.4182\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 71/100, Batch 35/36, Loss: 0.3834\n",
      "Epoch 71/100, Average Loss: 0.3942, Valid Batches: 36/36\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 0/36, Loss: 0.4777\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 1/36, Loss: 0.4377\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 2/36, Loss: 0.5179\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 3/36, Loss: 0.3664\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 4/36, Loss: 0.2982\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 5/36, Loss: 0.4035\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 6/36, Loss: 0.3752\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 7/36, Loss: 0.4170\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 8/36, Loss: 0.3089\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 9/36, Loss: 0.5247\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 10/36, Loss: 0.3051\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 11/36, Loss: 0.4249\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 12/36, Loss: 0.4277\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 13/36, Loss: 0.4104\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 14/36, Loss: 0.4586\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 15/36, Loss: 0.4848\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 16/36, Loss: 0.4726\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 17/36, Loss: 0.5024\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 72/100, Batch 18/36, Loss: 0.0793\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 19/36, Loss: 0.4121\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 20/36, Loss: 0.0743\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 21/36, Loss: 0.4835\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 22/36, Loss: 0.2787\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 23/36, Loss: 0.4999\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 24/36, Loss: 0.4143\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 25/36, Loss: 0.4984\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 26/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 27/36, Loss: 0.5153\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 28/36, Loss: 0.5087\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 29/36, Loss: 0.4400\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 30/36, Loss: 0.4454\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 31/36, Loss: 0.3250\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 32/36, Loss: 0.3011\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 33/36, Loss: 0.1159\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 34/36, Loss: 0.4636\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 72/100, Batch 35/36, Loss: 0.2726\n",
      "Epoch 72/100, Average Loss: 0.3934, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 0/36, Loss: 0.4832\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 1/36, Loss: 0.4924\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 2/36, Loss: 0.2901\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 3/36, Loss: 0.2961\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 4/36, Loss: 0.5279\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 5/36, Loss: 0.5153\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 6/36, Loss: 0.4189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 7/36, Loss: 0.3661\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 8/36, Loss: 0.4067\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 9/36, Loss: 0.5079\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 10/36, Loss: 0.5042\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 11/36, Loss: 0.4190\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 12/36, Loss: 0.5042\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 13/36, Loss: 0.2666\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 14/36, Loss: 0.4470\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 15/36, Loss: 0.4275\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 16/36, Loss: 0.4131\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 17/36, Loss: 0.4375\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 18/36, Loss: 0.5118\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 19/36, Loss: 0.4772\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 20/36, Loss: 0.3690\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 21/36, Loss: 0.1219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 22/36, Loss: 0.4283\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 23/36, Loss: 0.2750\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 24/36, Loss: 0.4024\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 25/36, Loss: 0.4691\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 26/36, Loss: 0.4654\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 27/36, Loss: 0.3363\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 28/36, Loss: 0.3112\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 73/100, Batch 29/36, Loss: 0.0853\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 30/36, Loss: 0.4723\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 31/36, Loss: 0.0657\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 32/36, Loss: 0.5177\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 33/36, Loss: 0.2881\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 34/36, Loss: 0.4185\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 73/100, Batch 35/36, Loss: 0.4521\n",
      "Epoch 73/100, Average Loss: 0.3942, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 0/36, Loss: 0.4405\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 1/36, Loss: 0.5111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 2/36, Loss: 0.4583\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 3/36, Loss: 0.4265\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 4/36, Loss: 0.3004\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 5/36, Loss: 0.4681\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 6/36, Loss: 0.4205\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 7/36, Loss: 0.4220\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 8/36, Loss: 0.4212\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 9/36, Loss: 0.3001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 10/36, Loss: 0.4510\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 11/36, Loss: 0.3755\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 12/36, Loss: 0.4896\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 13/36, Loss: 0.4739\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 14/36, Loss: 0.3674\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 15/36, Loss: 0.4849\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 74/100, Batch 16/36, Loss: 0.0874\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 17/36, Loss: 0.2936\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 18/36, Loss: 0.4307\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 19/36, Loss: 0.4164\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 20/36, Loss: 0.0637\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 21/36, Loss: 0.4728\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 22/36, Loss: 0.2664\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 23/36, Loss: 0.4922\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 24/36, Loss: 0.4065\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 25/36, Loss: 0.4533\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 26/36, Loss: 0.1217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 27/36, Loss: 0.4970\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 28/36, Loss: 0.3084\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 29/36, Loss: 0.4139\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 30/36, Loss: 0.5195\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 31/36, Loss: 0.3140\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 32/36, Loss: 0.4919\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 33/36, Loss: 0.5232\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 34/36, Loss: 0.2711\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 74/100, Batch 35/36, Loss: 0.4933\n",
      "Epoch 74/100, Average Loss: 0.3930, Valid Batches: 36/36\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 0/36, Loss: 0.4447\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 1/36, Loss: 0.5235\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 2/36, Loss: 0.4121\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 3/36, Loss: 0.4129\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 4/36, Loss: 0.4611\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 5/36, Loss: 0.3748\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 6/36, Loss: 0.4941\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 7/36, Loss: 0.4729\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 75/100, Batch 8/36, Loss: 0.0806\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 9/36, Loss: 0.4828\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 10/36, Loss: 0.2755\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 11/36, Loss: 0.3101\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 12/36, Loss: 0.3140\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 13/36, Loss: 0.4644\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 14/36, Loss: 0.4613\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 15/36, Loss: 0.2944\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 16/36, Loss: 0.4456\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 17/36, Loss: 0.2844\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 18/36, Loss: 0.5011\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 19/36, Loss: 0.4291\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 20/36, Loss: 0.4406\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 21/36, Loss: 0.5117\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 22/36, Loss: 0.3798\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 23/36, Loss: 0.4903\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 24/36, Loss: 0.0709\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 25/36, Loss: 0.2913\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 26/36, Loss: 0.4240\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 27/36, Loss: 0.4270\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 28/36, Loss: 0.4963\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 29/36, Loss: 0.1294\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 30/36, Loss: 0.4909\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 31/36, Loss: 0.4092\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 32/36, Loss: 0.2643\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 33/36, Loss: 0.4152\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 34/36, Loss: 0.4193\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 75/100, Batch 35/36, Loss: 0.5158\n",
      "Epoch 75/100, Average Loss: 0.3921, Valid Batches: 36/36\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 0/36, Loss: 0.2719\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 1/36, Loss: 0.5190\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 2/36, Loss: 0.2845\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 3/36, Loss: 0.4255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 4/36, Loss: 0.5087\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 5/36, Loss: 0.4843\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 6/36, Loss: 0.2944\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 7/36, Loss: 0.5141\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 8/36, Loss: 0.4170\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 9/36, Loss: 0.4874\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 10/36, Loss: 0.5100\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 11/36, Loss: 0.4322\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 12/36, Loss: 0.4609\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 13/36, Loss: 0.4241\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 14/36, Loss: 0.4382\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 15/36, Loss: 0.1220\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 16/36, Loss: 0.2723\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 17/36, Loss: 0.4708\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 18/36, Loss: 0.4186\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 19/36, Loss: 0.3720\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 20/36, Loss: 0.3079\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 21/36, Loss: 0.4099\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 22/36, Loss: 0.4452\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 23/36, Loss: 0.5161\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 24/36, Loss: 0.4088\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 25/36, Loss: 0.4453\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 26/36, Loss: 0.4901\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 27/36, Loss: 0.3190\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 76/100, Batch 28/36, Loss: 0.0815\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 29/36, Loss: 0.4982\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 30/36, Loss: 0.2877\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 31/36, Loss: 0.3805\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 32/36, Loss: 0.0677\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 33/36, Loss: 0.4965\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 34/36, Loss: 0.4642\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 76/100, Batch 35/36, Loss: 0.4192\n",
      "Epoch 76/100, Average Loss: 0.3935, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 0/36, Loss: 0.3034\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 1/36, Loss: 0.4264\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 2/36, Loss: 0.4055\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 3/36, Loss: 0.3054\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 4/36, Loss: 0.4088\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 5/36, Loss: 0.4526\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 6/36, Loss: 0.0726\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 7/36, Loss: 0.4768\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 8/36, Loss: 0.3583\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 9/36, Loss: 0.2744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 10/36, Loss: 0.3772\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 11/36, Loss: 0.5004\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 12/36, Loss: 0.4015\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 13/36, Loss: 0.2692\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 14/36, Loss: 0.4169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 15/36, Loss: 0.4255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 16/36, Loss: 0.4879\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 17/36, Loss: 0.4683\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 18/36, Loss: 0.1184\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 19/36, Loss: 0.5186\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 20/36, Loss: 0.5278\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 21/36, Loss: 0.5196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 22/36, Loss: 0.4774\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 77/100, Batch 23/36, Loss: 0.0887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 24/36, Loss: 0.2958\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 25/36, Loss: 0.2958\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 26/36, Loss: 0.4994\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 27/36, Loss: 0.4466\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 28/36, Loss: 0.5055\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 29/36, Loss: 0.4903\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 30/36, Loss: 0.4354\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 31/36, Loss: 0.2856\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 32/36, Loss: 0.4350\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 33/36, Loss: 0.4613\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 34/36, Loss: 0.4238\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 77/100, Batch 35/36, Loss: 0.4862\n",
      "Epoch 77/100, Average Loss: 0.3928, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 0/36, Loss: 0.4234\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 1/36, Loss: 0.0656\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 2/36, Loss: 0.3033\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 3/36, Loss: 0.4912\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 4/36, Loss: 0.4274\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 5/36, Loss: 0.2655\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 6/36, Loss: 0.4278\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 7/36, Loss: 0.4799\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 8/36, Loss: 0.4243\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 9/36, Loss: 0.4203\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 10/36, Loss: 0.3658\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 11/36, Loss: 0.2952\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 12/36, Loss: 0.2698\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 13/36, Loss: 0.5302\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 14/36, Loss: 0.1203\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 15/36, Loss: 0.3714\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 16/36, Loss: 0.4830\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 17/36, Loss: 0.4913\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 18/36, Loss: 0.5137\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 19/36, Loss: 0.4165\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 20/36, Loss: 0.4798\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 21/36, Loss: 0.4155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 22/36, Loss: 0.4166\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 23/36, Loss: 0.3054\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 24/36, Loss: 0.5176\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 25/36, Loss: 0.4460\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 26/36, Loss: 0.2968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 27/36, Loss: 0.2972\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 28/36, Loss: 0.4599\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 29/36, Loss: 0.4105\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 30/36, Loss: 0.4408\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 31/36, Loss: 0.5083\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 32/36, Loss: 0.5111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 33/36, Loss: 0.4578\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 78/100, Batch 34/36, Loss: 0.0858\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 78/100, Batch 35/36, Loss: 0.4749\n",
      "Epoch 78/100, Average Loss: 0.3919, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 0/36, Loss: 0.4962\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 79/100, Batch 1/36, Loss: 0.0915\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 2/36, Loss: 0.0626\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 3/36, Loss: 0.4927\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 4/36, Loss: 0.4236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 5/36, Loss: 0.4345\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 6/36, Loss: 0.2744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 7/36, Loss: 0.4881\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 8/36, Loss: 0.4219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 9/36, Loss: 0.4711\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 10/36, Loss: 0.4713\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 11/36, Loss: 0.5147\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 12/36, Loss: 0.4432\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 13/36, Loss: 0.4181\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 14/36, Loss: 0.2865\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 15/36, Loss: 0.3061\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 16/36, Loss: 0.4422\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 17/36, Loss: 0.5175\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 18/36, Loss: 0.3649\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 19/36, Loss: 0.4862\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 20/36, Loss: 0.2883\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 21/36, Loss: 0.3095\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 22/36, Loss: 0.4951\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 23/36, Loss: 0.3881\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 24/36, Loss: 0.2826\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 25/36, Loss: 0.4295\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 26/36, Loss: 0.5063\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 27/36, Loss: 0.4191\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 28/36, Loss: 0.4732\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 29/36, Loss: 0.4128\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 30/36, Loss: 0.5213\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 31/36, Loss: 0.4604\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 32/36, Loss: 0.4291\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 33/36, Loss: 0.1219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 34/36, Loss: 0.4201\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 79/100, Batch 35/36, Loss: 0.3109\n",
      "Epoch 79/100, Average Loss: 0.3938, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 0/36, Loss: 0.4632\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 1/36, Loss: 0.4259\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 2/36, Loss: 0.2914\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 3/36, Loss: 0.2870\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 4/36, Loss: 0.4531\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 5/36, Loss: 0.4651\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 6/36, Loss: 0.5100\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 7/36, Loss: 0.4850\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 8/36, Loss: 0.4933\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 9/36, Loss: 0.3062\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 10/36, Loss: 0.2690\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 11/36, Loss: 0.5319\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 12/36, Loss: 0.3117\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 13/36, Loss: 0.4078\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 14/36, Loss: 0.2782\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 15/36, Loss: 0.4862\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 16/36, Loss: 0.4406\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 17/36, Loss: 0.4789\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 18/36, Loss: 0.3746\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 19/36, Loss: 0.4166\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 20/36, Loss: 0.0695\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 21/36, Loss: 0.3755\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 22/36, Loss: 0.4252\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 23/36, Loss: 0.4815\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 24/36, Loss: 0.4199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 25/36, Loss: 0.3063\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 26/36, Loss: 0.4299\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 27/36, Loss: 0.4170\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 28/36, Loss: 0.4139\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 29/36, Loss: 0.5075\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 30/36, Loss: 0.4972\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 31/36, Loss: 0.5232\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 32/36, Loss: 0.4383\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 33/36, Loss: 0.4949\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 80/100, Batch 34/36, Loss: 0.1171\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 80/100, Batch 35/36, Loss: 0.0825\n",
      "Epoch 80/100, Average Loss: 0.3938, Valid Batches: 36/36\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 0/36, Loss: 0.1142\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 1/36, Loss: 0.4263\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 2/36, Loss: 0.0589\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 3/36, Loss: 0.4393\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 4/36, Loss: 0.3837\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 5/36, Loss: 0.3339\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 6/36, Loss: 0.4981\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 7/36, Loss: 0.3827\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 8/36, Loss: 0.2636\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 9/36, Loss: 0.2803\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 10/36, Loss: 0.4821\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 11/36, Loss: 0.4082\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 12/36, Loss: 0.4848\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 81/100, Batch 13/36, Loss: 0.0758\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 14/36, Loss: 0.4956\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 15/36, Loss: 0.4829\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 16/36, Loss: 0.2986\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 17/36, Loss: 0.5201\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 18/36, Loss: 0.5039\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 19/36, Loss: 0.2972\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 20/36, Loss: 0.4636\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 21/36, Loss: 0.2978\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 22/36, Loss: 0.4378\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 23/36, Loss: 0.5197\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 24/36, Loss: 0.5083\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 25/36, Loss: 0.4097\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 26/36, Loss: 0.5001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 27/36, Loss: 0.4218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 28/36, Loss: 0.4230\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 29/36, Loss: 0.4451\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 30/36, Loss: 0.4488\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 31/36, Loss: 0.5082\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 32/36, Loss: 0.4266\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 33/36, Loss: 0.4042\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 34/36, Loss: 0.4681\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 81/100, Batch 35/36, Loss: 0.3124\n",
      "Epoch 81/100, Average Loss: 0.3951, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 0/36, Loss: 0.2827\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 1/36, Loss: 0.4122\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 2/36, Loss: 0.2800\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 3/36, Loss: 0.1271\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 4/36, Loss: 0.4784\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 5/36, Loss: 0.5092\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 6/36, Loss: 0.2727\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 7/36, Loss: 0.4761\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 8/36, Loss: 0.3725\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 9/36, Loss: 0.3031\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 10/36, Loss: 0.4326\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 11/36, Loss: 0.4922\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 12/36, Loss: 0.4300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 13/36, Loss: 0.5247\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 82/100, Batch 14/36, Loss: 0.0820\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 15/36, Loss: 0.4963\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 16/36, Loss: 0.4591\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 17/36, Loss: 0.4224\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 18/36, Loss: 0.4218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 19/36, Loss: 0.4527\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 20/36, Loss: 0.4846\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 21/36, Loss: 0.2863\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 22/36, Loss: 0.2912\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 23/36, Loss: 0.4175\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 24/36, Loss: 0.4367\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 25/36, Loss: 0.5236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 26/36, Loss: 0.5061\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 27/36, Loss: 0.5058\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 28/36, Loss: 0.4793\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 29/36, Loss: 0.4651\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 30/36, Loss: 0.0625\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 31/36, Loss: 0.4153\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 32/36, Loss: 0.3859\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 33/36, Loss: 0.4269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 34/36, Loss: 0.4112\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 82/100, Batch 35/36, Loss: 0.3154\n",
      "Epoch 82/100, Average Loss: 0.3928, Valid Batches: 36/36\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 0/36, Loss: 0.4751\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 1/36, Loss: 0.4060\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 2/36, Loss: 0.3056\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 3/36, Loss: 0.3660\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 4/36, Loss: 0.4671\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 5/36, Loss: 0.4085\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 6/36, Loss: 0.2845\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 7/36, Loss: 0.4450\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 8/36, Loss: 0.4366\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 9/36, Loss: 0.2694\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 10/36, Loss: 0.3797\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 11/36, Loss: 0.3042\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 83/100, Batch 12/36, Loss: 0.0887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 13/36, Loss: 0.4287\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 14/36, Loss: 0.4777\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 15/36, Loss: 0.3106\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 16/36, Loss: 0.4163\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 17/36, Loss: 0.0679\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 18/36, Loss: 0.4872\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 19/36, Loss: 0.4169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 20/36, Loss: 0.5169\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 21/36, Loss: 0.4260\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 22/36, Loss: 0.4809\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 23/36, Loss: 0.5175\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 24/36, Loss: 0.1131\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 25/36, Loss: 0.4198\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 26/36, Loss: 0.4615\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 27/36, Loss: 0.4451\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 28/36, Loss: 0.3121\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 29/36, Loss: 0.4946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 30/36, Loss: 0.4939\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 31/36, Loss: 0.4842\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 32/36, Loss: 0.4093\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 33/36, Loss: 0.5162\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 34/36, Loss: 0.3002\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 83/100, Batch 35/36, Loss: 0.4941\n",
      "Epoch 83/100, Average Loss: 0.3924, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 0/36, Loss: 0.4245\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 1/36, Loss: 0.3022\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 2/36, Loss: 0.4154\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 3/36, Loss: 0.4801\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 4/36, Loss: 0.4389\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 5/36, Loss: 0.2876\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 84/100, Batch 6/36, Loss: 0.0799\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 7/36, Loss: 0.4927\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 8/36, Loss: 0.4460\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 9/36, Loss: 0.4938\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 10/36, Loss: 0.4014\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 11/36, Loss: 0.4189\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 12/36, Loss: 0.2678\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 13/36, Loss: 0.4612\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 14/36, Loss: 0.5208\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 15/36, Loss: 0.3023\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 16/36, Loss: 0.4682\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 17/36, Loss: 0.0599\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 18/36, Loss: 0.5131\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 19/36, Loss: 0.5057\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 20/36, Loss: 0.4212\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 21/36, Loss: 0.3034\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 22/36, Loss: 0.3161\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 23/36, Loss: 0.1230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 24/36, Loss: 0.4073\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 25/36, Loss: 0.3908\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 26/36, Loss: 0.4304\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 27/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 28/36, Loss: 0.5244\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 29/36, Loss: 0.2767\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 30/36, Loss: 0.4217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 31/36, Loss: 0.3578\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 32/36, Loss: 0.4997\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 33/36, Loss: 0.4846\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 34/36, Loss: 0.4874\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 84/100, Batch 35/36, Loss: 0.4881\n",
      "Epoch 84/100, Average Loss: 0.3926, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 0/36, Loss: 0.4326\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 1/36, Loss: 0.4344\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 2/36, Loss: 0.4323\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 3/36, Loss: 0.2717\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 4/36, Loss: 0.4141\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 5/36, Loss: 0.5086\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 6/36, Loss: 0.2893\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 7/36, Loss: 0.2857\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 8/36, Loss: 0.4592\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 9/36, Loss: 0.2887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 10/36, Loss: 0.4211\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 11/36, Loss: 0.4406\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 12/36, Loss: 0.4767\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 13/36, Loss: 0.4002\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 14/36, Loss: 0.4888\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 15/36, Loss: 0.2596\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 16/36, Loss: 0.3714\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 17/36, Loss: 0.5300\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 18/36, Loss: 0.4884\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 19/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 20/36, Loss: 0.5220\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 21/36, Loss: 0.4208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 22/36, Loss: 0.5044\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 23/36, Loss: 0.1164\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 24/36, Loss: 0.5048\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 25/36, Loss: 0.4607\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 26/36, Loss: 0.4806\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 27/36, Loss: 0.4416\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 85/100, Batch 28/36, Loss: 0.0839\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 29/36, Loss: 0.4801\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 30/36, Loss: 0.4188\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 31/36, Loss: 0.5075\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 32/36, Loss: 0.3678\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 33/36, Loss: 0.3227\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 34/36, Loss: 0.3078\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 85/100, Batch 35/36, Loss: 0.0687\n",
      "Epoch 85/100, Average Loss: 0.3923, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 0/36, Loss: 0.3013\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 1/36, Loss: 0.4590\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 2/36, Loss: 0.4988\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 3/36, Loss: 0.2954\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 4/36, Loss: 0.2858\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 5/36, Loss: 0.4360\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 6/36, Loss: 0.4811\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 7/36, Loss: 0.4547\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 8/36, Loss: 0.4101\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 9/36, Loss: 0.5226\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 10/36, Loss: 0.2908\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 11/36, Loss: 0.2684\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 12/36, Loss: 0.4193\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 13/36, Loss: 0.4870\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 14/36, Loss: 0.3783\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 15/36, Loss: 0.4609\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 16/36, Loss: 0.4146\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 17/36, Loss: 0.4236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 18/36, Loss: 0.5257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 19/36, Loss: 0.5142\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 20/36, Loss: 0.3146\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 21/36, Loss: 0.5155\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 22/36, Loss: 0.4327\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 23/36, Loss: 0.4189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 24/36, Loss: 0.3645\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 25/36, Loss: 0.2755\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 26/36, Loss: 0.0731\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 27/36, Loss: 0.4894\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 28/36, Loss: 0.1208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 29/36, Loss: 0.4272\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 30/36, Loss: 0.4707\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 31/36, Loss: 0.4164\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 32/36, Loss: 0.4362\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 33/36, Loss: 0.4933\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 86/100, Batch 34/36, Loss: 0.0794\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 86/100, Batch 35/36, Loss: 0.5042\n",
      "Epoch 86/100, Average Loss: 0.3933, Valid Batches: 36/36\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 0/36, Loss: 0.4765\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 1/36, Loss: 0.4333\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 2/36, Loss: 0.4707\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 3/36, Loss: 0.4046\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 4/36, Loss: 0.4609\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 5/36, Loss: 0.1152\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 6/36, Loss: 0.4254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 7/36, Loss: 0.4331\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 8/36, Loss: 0.4413\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 9/36, Loss: 0.2980\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 10/36, Loss: 0.3219\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 11/36, Loss: 0.4876\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 12/36, Loss: 0.4194\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 13/36, Loss: 0.5012\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 14/36, Loss: 0.0575\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 15/36, Loss: 0.4195\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 16/36, Loss: 0.3569\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 17/36, Loss: 0.4191\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 18/36, Loss: 0.2945\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 19/36, Loss: 0.4873\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 20/36, Loss: 0.3872\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 21/36, Loss: 0.2662\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 22/36, Loss: 0.5215\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 23/36, Loss: 0.4187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 24/36, Loss: 0.4363\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 25/36, Loss: 0.3127\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 26/36, Loss: 0.4767\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 27/36, Loss: 0.4986\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 87/100, Batch 28/36, Loss: 0.0873\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 29/36, Loss: 0.2958\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 30/36, Loss: 0.5268\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 31/36, Loss: 0.4911\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 32/36, Loss: 0.4666\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 33/36, Loss: 0.5112\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 34/36, Loss: 0.4172\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 87/100, Batch 35/36, Loss: 0.2686\n",
      "Epoch 87/100, Average Loss: 0.3918, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 0/36, Loss: 0.3008\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 1/36, Loss: 0.3046\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 2/36, Loss: 0.4096\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 3/36, Loss: 0.4267\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 4/36, Loss: 0.4657\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 5/36, Loss: 0.4948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 6/36, Loss: 0.4342\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 7/36, Loss: 0.1236\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 8/36, Loss: 0.0631\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 9/36, Loss: 0.4299\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 10/36, Loss: 0.3610\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 11/36, Loss: 0.2913\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 12/36, Loss: 0.5206\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 13/36, Loss: 0.3179\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 14/36, Loss: 0.4586\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 15/36, Loss: 0.2884\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 16/36, Loss: 0.4452\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 17/36, Loss: 0.3805\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 18/36, Loss: 0.4714\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 19/36, Loss: 0.2749\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 20/36, Loss: 0.5092\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 21/36, Loss: 0.4207\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 22/36, Loss: 0.4066\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 23/36, Loss: 0.4193\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 88/100, Batch 24/36, Loss: 0.0903\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 25/36, Loss: 0.4182\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 26/36, Loss: 0.4809\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 27/36, Loss: 0.5068\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 28/36, Loss: 0.4091\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 29/36, Loss: 0.4709\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 30/36, Loss: 0.5185\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 31/36, Loss: 0.4892\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 32/36, Loss: 0.4974\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 33/36, Loss: 0.4142\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 34/36, Loss: 0.4756\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 88/100, Batch 35/36, Loss: 0.2824\n",
      "Epoch 88/100, Average Loss: 0.3909, Valid Batches: 36/36\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 0/36, Loss: 0.0638\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 1/36, Loss: 0.3046\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 2/36, Loss: 0.3786\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 3/36, Loss: 0.4798\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 4/36, Loss: 0.4182\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 5/36, Loss: 0.4346\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 6/36, Loss: 0.3014\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 7/36, Loss: 0.3156\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 8/36, Loss: 0.4415\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 9/36, Loss: 0.4409\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 10/36, Loss: 0.5050\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 11/36, Loss: 0.4159\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 12/36, Loss: 0.4208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 13/36, Loss: 0.4578\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 89/100, Batch 14/36, Loss: 0.0926\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 15/36, Loss: 0.4146\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 16/36, Loss: 0.2933\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 17/36, Loss: 0.4952\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 18/36, Loss: 0.2660\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 19/36, Loss: 0.4759\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 20/36, Loss: 0.5290\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 21/36, Loss: 0.5052\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 22/36, Loss: 0.5078\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 23/36, Loss: 0.3749\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 24/36, Loss: 0.5082\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 25/36, Loss: 0.2933\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 26/36, Loss: 0.4356\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 27/36, Loss: 0.4115\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 28/36, Loss: 0.4065\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 29/36, Loss: 0.4264\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 30/36, Loss: 0.4832\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 31/36, Loss: 0.5184\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 32/36, Loss: 0.1215\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 33/36, Loss: 0.2589\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 34/36, Loss: 0.4748\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 89/100, Batch 35/36, Loss: 0.4725\n",
      "Epoch 89/100, Average Loss: 0.3929, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 0/36, Loss: 0.5141\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 1/36, Loss: 0.2744\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 2/36, Loss: 0.4659\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 3/36, Loss: 0.5148\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 4/36, Loss: 0.4800\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 5/36, Loss: 0.4803\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 6/36, Loss: 0.4262\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 7/36, Loss: 0.4218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 8/36, Loss: 0.3786\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 9/36, Loss: 0.3104\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 10/36, Loss: 0.4306\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 11/36, Loss: 0.5091\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 12/36, Loss: 0.4322\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 13/36, Loss: 0.2968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 14/36, Loss: 0.4918\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 15/36, Loss: 0.4199\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 16/36, Loss: 0.2867\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 17/36, Loss: 0.5101\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 18/36, Loss: 0.3756\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 19/36, Loss: 0.4380\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 20/36, Loss: 0.4967\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 21/36, Loss: 0.4353\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 22/36, Loss: 0.4183\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 90/100, Batch 23/36, Loss: 0.0849\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 24/36, Loss: 0.4608\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 25/36, Loss: 0.4462\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 26/36, Loss: 0.5125\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 27/36, Loss: 0.4233\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 28/36, Loss: 0.4708\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 29/36, Loss: 0.1184\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 30/36, Loss: 0.3062\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 31/36, Loss: 0.0611\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 32/36, Loss: 0.4746\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 33/36, Loss: 0.2630\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 34/36, Loss: 0.4233\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 90/100, Batch 35/36, Loss: 0.3284\n",
      "Epoch 90/100, Average Loss: 0.3939, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 0/36, Loss: 0.3315\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 1/36, Loss: 0.4877\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 2/36, Loss: 0.3707\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 3/36, Loss: 0.2908\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 4/36, Loss: 0.3142\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 5/36, Loss: 0.0707\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 6/36, Loss: 0.4597\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 7/36, Loss: 0.4863\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 8/36, Loss: 0.4463\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 9/36, Loss: 0.5290\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 10/36, Loss: 0.3727\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 11/36, Loss: 0.5268\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 91/100, Batch 12/36, Loss: 0.0939\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 13/36, Loss: 0.4783\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 14/36, Loss: 0.4214\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 15/36, Loss: 0.4242\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 16/36, Loss: 0.3122\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 17/36, Loss: 0.1221\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 18/36, Loss: 0.4423\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 19/36, Loss: 0.2757\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 20/36, Loss: 0.4264\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 21/36, Loss: 0.4166\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 22/36, Loss: 0.2735\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 23/36, Loss: 0.4099\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 24/36, Loss: 0.4610\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 25/36, Loss: 0.5102\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 26/36, Loss: 0.3009\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 27/36, Loss: 0.4254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 28/36, Loss: 0.4856\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 29/36, Loss: 0.5066\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 30/36, Loss: 0.4254\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 31/36, Loss: 0.4681\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 32/36, Loss: 0.4978\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 33/36, Loss: 0.4048\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 34/36, Loss: 0.4878\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 91/100, Batch 35/36, Loss: 0.4218\n",
      "Epoch 91/100, Average Loss: 0.3938, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 0/36, Loss: 0.4244\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 1/36, Loss: 0.0623\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 2/36, Loss: 0.4597\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 3/36, Loss: 0.4404\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 92/100, Batch 4/36, Loss: 0.0762\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 5/36, Loss: 0.4227\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 6/36, Loss: 0.2785\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 7/36, Loss: 0.4326\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 8/36, Loss: 0.5136\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 9/36, Loss: 0.4122\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 10/36, Loss: 0.4204\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 11/36, Loss: 0.4248\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 12/36, Loss: 0.4753\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 13/36, Loss: 0.5021\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 14/36, Loss: 0.4040\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 15/36, Loss: 0.2820\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 16/36, Loss: 0.4133\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 17/36, Loss: 0.3178\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 18/36, Loss: 0.4256\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 19/36, Loss: 0.4872\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 20/36, Loss: 0.2931\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 21/36, Loss: 0.3901\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 22/36, Loss: 0.4837\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 23/36, Loss: 0.5057\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 24/36, Loss: 0.4606\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 25/36, Loss: 0.2786\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 26/36, Loss: 0.4880\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 27/36, Loss: 0.4742\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 28/36, Loss: 0.2986\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 29/36, Loss: 0.1268\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 30/36, Loss: 0.5350\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 31/36, Loss: 0.5024\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 32/36, Loss: 0.4373\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 33/36, Loss: 0.3834\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 34/36, Loss: 0.5274\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 92/100, Batch 35/36, Loss: 0.3055\n",
      "Epoch 92/100, Average Loss: 0.3935, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 0/36, Loss: 0.4199\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 1/36, Loss: 0.3686\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 2/36, Loss: 0.4661\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 3/36, Loss: 0.1208\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 4/36, Loss: 0.4658\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 5/36, Loss: 0.4631\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 6/36, Loss: 0.4310\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 7/36, Loss: 0.4782\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 8/36, Loss: 0.4001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 9/36, Loss: 0.4293\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 10/36, Loss: 0.5118\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 11/36, Loss: 0.4041\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 12/36, Loss: 0.5280\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 13/36, Loss: 0.3213\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 14/36, Loss: 0.4138\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 15/36, Loss: 0.4099\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 16/36, Loss: 0.0693\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 17/36, Loss: 0.4202\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 18/36, Loss: 0.2752\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 19/36, Loss: 0.2915\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 20/36, Loss: 0.2990\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 21/36, Loss: 0.5016\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 22/36, Loss: 0.5124\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 23/36, Loss: 0.3016\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 24/36, Loss: 0.4790\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 25/36, Loss: 0.4230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 26/36, Loss: 0.4355\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 27/36, Loss: 0.4449\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 28/36, Loss: 0.2699\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 29/36, Loss: 0.2891\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 30/36, Loss: 0.4791\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 93/100, Batch 31/36, Loss: 0.0912\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 32/36, Loss: 0.4968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 33/36, Loss: 0.4525\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 34/36, Loss: 0.4982\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 93/100, Batch 35/36, Loss: 0.4864\n",
      "Epoch 93/100, Average Loss: 0.3930, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 0/36, Loss: 0.4438\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 1/36, Loss: 0.3027\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 2/36, Loss: 0.3660\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 3/36, Loss: 0.4348\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 4/36, Loss: 0.2765\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 5/36, Loss: 0.2589\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 6/36, Loss: 0.4047\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 7/36, Loss: 0.4396\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 8/36, Loss: 0.4777\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 9/36, Loss: 0.4218\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 10/36, Loss: 0.4999\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 11/36, Loss: 0.4869\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 12/36, Loss: 0.5216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 13/36, Loss: 0.4826\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 14/36, Loss: 0.2731\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 15/36, Loss: 0.4914\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 16/36, Loss: 0.4216\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 17/36, Loss: 0.3852\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 18/36, Loss: 0.4266\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 19/36, Loss: 0.5023\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 20/36, Loss: 0.4679\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 21/36, Loss: 0.2977\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 22/36, Loss: 0.4310\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 23/36, Loss: 0.5257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 24/36, Loss: 0.4163\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 25/36, Loss: 0.4954\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 26/36, Loss: 0.5161\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 27/36, Loss: 0.0665\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 28/36, Loss: 0.3209\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 29/36, Loss: 0.4307\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 94/100, Batch 30/36, Loss: 0.0813\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 31/36, Loss: 0.3010\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 32/36, Loss: 0.4660\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 33/36, Loss: 0.1130\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 34/36, Loss: 0.4124\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 94/100, Batch 35/36, Loss: 0.4806\n",
      "Epoch 94/100, Average Loss: 0.3928, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 0/36, Loss: 0.5264\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 1/36, Loss: 0.5060\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 2/36, Loss: 0.4129\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 3/36, Loss: 0.3001\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 4/36, Loss: 0.4081\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 5/36, Loss: 0.4360\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 6/36, Loss: 0.3063\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 7/36, Loss: 0.0654\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 8/36, Loss: 0.3677\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 9/36, Loss: 0.4624\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 10/36, Loss: 0.4796\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 11/36, Loss: 0.4434\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 12/36, Loss: 0.3642\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 13/36, Loss: 0.4629\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 14/36, Loss: 0.4493\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 15/36, Loss: 0.2762\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 16/36, Loss: 0.4266\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 17/36, Loss: 0.4772\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 18/36, Loss: 0.4230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 19/36, Loss: 0.5076\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 20/36, Loss: 0.4195\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 21/36, Loss: 0.5054\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 22/36, Loss: 0.2815\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 95/100, Batch 23/36, Loss: 0.0777\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 24/36, Loss: 0.4251\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 25/36, Loss: 0.2855\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 26/36, Loss: 0.2887\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 27/36, Loss: 0.4092\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 28/36, Loss: 0.4696\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 29/36, Loss: 0.4041\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 30/36, Loss: 0.5214\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 31/36, Loss: 0.1201\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 32/36, Loss: 0.5005\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 33/36, Loss: 0.4847\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 34/36, Loss: 0.4722\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 95/100, Batch 35/36, Loss: 0.3163\n",
      "Epoch 95/100, Average Loss: 0.3912, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 0/36, Loss: 0.4190\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 1/36, Loss: 0.3572\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 2/36, Loss: 0.4805\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 3/36, Loss: 0.4399\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 4/36, Loss: 0.5118\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 5/36, Loss: 0.4460\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 6/36, Loss: 0.3801\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 7/36, Loss: 0.4995\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 8/36, Loss: 0.4784\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 9/36, Loss: 0.4150\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 10/36, Loss: 0.4234\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 11/36, Loss: 0.4239\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 12/36, Loss: 0.4307\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 13/36, Loss: 0.4793\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 14/36, Loss: 0.3126\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 15/36, Loss: 0.5144\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 16/36, Loss: 0.1322\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 17/36, Loss: 0.4656\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 18/36, Loss: 0.4118\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 19/36, Loss: 0.3070\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 20/36, Loss: 0.4558\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 96/100, Batch 21/36, Loss: 0.0928\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 22/36, Loss: 0.2898\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 23/36, Loss: 0.4718\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 24/36, Loss: 0.5269\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 25/36, Loss: 0.0630\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 26/36, Loss: 0.4236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 27/36, Loss: 0.4245\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 28/36, Loss: 0.2792\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 29/36, Loss: 0.2722\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 30/36, Loss: 0.2894\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 31/36, Loss: 0.4926\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 32/36, Loss: 0.2898\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 33/36, Loss: 0.5010\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 34/36, Loss: 0.5194\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 96/100, Batch 35/36, Loss: 0.4354\n",
      "Epoch 96/100, Average Loss: 0.3932, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 0/36, Loss: 0.4958\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 1/36, Loss: 0.4868\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 2/36, Loss: 0.4638\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 3/36, Loss: 0.4298\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 4/36, Loss: 0.4315\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 5/36, Loss: 0.1188\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 6/36, Loss: 0.4130\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 7/36, Loss: 0.4874\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 8/36, Loss: 0.2782\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 9/36, Loss: 0.4205\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 10/36, Loss: 0.2946\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 11/36, Loss: 0.3714\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 12/36, Loss: 0.3093\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 13/36, Loss: 0.4616\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 14/36, Loss: 0.4918\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 15/36, Loss: 0.4111\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 16/36, Loss: 0.5073\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 17/36, Loss: 0.0688\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 18/36, Loss: 0.4077\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 19/36, Loss: 0.2624\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 20/36, Loss: 0.3099\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 21/36, Loss: 0.4824\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 22/36, Loss: 0.4387\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 23/36, Loss: 0.4169\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 24/36, Loss: 0.4821\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 97/100, Batch 25/36, Loss: 0.0884\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 26/36, Loss: 0.2833\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 27/36, Loss: 0.2990\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 28/36, Loss: 0.5254\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 29/36, Loss: 0.3704\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 30/36, Loss: 0.5269\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 31/36, Loss: 0.4640\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 32/36, Loss: 0.4265\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 33/36, Loss: 0.4406\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 34/36, Loss: 0.4273\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 97/100, Batch 35/36, Loss: 0.5162\n",
      "Epoch 97/100, Average Loss: 0.3919, Valid Batches: 36/36\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 0/36, Loss: 0.0673\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 1/36, Loss: 0.5196\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 2/36, Loss: 0.5067\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 3/36, Loss: 0.2733\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 4/36, Loss: 0.4544\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 5/36, Loss: 0.5123\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 6/36, Loss: 0.4712\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 7/36, Loss: 0.4694\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 8/36, Loss: 0.3815\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 9/36, Loss: 0.4994\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 10/36, Loss: 0.4874\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 11/36, Loss: 0.3682\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 12/36, Loss: 0.4051\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 13/36, Loss: 0.4886\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 14/36, Loss: 0.4240\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 15/36, Loss: 0.4190\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 16/36, Loss: 0.4187\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 17/36, Loss: 0.4152\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 18/36, Loss: 0.2948\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 19/36, Loss: 0.5228\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 20/36, Loss: 0.3046\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 21/36, Loss: 0.2971\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 22/36, Loss: 0.4779\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 23/36, Loss: 0.4236\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 24/36, Loss: 0.2975\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 25/36, Loss: 0.2761\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 26/36, Loss: 0.4465\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 27/36, Loss: 0.2818\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 28/36, Loss: 0.4379\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 29/36, Loss: 0.4753\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 98/100, Batch 30/36, Loss: 0.0938\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 31/36, Loss: 0.4072\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 32/36, Loss: 0.1257\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 33/36, Loss: 0.5002\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 34/36, Loss: 0.4287\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 98/100, Batch 35/36, Loss: 0.4284\n",
      "Epoch 98/100, Average Loss: 0.3917, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 0/36, Loss: 0.4968\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 1/36, Loss: 0.3020\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 2/36, Loss: 0.4123\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 3/36, Loss: 0.2632\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 4/36, Loss: 0.4716\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 5/36, Loss: 0.4834\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 6/36, Loss: 0.2776\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 7/36, Loss: 0.4235\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 8/36, Loss: 0.4189\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 9/36, Loss: 0.5129\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 10/36, Loss: 0.3732\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 11/36, Loss: 0.4782\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 12/36, Loss: 0.4621\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 13/36, Loss: 0.4076\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 14/36, Loss: 0.4411\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 15/36, Loss: 0.5215\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 16/36, Loss: 0.4688\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 17/36, Loss: 0.4912\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 18/36, Loss: 0.3103\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 19/36, Loss: 0.1187\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 20/36, Loss: 0.3120\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 21/36, Loss: 0.2934\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 22/36, Loss: 0.5067\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 23/36, Loss: 0.4255\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 24/36, Loss: 0.4210\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 25/36, Loss: 0.4757\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 99/100, Batch 26/36, Loss: 0.0877\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 27/36, Loss: 0.5180\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 28/36, Loss: 0.4400\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 29/36, Loss: 0.4493\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 30/36, Loss: 0.4063\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 31/36, Loss: 0.2700\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 32/36, Loss: 0.5016\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 33/36, Loss: 0.0674\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 34/36, Loss: 0.3687\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 99/100, Batch 35/36, Loss: 0.4152\n",
      "Epoch 99/100, Average Loss: 0.3915, Valid Batches: 36/36\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 0/36, Loss: 0.5098\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 1/36, Loss: 0.4852\n",
      "Batch size: 5729, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 2/36, Loss: 0.3217\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 3/36, Loss: 0.4832\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 4/36, Loss: 0.4625\n",
      "Batch size: 4608, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 5/36, Loss: 0.2808\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 6/36, Loss: 0.3681\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 7/36, Loss: 0.4203\n",
      "Batch size: 4154, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 8/36, Loss: 0.1192\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 9/36, Loss: 0.2971\n",
      "Batch size: 5128, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 10/36, Loss: 0.2852\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 11/36, Loss: 0.4056\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 12/36, Loss: 0.4126\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 13/36, Loss: 0.4142\n",
      "Batch size: 4098, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 14/36, Loss: 0.0703\n",
      "Batch size: 4096, Unique labels: [0, 2]\n",
      "Epoch 100/100, Batch 15/36, Loss: 0.0822\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 16/36, Loss: 0.5231\n",
      "Batch size: 5555, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 17/36, Loss: 0.4516\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 18/36, Loss: 0.4230\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 19/36, Loss: 0.5060\n",
      "Batch size: 4550, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 20/36, Loss: 0.2853\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 21/36, Loss: 0.4375\n",
      "Batch size: 6026, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 22/36, Loss: 0.4819\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 23/36, Loss: 0.5307\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 24/36, Loss: 0.3905\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 25/36, Loss: 0.4091\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 26/36, Loss: 0.4270\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 27/36, Loss: 0.4454\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 28/36, Loss: 0.4197\n",
      "Batch size: 4435, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 29/36, Loss: 0.2800\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 30/36, Loss: 0.4965\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 31/36, Loss: 0.4950\n",
      "Batch size: 5463, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 32/36, Loss: 0.4832\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 33/36, Loss: 0.4755\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 34/36, Loss: 0.3013\n",
      "Batch size: 6144, Unique labels: [0, 1, 2]\n",
      "Epoch 100/100, Batch 35/36, Loss: 0.4719\n",
      "Epoch 100/100, Average Loss: 0.3931, Valid Batches: 36/36\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    valid_batches = 0\n",
    "    for batch_idx, (embeddings, labels) in enumerate(loader):\n",
    "        embeddings = embeddings.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)\n",
    "        labels = labels.squeeze(0)\n",
    "        \n",
    "        embeddings_flat = embeddings.reshape(-1, 48)\n",
    "        labels_flat = labels.reshape(-1)\n",
    "        \n",
    "        valid_mask = labels_flat >= 0\n",
    "        embeddings_valid = embeddings_flat[valid_mask]\n",
    "        labels_valid = labels_flat[valid_mask]\n",
    "        \n",
    "        if embeddings_valid.shape[0] < 2:\n",
    "            print(f\"Batch {batch_idx}: Insuficientes vóxeles válidos\")\n",
    "            continue\n",
    "        \n",
    "        z = model(embeddings_valid)\n",
    "        loss = contrastive_loss(z, labels_valid, temperature, sample_size_per_class)\n",
    "        \n",
    "        if loss.item() == 0:\n",
    "            continue  # No contar batches con pérdida 0 en el promedio\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        valid_batches += 1\n",
    "        \n",
    "        if batch_idx % 1 == 0:  # Reducir frecuencia de impresión\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}\")\n",
    "    \n",
    "    avg_loss = total_loss / max(valid_batches, 1)  # Evitar división por 0\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}, Valid Batches: {valid_batches}/{len(loader)}\")\n",
    "\n",
    "torch.save(model.state_dict(), \"trained_models/contrastive_projection_head.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels: [0, 1, 2]\n",
      "Case 0: Fondo: 2004144, Vasogénico: 1032, Infiltrado: 91976\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 1: Fondo: 2056648, Vasogénico: 18101, Infiltrado: 22403\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 2: Fondo: 2079347, Vasogénico: 512, Infiltrado: 17293\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 3: Fondo: 2084680, Vasogénico: 6398, Infiltrado: 6074\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 4: Fondo: 1994106, Vasogénico: 3204, Infiltrado: 99842\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 5: Fondo: 2059831, Vasogénico: 2, Infiltrado: 37319\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 6: Fondo: 2065553, Vasogénico: 1930, Infiltrado: 29669\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 7: Fondo: 2038238, Vasogénico: 5913, Infiltrado: 53001\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 8: Fondo: 2068807, Vasogénico: 17756, Infiltrado: 10589\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 9: Fondo: 2054422, Vasogénico: 58, Infiltrado: 42672\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 10: Fondo: 1964971, Vasogénico: 23627, Infiltrado: 108554\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 11: Fondo: 2081185, Vasogénico: 3571, Infiltrado: 12396\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 12: Fondo: 2060643, Vasogénico: 7601, Infiltrado: 28908\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 13: Fondo: 1995052, Vasogénico: 12444, Infiltrado: 89656\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 14: Fondo: 1977290, Vasogénico: 339, Infiltrado: 119523\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 15: Fondo: 2070020, Vasogénico: 3584, Infiltrado: 23548\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 16: Fondo: 2023925, Vasogénico: 30312, Infiltrado: 42915\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 17: Fondo: 1983599, Vasogénico: 12105, Infiltrado: 101448\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 18: Fondo: 1950824, Vasogénico: 5697, Infiltrado: 140631\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 19: Fondo: 2016777, Vasogénico: 33491, Infiltrado: 46884\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 20: Fondo: 2055059, Vasogénico: 26397, Infiltrado: 15696\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 21: Fondo: 2079027, Vasogénico: 2325, Infiltrado: 15800\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 22: Fondo: 2026204, Vasogénico: 34847, Infiltrado: 36101\n",
      "Unique labels: [0, 2]\n",
      "Case 23: Fondo: 2069068, Vasogénico: 0, Infiltrado: 28084\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 24: Fondo: 1988206, Vasogénico: 7552, Infiltrado: 101394\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 25: Fondo: 2076974, Vasogénico: 1459, Infiltrado: 18719\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 26: Fondo: 1972565, Vasogénico: 6331, Infiltrado: 118256\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 27: Fondo: 2085164, Vasogénico: 4085, Infiltrado: 7903\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 28: Fondo: 2026402, Vasogénico: 1367, Infiltrado: 69383\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 29: Fondo: 2072591, Vasogénico: 1633, Infiltrado: 22928\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 30: Fondo: 2076054, Vasogénico: 2810, Infiltrado: 18288\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 31: Fondo: 2073712, Vasogénico: 6671, Infiltrado: 16769\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 32: Fondo: 2027214, Vasogénico: 5312, Infiltrado: 64626\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 33: Fondo: 2022145, Vasogénico: 454, Infiltrado: 74553\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 34: Fondo: 2064529, Vasogénico: 8917, Infiltrado: 23706\n",
      "Unique labels: [0, 1, 2]\n",
      "Case 35: Fondo: 2081618, Vasogénico: 5183, Infiltrado: 10351\n"
     ]
    }
   ],
   "source": [
    "for idx, (embeddings, labels) in enumerate(loader):\n",
    "    print(f\"Unique labels: {torch.unique(labels).tolist()}\")\n",
    "    labels_flat = labels.reshape(-1)\n",
    "    class_counts = torch.bincount(labels_flat)\n",
    "    print(f\"Case {idx}: Fondo: {class_counts[0]}, Vasogénico: {class_counts[1] if len(class_counts) > 1 else 0}, Infiltrado: {class_counts[2] if len(class_counts) > 2 else 0}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar modelo de clasificacion supervisado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2658900/1920189412.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  projection_head.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final.pth\", map_location=device))\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Dataset (ya lo tienes)\n",
    "class EmbeddingDataset(Dataset):\n",
    "    def __init__(self, embedding_dir, label_dir):\n",
    "        self.embedding_dir = embedding_dir\n",
    "        self.label_dir = label_dir\n",
    "        self.case_files = [f for f in os.listdir(embedding_dir) if f.endswith(\".npy\")]\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.case_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        embedding_path = os.path.join(self.embedding_dir, f\"case_{idx}.npy\")\n",
    "        label_path = os.path.join(self.label_dir, f\"case_{idx}.npy\")\n",
    "        \n",
    "        embeddings = np.load(embedding_path)  # [1, 48, 128, 128, 128]\n",
    "        labels = np.load(label_path)  # [128, 128, 128]\n",
    "        \n",
    "        embeddings = torch.tensor(embeddings, dtype=torch.float32).squeeze(0)  # [48, 128, 128, 128]\n",
    "        labels = torch.tensor(labels, dtype=torch.long)  # [128, 128, 128]\n",
    "        \n",
    "        return embeddings, labels\n",
    "\n",
    "# Modelo de proyección (ya lo tienes)\n",
    "class ProjectionHead(nn.Module):\n",
    "    def __init__(self, input_dim=48, hidden_dim=128, output_dim=128):\n",
    "        super(ProjectionHead, self).__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(input_dim, hidden_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_dim, output_dim)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# Clasificador supervisado\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_dim=128, num_classes=3):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(input_dim, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# Configuración\n",
    "embedding_dir = \"Dataset/contrastive_voxel_wise/embeddings\"\n",
    "label_dir = \"Dataset/contrastive_voxel_wise/labels\"\n",
    "batch_size = 1\n",
    "sample_size_per_class = 3333  # ~10,000 vóxeles total\n",
    "num_epochs = 100  # Máximo de épocas\n",
    "patience = 10  # Early stopping: épocas sin mejora\n",
    "\n",
    "# Cargar dataset y DataLoader\n",
    "dataset = EmbeddingDataset(embedding_dir, label_dir)\n",
    "loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "\n",
    "# Cargar modelo contrastivo preentrenado\n",
    "projection_head = ProjectionHead(input_dim=48).to(device)\n",
    "projection_head.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final.pth\", map_location=device))\n",
    "projection_head.eval()  # Modo evaluación, sin gradientes\n",
    "\n",
    "# Definir clasificador\n",
    "classifier = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "optimizer = optim.Adam(classifier.parameters(), lr=0.001)\n",
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=3, verbose=True)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Batch 0/36, Loss: 1.0780, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 5/36, Loss: 1.0328, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 10/36, Loss: 0.9910, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 15/36, Loss: 0.9468, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 20/36, Loss: 0.9046, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 25/36, Loss: 0.8675, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 30/36, Loss: 0.8287, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Batch 35/36, Loss: 0.8114, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 1/100, Average Loss: 0.9284, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.9284\n",
      "Epoch 2/100, Batch 0/36, Loss: 0.7519, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 2/100, Batch 5/36, Loss: 0.7536, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Batch 10/36, Loss: 0.7198, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Batch 15/36, Loss: 0.6937, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Batch 20/36, Loss: 0.6596, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Batch 25/36, Loss: 0.6363, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Batch 30/36, Loss: 0.6035, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Batch 35/36, Loss: 0.5997, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 2/100, Average Loss: 0.6803, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.6803\n",
      "Epoch 3/100, Batch 0/36, Loss: 0.5839, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 5/36, Loss: 0.5506, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 10/36, Loss: 0.5493, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 15/36, Loss: 0.5037, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 20/36, Loss: 0.4866, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 25/36, Loss: 0.4687, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 30/36, Loss: 0.4447, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Batch 35/36, Loss: 0.4369, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 3/100, Average Loss: 0.5061, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.5061\n",
      "Epoch 4/100, Batch 0/36, Loss: 0.4312, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 5/36, Loss: 0.4244, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 10/36, Loss: 0.4138, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 15/36, Loss: 0.4044, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 20/36, Loss: 0.3768, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 25/36, Loss: 0.3672, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 30/36, Loss: 0.3869, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Batch 35/36, Loss: 0.3447, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 4/100, Average Loss: 0.3897, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.3897\n",
      "Epoch 5/100, Batch 0/36, Loss: 0.3475, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 5/36, Loss: 0.3277, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 10/36, Loss: 0.3050, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 15/36, Loss: 0.3333, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 20/36, Loss: 0.2847, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 25/36, Loss: 0.2817, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 30/36, Loss: 0.2858, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Batch 35/36, Loss: 0.2782, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 5/100, Average Loss: 0.3107, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.3107\n",
      "Epoch 6/100, Batch 0/36, Loss: 0.2745, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 5/36, Loss: 0.3417, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 10/36, Loss: 0.2512, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 15/36, Loss: 0.2306, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 20/36, Loss: 0.2417, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 25/36, Loss: 0.2560, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 30/36, Loss: 0.2339, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Batch 35/36, Loss: 0.2455, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 6/100, Average Loss: 0.2565, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.2565\n",
      "Epoch 7/100, Batch 0/36, Loss: 0.2123, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 5/36, Loss: 0.2184, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 10/36, Loss: 0.2360, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 15/36, Loss: 0.3054, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 20/36, Loss: 0.2190, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 25/36, Loss: 0.1930, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 30/36, Loss: 0.2070, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Batch 35/36, Loss: 0.1747, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 7/100, Average Loss: 0.2197, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.2197\n",
      "Epoch 8/100, Batch 0/36, Loss: 0.1984, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 5/36, Loss: 0.2106, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 10/36, Loss: 0.2013, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 15/36, Loss: 0.1718, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 20/36, Loss: 0.1779, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 25/36, Loss: 0.1835, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 30/36, Loss: 0.2271, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Batch 35/36, Loss: 0.1522, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 8/100, Average Loss: 0.1921, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1921\n",
      "Epoch 9/100, Batch 0/36, Loss: 0.1687, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Batch 5/36, Loss: 0.1939, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Batch 10/36, Loss: 0.1619, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Batch 15/36, Loss: 0.1427, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Batch 20/36, Loss: 0.1313, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 9/100, Batch 25/36, Loss: 0.1701, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Batch 30/36, Loss: 0.1288, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Batch 35/36, Loss: 0.1816, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 9/100, Average Loss: 0.1721, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1721\n",
      "Epoch 10/100, Batch 0/36, Loss: 0.1689, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 5/36, Loss: 0.2270, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 10/36, Loss: 0.1365, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 15/36, Loss: 0.1633, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 20/36, Loss: 0.1312, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 25/36, Loss: 0.1727, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 30/36, Loss: 0.1392, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Batch 35/36, Loss: 0.1377, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 10/100, Average Loss: 0.1571, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1571\n",
      "Epoch 11/100, Batch 0/36, Loss: 0.1458, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 5/36, Loss: 0.1517, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 10/36, Loss: 0.2256, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 15/36, Loss: 0.1127, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 20/36, Loss: 0.1946, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 25/36, Loss: 0.1120, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 30/36, Loss: 0.0989, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Batch 35/36, Loss: 0.1241, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 11/100, Average Loss: 0.1451, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1451\n",
      "Epoch 12/100, Batch 0/36, Loss: 0.1550, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 5/36, Loss: 0.2157, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 10/36, Loss: 0.1383, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 15/36, Loss: 0.1279, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 20/36, Loss: 0.1281, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 25/36, Loss: 0.1259, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 30/36, Loss: 0.1435, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Batch 35/36, Loss: 0.1185, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 12/100, Average Loss: 0.1359, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1359\n",
      "Epoch 13/100, Batch 0/36, Loss: 0.1515, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 5/36, Loss: 0.0962, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 10/36, Loss: 0.1277, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 15/36, Loss: 0.0881, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 20/36, Loss: 0.1454, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 25/36, Loss: 0.2324, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 30/36, Loss: 0.1329, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Batch 35/36, Loss: 0.1028, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 13/100, Average Loss: 0.1285, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1285\n",
      "Epoch 14/100, Batch 0/36, Loss: 0.1204, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 5/36, Loss: 0.1220, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 10/36, Loss: 0.1130, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 15/36, Loss: 0.0800, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 20/36, Loss: 0.1121, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 25/36, Loss: 0.1041, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 30/36, Loss: 0.1010, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Batch 35/36, Loss: 0.1117, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 14/100, Average Loss: 0.1226, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1226\n",
      "Epoch 15/100, Batch 0/36, Loss: 0.1039, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Batch 5/36, Loss: 0.0735, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 15/100, Batch 10/36, Loss: 0.1269, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Batch 15/36, Loss: 0.1188, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Batch 20/36, Loss: 0.1178, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Batch 25/36, Loss: 0.1321, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Batch 30/36, Loss: 0.2162, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Batch 35/36, Loss: 0.0768, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 15/100, Average Loss: 0.1173, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1173\n",
      "Epoch 16/100, Batch 0/36, Loss: 0.0900, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 5/36, Loss: 0.1152, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 10/36, Loss: 0.1276, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 15/36, Loss: 0.1297, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 20/36, Loss: 0.0963, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 25/36, Loss: 0.2026, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 30/36, Loss: 0.0691, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Batch 35/36, Loss: 0.0999, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 16/100, Average Loss: 0.1135, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1135\n",
      "Epoch 17/100, Batch 0/36, Loss: 0.1048, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 5/36, Loss: 0.2108, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 10/36, Loss: 0.0997, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 15/36, Loss: 0.1105, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 20/36, Loss: 0.1142, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 25/36, Loss: 0.0887, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 30/36, Loss: 0.1624, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Batch 35/36, Loss: 0.0981, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 17/100, Average Loss: 0.1099, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1099\n",
      "Epoch 18/100, Batch 0/36, Loss: 0.1007, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 5/36, Loss: 0.1238, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 10/36, Loss: 0.1909, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 15/36, Loss: 0.1313, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 20/36, Loss: 0.0778, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 25/36, Loss: 0.0667, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 30/36, Loss: 0.0926, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Batch 35/36, Loss: 0.0676, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 18/100, Average Loss: 0.1077, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1077\n",
      "Epoch 19/100, Batch 0/36, Loss: 0.0770, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 5/36, Loss: 0.0890, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 10/36, Loss: 0.2188, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 15/36, Loss: 0.0898, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 20/36, Loss: 0.0622, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 25/36, Loss: 0.1046, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 30/36, Loss: 0.0776, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Batch 35/36, Loss: 0.1348, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 19/100, Average Loss: 0.1065, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1065\n",
      "Epoch 20/100, Batch 0/36, Loss: 0.0958, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 5/36, Loss: 0.1653, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 10/36, Loss: 0.1239, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 15/36, Loss: 0.0953, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 20/36, Loss: 0.1349, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 25/36, Loss: 0.1101, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 30/36, Loss: 0.1590, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Batch 35/36, Loss: 0.1220, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 20/100, Average Loss: 0.1031, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1031\n",
      "Epoch 21/100, Batch 0/36, Loss: 0.0835, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 5/36, Loss: 0.0642, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 10/36, Loss: 0.0893, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 15/36, Loss: 0.0907, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 20/36, Loss: 0.0755, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 25/36, Loss: 0.1231, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 30/36, Loss: 0.0621, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Batch 35/36, Loss: 0.0973, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 21/100, Average Loss: 0.1022, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1022\n",
      "Epoch 22/100, Batch 0/36, Loss: 0.0844, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 5/36, Loss: 0.0756, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 10/36, Loss: 0.0573, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 15/36, Loss: 0.0940, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 20/36, Loss: 0.0859, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 25/36, Loss: 0.2178, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 30/36, Loss: 0.1632, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Batch 35/36, Loss: 0.1170, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 22/100, Average Loss: 0.1000, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.1000\n",
      "Epoch 23/100, Batch 0/36, Loss: 0.0703, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Batch 5/36, Loss: 0.0523, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 23/100, Batch 10/36, Loss: 0.1097, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Batch 15/36, Loss: 0.1264, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Batch 20/36, Loss: 0.0920, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Batch 25/36, Loss: 0.0887, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Batch 30/36, Loss: 0.0602, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Batch 35/36, Loss: 0.1215, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 23/100, Average Loss: 0.0994, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0994\n",
      "Epoch 24/100, Batch 0/36, Loss: 0.0535, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 24/100, Batch 5/36, Loss: 0.0854, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Batch 10/36, Loss: 0.0881, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Batch 15/36, Loss: 0.2152, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Batch 20/36, Loss: 0.0784, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Batch 25/36, Loss: 0.0873, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Batch 30/36, Loss: 0.0522, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Batch 35/36, Loss: 0.1608, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 24/100, Average Loss: 0.0977, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0977\n",
      "Epoch 25/100, Batch 0/36, Loss: 0.0984, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Batch 5/36, Loss: 0.0442, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 25/100, Batch 10/36, Loss: 0.0680, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Batch 15/36, Loss: 0.1248, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Batch 20/36, Loss: 0.1773, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Batch 25/36, Loss: 0.0773, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Batch 30/36, Loss: 0.0901, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Batch 35/36, Loss: 0.1176, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 25/100, Average Loss: 0.0957, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0957\n",
      "Epoch 26/100, Batch 0/36, Loss: 0.0843, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 5/36, Loss: 0.2154, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 10/36, Loss: 0.0457, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 15/36, Loss: 0.0615, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 20/36, Loss: 0.0956, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 25/36, Loss: 0.0847, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 30/36, Loss: 0.0738, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Batch 35/36, Loss: 0.1011, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 26/100, Average Loss: 0.0967, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 27/100, Batch 0/36, Loss: 0.1800, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 5/36, Loss: 0.0835, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 10/36, Loss: 0.1142, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 15/36, Loss: 0.0418, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 20/36, Loss: 0.0622, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 25/36, Loss: 0.1252, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 30/36, Loss: 0.1622, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Batch 35/36, Loss: 0.0520, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 27/100, Average Loss: 0.0947, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0947\n",
      "Epoch 28/100, Batch 0/36, Loss: 0.0840, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 5/36, Loss: 0.0653, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 10/36, Loss: 0.0491, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 15/36, Loss: 0.0626, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 20/36, Loss: 0.0937, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 25/36, Loss: 0.0874, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 30/36, Loss: 0.0825, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Batch 35/36, Loss: 0.1118, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 28/100, Average Loss: 0.0944, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0944\n",
      "Epoch 29/100, Batch 0/36, Loss: 0.0810, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 5/36, Loss: 0.0811, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 10/36, Loss: 0.1164, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 15/36, Loss: 0.1194, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 20/36, Loss: 0.0969, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 25/36, Loss: 0.0648, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 30/36, Loss: 0.0753, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Batch 35/36, Loss: 0.0507, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 29/100, Average Loss: 0.0946, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 30/100, Batch 0/36, Loss: 0.0716, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 5/36, Loss: 0.1056, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 10/36, Loss: 0.0847, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 15/36, Loss: 0.1521, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 20/36, Loss: 0.0507, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 25/36, Loss: 0.0714, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 30/36, Loss: 0.1551, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Batch 35/36, Loss: 0.1832, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 30/100, Average Loss: 0.0924, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0924\n",
      "Epoch 31/100, Batch 0/36, Loss: 0.1108, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 5/36, Loss: 0.1185, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 10/36, Loss: 0.0701, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 15/36, Loss: 0.1608, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 20/36, Loss: 0.0772, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 25/36, Loss: 0.0884, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 30/36, Loss: 0.0987, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Batch 35/36, Loss: 0.0847, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 31/100, Average Loss: 0.0928, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 32/100, Batch 0/36, Loss: 0.1093, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 5/36, Loss: 0.0826, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 10/36, Loss: 0.2278, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 15/36, Loss: 0.0687, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 20/36, Loss: 0.0852, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 25/36, Loss: 0.1679, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 30/36, Loss: 0.0736, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Batch 35/36, Loss: 0.0986, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 32/100, Average Loss: 0.0924, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 33/100, Batch 0/36, Loss: 0.1153, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 5/36, Loss: 0.0660, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 10/36, Loss: 0.0735, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 15/36, Loss: 0.1125, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 20/36, Loss: 0.0508, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 25/36, Loss: 0.0601, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 30/36, Loss: 0.0788, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Batch 35/36, Loss: 0.0835, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 33/100, Average Loss: 0.0916, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0916\n",
      "Epoch 34/100, Batch 0/36, Loss: 0.0458, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 5/36, Loss: 0.0555, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 10/36, Loss: 0.0754, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 15/36, Loss: 0.2077, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 20/36, Loss: 0.1056, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 25/36, Loss: 0.0737, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 30/36, Loss: 0.0612, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Batch 35/36, Loss: 0.1236, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 34/100, Average Loss: 0.0907, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0907\n",
      "Epoch 35/100, Batch 0/36, Loss: 0.1116, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 5/36, Loss: 0.1187, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 10/36, Loss: 0.0712, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 15/36, Loss: 0.0996, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 20/36, Loss: 0.0729, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 25/36, Loss: 0.0725, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 30/36, Loss: 0.0425, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Batch 35/36, Loss: 0.1004, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 35/100, Average Loss: 0.0907, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0907\n",
      "Epoch 36/100, Batch 0/36, Loss: 0.1153, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Batch 5/36, Loss: 0.0860, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Batch 10/36, Loss: 0.0355, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 36/100, Batch 15/36, Loss: 0.0823, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Batch 20/36, Loss: 0.1099, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Batch 25/36, Loss: 0.0991, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Batch 30/36, Loss: 0.0775, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Batch 35/36, Loss: 0.0627, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 36/100, Average Loss: 0.0908, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 37/100, Batch 0/36, Loss: 0.0670, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 5/36, Loss: 0.0635, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 10/36, Loss: 0.1127, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 15/36, Loss: 0.1681, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 20/36, Loss: 0.0922, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 25/36, Loss: 0.0755, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 30/36, Loss: 0.0738, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Batch 35/36, Loss: 0.1178, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 37/100, Average Loss: 0.0919, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 38/100, Batch 0/36, Loss: 0.1157, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 5/36, Loss: 0.0460, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 10/36, Loss: 0.0543, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 15/36, Loss: 0.0857, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 20/36, Loss: 0.1807, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 25/36, Loss: 0.0624, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 30/36, Loss: 0.1483, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Batch 35/36, Loss: 0.1161, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 38/100, Average Loss: 0.0897, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0897\n",
      "Epoch 39/100, Batch 0/36, Loss: 0.0480, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 5/36, Loss: 0.0769, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 10/36, Loss: 0.1768, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 15/36, Loss: 0.0544, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 20/36, Loss: 0.0590, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 25/36, Loss: 0.0683, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 30/36, Loss: 0.0953, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Batch 35/36, Loss: 0.0427, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 39/100, Average Loss: 0.0890, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0890\n",
      "Epoch 40/100, Batch 0/36, Loss: 0.0620, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 5/36, Loss: 0.0381, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 10/36, Loss: 0.0694, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 15/36, Loss: 0.0615, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 20/36, Loss: 0.0833, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 25/36, Loss: 0.0982, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 30/36, Loss: 0.0759, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Batch 35/36, Loss: 0.1312, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 40/100, Average Loss: 0.0895, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 41/100, Batch 0/36, Loss: 0.0751, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 5/36, Loss: 0.1111, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 10/36, Loss: 0.0481, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 15/36, Loss: 0.0658, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 20/36, Loss: 0.0865, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 25/36, Loss: 0.0738, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 30/36, Loss: 0.0523, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Batch 35/36, Loss: 0.0701, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 41/100, Average Loss: 0.0901, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 42/100, Batch 0/36, Loss: 0.0424, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 5/36, Loss: 0.1873, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 10/36, Loss: 0.0574, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 15/36, Loss: 0.0828, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 20/36, Loss: 0.0606, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 25/36, Loss: 0.0440, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 30/36, Loss: 0.0588, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Batch 35/36, Loss: 0.0453, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 42/100, Average Loss: 0.0883, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Guardado checkpoint con mejor pérdida: 0.0883\n",
      "Epoch 43/100, Batch 0/36, Loss: 0.1134, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 5/36, Loss: 0.0721, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 10/36, Loss: 0.0976, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 15/36, Loss: 0.0765, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 20/36, Loss: 0.0914, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 25/36, Loss: 0.0509, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 30/36, Loss: 0.0555, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Batch 35/36, Loss: 0.0957, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 43/100, Average Loss: 0.0898, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 44/100, Batch 0/36, Loss: 0.0603, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 5/36, Loss: 0.1476, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 10/36, Loss: 0.1119, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 15/36, Loss: 0.1739, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 20/36, Loss: 0.1993, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 25/36, Loss: 0.0779, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 30/36, Loss: 0.0714, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Batch 35/36, Loss: 0.1088, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 44/100, Average Loss: 0.0894, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 45/100, Batch 0/36, Loss: 0.0516, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 5/36, Loss: 0.0673, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 10/36, Loss: 0.0803, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 15/36, Loss: 0.1600, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 20/36, Loss: 0.1018, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 25/36, Loss: 0.1001, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 30/36, Loss: 0.0848, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Batch 35/36, Loss: 0.0562, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 45/100, Average Loss: 0.0900, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 46/100, Batch 0/36, Loss: 0.0453, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 5/36, Loss: 0.1586, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 10/36, Loss: 0.1863, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 15/36, Loss: 0.0478, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 20/36, Loss: 0.0747, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 25/36, Loss: 0.1576, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 30/36, Loss: 0.1050, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Batch 35/36, Loss: 0.0847, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 46/100, Average Loss: 0.0890, Valid Batches: 36/36, Learning Rate: 0.001000\n",
      "Épocas sin mejora: 4/10\n",
      "Epoch 47/100, Batch 0/36, Loss: 0.0790, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 5/36, Loss: 0.0395, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 10/36, Loss: 0.1787, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 15/36, Loss: 0.1098, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 20/36, Loss: 0.1037, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 25/36, Loss: 0.0805, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 30/36, Loss: 0.0929, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Batch 35/36, Loss: 0.0769, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 47/100, Average Loss: 0.0877, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Guardado checkpoint con mejor pérdida: 0.0877\n",
      "Epoch 48/100, Batch 0/36, Loss: 0.0701, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Batch 5/36, Loss: 0.1598, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Batch 10/36, Loss: 0.0355, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 48/100, Batch 15/36, Loss: 0.0778, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Batch 20/36, Loss: 0.1653, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Batch 25/36, Loss: 0.0724, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Batch 30/36, Loss: 0.1006, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Batch 35/36, Loss: 0.1228, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 48/100, Average Loss: 0.0897, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 49/100, Batch 0/36, Loss: 0.0618, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 5/36, Loss: 0.0700, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 10/36, Loss: 0.0876, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 15/36, Loss: 0.0850, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 20/36, Loss: 0.0771, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 25/36, Loss: 0.1725, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 30/36, Loss: 0.1125, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Batch 35/36, Loss: 0.1084, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 49/100, Average Loss: 0.0891, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 50/100, Batch 0/36, Loss: 0.0379, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 5/36, Loss: 0.0762, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 10/36, Loss: 0.0906, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 15/36, Loss: 0.0723, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 20/36, Loss: 0.1102, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 25/36, Loss: 0.1563, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 30/36, Loss: 0.0784, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Batch 35/36, Loss: 0.0510, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 50/100, Average Loss: 0.0865, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Guardado checkpoint con mejor pérdida: 0.0865\n",
      "Epoch 51/100, Batch 0/36, Loss: 0.1135, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Batch 5/36, Loss: 0.1123, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Batch 10/36, Loss: 0.0531, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Batch 15/36, Loss: 0.0313, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 51/100, Batch 20/36, Loss: 0.0839, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Batch 25/36, Loss: 0.2080, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Batch 30/36, Loss: 0.1127, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Batch 35/36, Loss: 0.0732, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 51/100, Average Loss: 0.0872, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 1/10\n",
      "Epoch 52/100, Batch 0/36, Loss: 0.1757, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 5/36, Loss: 0.0443, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 10/36, Loss: 0.1062, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 15/36, Loss: 0.0622, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 20/36, Loss: 0.0597, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 25/36, Loss: 0.1621, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 30/36, Loss: 0.0892, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Batch 35/36, Loss: 0.0709, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 52/100, Average Loss: 0.0887, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 2/10\n",
      "Epoch 53/100, Batch 0/36, Loss: 0.0335, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 53/100, Batch 5/36, Loss: 0.1692, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Batch 10/36, Loss: 0.0708, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Batch 15/36, Loss: 0.0944, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Batch 20/36, Loss: 0.0650, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Batch 25/36, Loss: 0.0412, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Batch 30/36, Loss: 0.1595, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Batch 35/36, Loss: 0.0473, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 53/100, Average Loss: 0.0887, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 3/10\n",
      "Epoch 54/100, Batch 0/36, Loss: 0.0755, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 5/36, Loss: 0.0792, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 10/36, Loss: 0.1089, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 15/36, Loss: 0.0824, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 20/36, Loss: 0.0407, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 25/36, Loss: 0.0684, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 30/36, Loss: 0.0940, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Batch 35/36, Loss: 0.0328, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 54/100, Average Loss: 0.0880, Valid Batches: 36/36, Learning Rate: 0.000500\n",
      "Épocas sin mejora: 4/10\n",
      "Epoch 55/100, Batch 0/36, Loss: 0.0837, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 5/36, Loss: 0.1793, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 10/36, Loss: 0.1204, Sampled size: 9507, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 15/36, Loss: 0.0438, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 20/36, Loss: 0.0719, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 25/36, Loss: 0.0688, Sampled size: 8331, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 30/36, Loss: 0.0770, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Batch 35/36, Loss: 0.1156, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 55/100, Average Loss: 0.0888, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 5/10\n",
      "Epoch 56/100, Batch 0/36, Loss: 0.2030, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 5/36, Loss: 0.0884, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 10/36, Loss: 0.1127, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 15/36, Loss: 0.0873, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 20/36, Loss: 0.1622, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 25/36, Loss: 0.0431, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 30/36, Loss: 0.0693, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Batch 35/36, Loss: 0.0916, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 56/100, Average Loss: 0.0888, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 6/10\n",
      "Epoch 57/100, Batch 0/36, Loss: 0.0554, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 5/36, Loss: 0.0337, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 10/36, Loss: 0.0651, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 15/36, Loss: 0.0861, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 20/36, Loss: 0.0701, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 25/36, Loss: 0.0723, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 30/36, Loss: 0.0534, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Batch 35/36, Loss: 0.1144, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 57/100, Average Loss: 0.0877, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 7/10\n",
      "Epoch 58/100, Batch 0/36, Loss: 0.0617, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Batch 5/36, Loss: 0.0378, Sampled size: 6666, Classes: [0, 2]\n",
      "Epoch 58/100, Batch 10/36, Loss: 0.1241, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Batch 15/36, Loss: 0.0756, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Batch 20/36, Loss: 0.1187, Sampled size: 7423, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Batch 25/36, Loss: 0.0683, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Batch 30/36, Loss: 0.0869, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Batch 35/36, Loss: 0.1612, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 58/100, Average Loss: 0.0897, Valid Batches: 36/36, Learning Rate: 0.000250\n",
      "Épocas sin mejora: 8/10\n",
      "Epoch 59/100, Batch 0/36, Loss: 0.0783, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 5/36, Loss: 0.1633, Sampled size: 9975, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 10/36, Loss: 0.0721, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 15/36, Loss: 0.0513, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 20/36, Loss: 0.0413, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 25/36, Loss: 0.0584, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 30/36, Loss: 0.0823, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Batch 35/36, Loss: 0.0657, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 59/100, Average Loss: 0.0888, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Épocas sin mejora: 9/10\n",
      "Epoch 60/100, Batch 0/36, Loss: 0.0826, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 5/36, Loss: 0.0441, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 10/36, Loss: 0.1650, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 15/36, Loss: 0.1252, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 20/36, Loss: 0.0912, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 25/36, Loss: 0.0424, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 30/36, Loss: 0.0719, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Batch 35/36, Loss: 0.0663, Sampled size: 9999, Classes: [0, 1, 2]\n",
      "Epoch 60/100, Average Loss: 0.0893, Valid Batches: 36/36, Learning Rate: 0.000125\n",
      "Épocas sin mejora: 10/10\n",
      "Early stopping activado tras 60 épocas. Mejor pérdida: 0.0865\n",
      "Cargado el mejor modelo desde trained_models/checkpoints/best_supervised_classifier.pth con pérdida: 0.0865\n",
      "Clasificador final guardado en 'trained_models/checkpoints/supervised_classifier_final.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2658900/3338365319.py:99: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(best_model_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "# Directorio para checkpoints\n",
    "output_dir = \"trained_models/checkpoints\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Variables para early stopping y checkpoints\n",
    "best_loss = float('inf')\n",
    "epochs_no_improve = 0\n",
    "best_model_path = os.path.join(output_dir, \"best_supervised_classifier.pth\")\n",
    "\n",
    "# Entrenamiento del clasificador con muestreo balanceado, scheduler y early stopping\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    valid_batches = 0\n",
    "    \n",
    "    classifier.train()  # Modo entrenamiento\n",
    "    \n",
    "    for batch_idx, (embeddings, labels) in enumerate(loader):\n",
    "        embeddings = embeddings.to(device)  # [1, 48, 128, 128, 128]\n",
    "        labels = labels.to(device)  # [1, 128, 128, 128]\n",
    "        \n",
    "        # Reorganizar para procesar vóxeles\n",
    "        embeddings = embeddings.squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        labels = labels.squeeze(0)  # [128, 128, 128]\n",
    "        \n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        labels_flat = labels.reshape(-1)  # [2097152]\n",
    "        \n",
    "        # Muestreo estratificado balanceado\n",
    "        classes = torch.unique(labels_flat)\n",
    "        if len(classes) < 2:\n",
    "            print(f\"Batch {batch_idx}: Solo una clase presente ({classes.tolist()}), saltando\")\n",
    "            continue\n",
    "        \n",
    "        sampled_embeddings = []\n",
    "        sampled_labels = []\n",
    "        \n",
    "        for cls in classes:\n",
    "            cls_indices = (labels_flat == cls).nonzero(as_tuple=True)[0]\n",
    "            cls_size = cls_indices.shape[0]\n",
    "            if cls_size > sample_size_per_class:\n",
    "                indices = torch.randperm(cls_size)[:sample_size_per_class]\n",
    "                cls_indices = cls_indices[indices]\n",
    "            sampled_embeddings.append(embeddings_flat[cls_indices])\n",
    "            sampled_labels.append(labels_flat[cls_indices])\n",
    "        \n",
    "        embeddings_sampled = torch.cat(sampled_embeddings, dim=0)\n",
    "        labels_sampled = torch.cat(sampled_labels, dim=0)\n",
    "        \n",
    "        # Obtener representaciones contrastivas\n",
    "        with torch.no_grad():\n",
    "            z = projection_head(embeddings_sampled)  # [N, 128]\n",
    "            z = F.normalize(z, dim=1)\n",
    "        \n",
    "        # Clasificación\n",
    "        logits = classifier(z)\n",
    "        loss = criterion(logits, labels_sampled)\n",
    "        \n",
    "        # Optimización\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        valid_batches += 1\n",
    "        \n",
    "        if batch_idx % 5 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}, Batch {batch_idx}/{len(loader)}, Loss: {loss.item():.4f}, \"\n",
    "                  f\"Sampled size: {embeddings_sampled.shape[0]}, Classes: {torch.unique(labels_sampled).tolist()}\")\n",
    "    \n",
    "    # Calcular pérdida promedio\n",
    "    avg_loss = total_loss / max(valid_batches, 1)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Average Loss: {avg_loss:.4f}, Valid Batches: {valid_batches}/{len(loader)}, \"\n",
    "          f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "    \n",
    "    # Scheduler: ajustar tasa de aprendizaje basada en la pérdida promedio\n",
    "    scheduler.step(avg_loss)\n",
    "    \n",
    "    # Checkpoint: guardar el mejor modelo\n",
    "    if avg_loss < best_loss:\n",
    "        best_loss = avg_loss\n",
    "        epochs_no_improve = 0\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': classifier.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'loss': best_loss,\n",
    "        }, best_model_path)\n",
    "        print(f\"Guardado checkpoint con mejor pérdida: {best_loss:.4f}\")\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        print(f\"Épocas sin mejora: {epochs_no_improve}/{patience}\")\n",
    "    \n",
    "    # Early stopping\n",
    "    if epochs_no_improve >= patience:\n",
    "        print(f\"Early stopping activado tras {epoch+1} épocas. Mejor pérdida: {best_loss:.4f}\")\n",
    "        break\n",
    "\n",
    "# Cargar el mejor modelo al final (opcional)\n",
    "checkpoint = torch.load(best_model_path, map_location=device)\n",
    "classifier.load_state_dict(checkpoint['model_state_dict'])\n",
    "print(f\"Cargado el mejor modelo desde {best_model_path} con pérdida: {checkpoint['loss']:.4f}\")\n",
    "\n",
    "# Guardar el modelo final (opcional)\n",
    "torch.save(classifier.state_dict(), os.path.join(output_dir, \"supervised_classifier_final.pth\"))\n",
    "print(\"Clasificador final guardado en 'trained_models/checkpoints/supervised_classifier_final.pth'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2658900/2256524057.py:37: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  projection_head.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final.pth\", map_location=device))\n",
      "/tmp/ipykernel_2658900/2256524057.py:41: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  classifier.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final.pth\", map_location=device))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapas de probabilidad para caso 0, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_0.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_0.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_0.nii.gz\n",
      "Mapas de probabilidad para caso 1, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_1.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_1.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_1.nii.gz\n",
      "Mapas de probabilidad para caso 2, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_2.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_2.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_2.nii.gz\n",
      "Mapas de probabilidad para caso 3, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_3.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_3.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_3.nii.gz\n",
      "Mapas de probabilidad para caso 4, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_4.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_4.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_4.nii.gz\n",
      "Mapas de probabilidad para caso 5, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_5.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_5.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_5.nii.gz\n",
      "Mapas de probabilidad para caso 6, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_6.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_6.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_6.nii.gz\n",
      "Mapas de probabilidad para caso 7, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_7.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_7.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_7.nii.gz\n",
      "Mapas de probabilidad para caso 8, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_8.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_8.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_8.nii.gz\n",
      "Mapas de probabilidad para caso 9, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_9.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_9.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_9.nii.gz\n",
      "Mapas de probabilidad para caso 10, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_10.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_10.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_10.nii.gz\n",
      "Mapas de probabilidad para caso 11, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_11.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_11.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_11.nii.gz\n",
      "Mapas de probabilidad para caso 12, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_12.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_12.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_12.nii.gz\n",
      "Mapas de probabilidad para caso 13, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_13.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_13.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_13.nii.gz\n",
      "Mapas de probabilidad para caso 14, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_14.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_14.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_14.nii.gz\n",
      "Mapas de probabilidad para caso 15, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_15.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_15.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_15.nii.gz\n",
      "Mapas de probabilidad para caso 16, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_16.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_16.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_16.nii.gz\n",
      "Mapas de probabilidad para caso 17, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_17.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_17.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_17.nii.gz\n",
      "Mapas de probabilidad para caso 18, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_18.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_18.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_18.nii.gz\n",
      "Mapas de probabilidad para caso 19, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_19.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_19.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_19.nii.gz\n",
      "Mapas de probabilidad para caso 20, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_20.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_20.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_20.nii.gz\n",
      "Mapas de probabilidad para caso 21, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_21.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_21.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_21.nii.gz\n",
      "Mapas de probabilidad para caso 22, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_22.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_22.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_22.nii.gz\n",
      "Mapas de probabilidad para caso 23, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_23.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_23.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_23.nii.gz\n",
      "Mapas de probabilidad para caso 24, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_24.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_24.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_24.nii.gz\n",
      "Mapas de probabilidad para caso 25, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_25.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_25.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_25.nii.gz\n",
      "Mapas de probabilidad para caso 26, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_26.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_26.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_26.nii.gz\n",
      "Mapas de probabilidad para caso 27, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_27.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_27.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_27.nii.gz\n",
      "Mapas de probabilidad para caso 28, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_28.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_28.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_28.nii.gz\n",
      "Mapas de probabilidad para caso 29, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_29.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_29.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_29.nii.gz\n",
      "Mapas de probabilidad para caso 30, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_30.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_30.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_30.nii.gz\n",
      "Mapas de probabilidad para caso 31, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_31.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_31.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_31.nii.gz\n",
      "Mapas de probabilidad para caso 32, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_32.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_32.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_32.nii.gz\n",
      "Mapas de probabilidad para caso 33, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_33.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_33.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_33.nii.gz\n",
      "Mapas de probabilidad para caso 34, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_34.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_34.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_34.nii.gz\n",
      "Mapas de probabilidad para caso 35, shape: torch.Size([3, 128, 128, 128])\n",
      "Guardado mapa de probabilidad como NIfTI en trained_models/mapas/probability_maps_case_35.nii.gz\n",
      "Guardadas etiquetas como NIfTI en trained_models/mapas/labels_case_35.nii.gz\n",
      "Guardada segmentación semántica como NIfTI en trained_models/mapas/segmentation_case_35.nii.gz\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import nibabel as nib\n",
    "\n",
    "# Dispositivo\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device):\n",
    "    \"\"\"\n",
    "    embeddings: tensor [1, 48, 128, 128, 128] - Características de SwinUNETR\n",
    "    Retorna: mapas de probabilidad [3, 128, 128, 128]\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.to(device).squeeze(0).permute(1, 2, 3, 0)  # [128, 128, 128, 48]\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)  # [2097152, 48]\n",
    "        \n",
    "        z = projection_head(embeddings_flat)  # [2097152, 128]\n",
    "        z = F.normalize(z, dim=1)\n",
    "        \n",
    "        logits = classifier(z)  # [2097152, 3]\n",
    "        probs = F.softmax(logits, dim=1)  # [2097152, 3]\n",
    "        \n",
    "        probs = probs.view(128, 128, 128, 3).permute(3, 0, 1, 2)  # [3, 128, 128, 128]\n",
    "        return probs\n",
    "\n",
    "dataset = EmbeddingDataset(embedding_dir=\"Dataset/contrastive_voxel_wise/embeddings\", \n",
    "                          label_dir=\"Dataset/contrastive_voxel_wise/labels\")\n",
    "loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=1)\n",
    "\n",
    "# Cargar modelos (asumiendo que ya los tienes cargados)\n",
    "projection_head = ProjectionHead(input_dim=48).to(device)\n",
    "projection_head.load_state_dict(torch.load(\"trained_models/checkpoints_contrastive/contrastive_projection_head_final.pth\", map_location=device))\n",
    "projection_head.eval()\n",
    "\n",
    "classifier = Classifier(input_dim=128, num_classes=3).to(device)\n",
    "classifier.load_state_dict(torch.load(\"trained_models/checkpoints/supervised_classifier_final.pth\", map_location=device))\n",
    "classifier.eval()\n",
    "\n",
    "# Directorio de salida\n",
    "output_dir = \"trained_models/mapas\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Procesar y guardar como NIfTI\n",
    "for idx, (embeddings, labels) in enumerate(loader):\n",
    "    # Generar mapas de probabilidad\n",
    "    prob_maps = generate_probability_maps(embeddings, projection_head, classifier, device)\n",
    "    print(f\"Mapas de probabilidad para caso {idx}, shape: {prob_maps.shape}\")\n",
    "    \n",
    "    # Convertir mapas de probabilidad a numpy y ajustar formato para NIfTI\n",
    "    prob_maps_np = prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "    prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3] para NIfTI\n",
    "    \n",
    "    # Generar segmentación semántica (clase más probable por vóxel)\n",
    "    segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128], valores 0, 1, 2\n",
    "    segmentation_np = segmentation.astype(np.uint8)  # Convertir a uint8 para NIfTI\n",
    "    \n",
    "    # Convertir etiquetas a numpy\n",
    "    labels = labels.squeeze(0)  # [128, 128, 128]\n",
    "    labels_np = labels.cpu().numpy().astype(np.uint8)  # Convertir a uint8\n",
    "    \n",
    "    # Crear imágenes NIfTI con matriz afín identidad\n",
    "    affine = np.eye(4)  # Ajusta si tienes una matriz afín real\n",
    "    \n",
    "    # Guardar mapas de probabilidad\n",
    "    nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine)\n",
    "    prob_output_path = os.path.join(output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_prob_img, prob_output_path)\n",
    "    print(f\"Guardado mapa de probabilidad como NIfTI en {prob_output_path}\")\n",
    "    \n",
    "    # Guardar etiquetas\n",
    "    nifti_label_img = nib.Nifti1Image(labels_np, affine)\n",
    "    label_output_path = os.path.join(output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_label_img, label_output_path)\n",
    "    print(f\"Guardadas etiquetas como NIfTI en {label_output_path}\")\n",
    "    \n",
    "    # Guardar segmentación semántica\n",
    "    nifti_seg_img = nib.Nifti1Image(segmentation_np, affine)\n",
    "    seg_output_path = os.path.join(output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_seg_img, seg_output_path)\n",
    "    print(f\"Guardada segmentación semántica como NIfTI en {seg_output_path}\")\n",
    "    \n",
    "    # break  # Descomenta si solo quieres procesar un caso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapas de probabilidad para caso 0, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 0 - Dice: [0.9982944408902586, 0.9232356331741467, 0.9555542309845121], Sensitivity: [0.9968744482419158, 0.9955503205083692, 0.9851694047143108], Precision: [0.9997184847111337, 0.8607150938152619, 0.9276676182274045]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_0.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_0.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_0.nii.gz\n",
      "Mapas de probabilidad para caso 1, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 1 - Dice: [0.9946391933217696, 0.6537797541027, 0.7608557280402959], Sensitivity: [0.9893491187988228, 0.999360255817724, 0.8377402418255353], Precision: [0.999986144285978, 0.4857920310792695, 0.6968972331878084]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_1.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_1.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_1.nii.gz\n",
      "Mapas de probabilidad para caso 2, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 2 - Dice: [0.9960974899550616, 0.8842157283382855, 0.9054693966099139], Sensitivity: [0.9922955319902077, 0.9824008784827649, 0.9541879950677146], Precision: [0.999928694208402, 0.8038733476600565, 0.8614840441900563]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_2.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_2.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_2.nii.gz\n",
      "Mapas de probabilidad para caso 3, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 3 - Dice: [0.9963603391718139, 0.9224855657130613, 0.7412600556209823], Sensitivity: [0.9927587182437826, 0.9818027499242301, 0.9346383543020836], Precision: [0.99998818783071, 0.86992750350841, 0.614184264604305]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_3.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_3.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_3.nii.gz\n",
      "Mapas de probabilidad para caso 4, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 4 - Dice: [0.9957368299542488, 0.9122539405659865, 0.6895344209970248], Sensitivity: [0.9915228935444964, 0.9716827852622173, 0.9560275861541502], Precision: [0.9999867373935246, 0.8596755424443947, 0.5392251439072904]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_4.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_4.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_4.nii.gz\n",
      "Mapas de probabilidad para caso 5, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 5 - Dice: [0.9962709850404369, 0.9581994138447668, 0.9308712650760285], Sensitivity: [0.9926939186948407, 0.9872466200626312, 0.984291673823926], Precision: [0.9998739237657318, 0.9308126333012658, 0.8829509176925538]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_5.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_5.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_5.nii.gz\n",
      "Mapas de probabilidad para caso 6, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 6 - Dice: [0.9948576126617785, 0.7927282204474667, 0.7244714071406536], Sensitivity: [0.9898724092204838, 0.9289859497664957, 0.9705145215623429], Precision: [0.9998932833098035, 0.6913285599850746, 0.5779504400566724]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_6.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_6.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_6.nii.gz\n",
      "Mapas de probabilidad para caso 7, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 7 - Dice: [0.9904859237593394, 0.7912795510264667, 0.43945726394455714], Sensitivity: [0.9811516489775123, 0.9999999997674959, 0.9611819234607195], Precision: [0.999999509361857, 0.6546423134467819, 0.28484490060122775]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_7.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_7.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_7.nii.gz\n",
      "Mapas de probabilidad para caso 8, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 8 - Dice: [0.9985619924908538, 0.9548826002288996, 0.9709680240137049], Sensitivity: [0.9980414998468279, 0.9745419478327346, 0.9787757100785625], Precision: [0.9990830283060793, 0.9360007408598684, 0.9632839158589263]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_8.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_8.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_8.nii.gz\n",
      "Mapas de probabilidad para caso 9, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 9 - Dice: [0.9958484901340855, 0.8894941480472597, 0.9361682484538933], Sensitivity: [0.9918067627552407, 0.9969914166446778, 0.9840459600471242], Precision: [0.9999232933140919, 0.802921788676183, 0.892733259372698]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_9.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_9.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_9.nii.gz\n",
      "Mapas de probabilidad para caso 10, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 10 - Dice: [0.9963269445110117, 0.9214243342324174, 0.9278762487875051], Sensitivity: [0.9938962459016257, 0.9831668262972777, 0.9508335314703193], Precision: [0.9987695614275768, 0.8669784280927145, 0.9060014097195147]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_10.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_10.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_10.nii.gz\n",
      "Mapas de probabilidad para caso 11, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 11 - Dice: [0.9961026529890329, 0.9395602584310757, 0.8931395675660734], Sensitivity: [0.9922406232365498, 0.9520827070021698, 0.974229071940296], Precision: [0.9999948640377391, 0.9273629412570789, 0.8245117176388177]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_11.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_11.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_11.nii.gz\n",
      "Mapas de probabilidad para caso 12, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 12 - Dice: [0.9969091402607023, 0.8097965725948236, 0.9438097753471897], Sensitivity: [0.9939730884219239, 0.9701779157881854, 0.9597218964831578], Precision: [0.9998625888259921, 0.6949186827132082, 0.9284166922750009]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_12.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_12.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_12.nii.gz\n",
      "Mapas de probabilidad para caso 13, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 13 - Dice: [0.9952156271078915, 0.9069693094266716, 0.75659020051731], Sensitivity: [0.9904980430123232, 0.9978018112197483, 0.9558900162169055], Precision: [0.9999783644609727, 0.831294410604989, 0.6260590242797418]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_13.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_13.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_13.nii.gz\n",
      "Mapas de probabilidad para caso 14, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 14 - Dice: [0.9955340923612611, 0.945316367619681, 0.784516863515234], Sensitivity: [0.9911481148971625, 0.9713617927961593, 0.9724466395846729], Precision: [0.9999590595622709, 0.9206311976216642, 0.657459749537091]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_14.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_14.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_14.nii.gz\n",
      "Mapas de probabilidad para caso 15, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 15 - Dice: [0.990225193331768, 0.9046221569968429, 0.6625561609725403], Sensitivity: [0.9807139844793189, 0.9804939657362594, 0.9492180010148397], Precision: [0.999922693030701, 0.8396490946795455, 0.508876521629508]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_15.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_15.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_15.nii.gz\n",
      "Mapas de probabilidad para caso 16, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 16 - Dice: [0.9962010538015372, 0.9474191628872579, 0.9505507082426127], Sensitivity: [0.9932698975038003, 0.9977156273141533, 0.9648939369022682], Precision: [0.9991495610855996, 0.9019503800243519, 0.9366276601328303]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_16.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_16.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_16.nii.gz\n",
      "Mapas de probabilidad para caso 17, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 17 - Dice: [0.9915569350667198, 0.8133294012366072, 0.39716760669096396], Sensitivity: [0.9834530954126792, 0.9707849345403784, 0.9427761093641328], Precision: [0.9997954387224246, 0.6998223799289971, 0.2515748469615676]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_17.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_17.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_17.nii.gz\n",
      "Mapas de probabilidad para caso 18, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 18 - Dice: [0.9973576937518815, 0.9592470135046145, 0.8986315844994069], Sensitivity: [0.9947303012633512, 0.977133713552607, 0.995108822817807], Precision: [0.9999990025206291, 0.9420033837345242, 0.8192081687540852]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_18.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_18.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_18.nii.gz\n",
      "Mapas de probabilidad para caso 19, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 19 - Dice: [0.9926961087319436, 0.92056894313269, 0.6711362427473738], Sensitivity: [0.9855327937864736, 0.979071459197197, 0.9761410365630007], Precision: [0.9999643187745559, 0.8686636325880238, 0.5113575770393226]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_19.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_19.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_19.nii.gz\n",
      "Mapas de probabilidad para caso 20, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 20 - Dice: [0.9946125557650831, 0.9240418528043496, 0.8818850507383389], Sensitivity: [0.9898145198576839, 0.9812364235477113, 0.9371166077606062], Precision: [0.9994573343385966, 0.8731475926939819, 0.832801587689886]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_20.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_20.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_20.nii.gz\n",
      "Mapas de probabilidad para caso 21, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 21 - Dice: [0.9916312898197103, 0.9501864529282826, 0.6903052660462375], Sensitivity: [0.9835321202168145, 0.9812058163980342, 0.9752150263665171], Precision: [0.9998649567203862, 0.9210682492333135, 0.5342296852904206]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_21.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_21.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_21.nii.gz\n",
      "Mapas de probabilidad para caso 22, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 22 - Dice: [0.9936306472597226, 0.354001638799781, 0.5751572747862542], Sensitivity: [0.9873433433236053, 0.8560105669009107, 0.965346812638846], Precision: [0.9999985382142343, 0.2231404957909296, 0.4095989323830613]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_22.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_22.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_22.nii.gz\n",
      "Mapas de probabilidad para caso 23, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 23 - Dice: [0.9978831052258537, 0.9744798061602071, 0.8171795766528326], Sensitivity: [0.9957766026985342, 0.986030893150703, 0.9863217364958706], Precision: [0.9999985389923336, 0.9631962211531065, 0.6975570431917018]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_23.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_23.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_23.nii.gz\n",
      "Mapas de probabilidad para caso 24, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 24 - Dice: [0.9959332068884907, 0.8131192073820263, 0.7493039994440601], Sensitivity: [0.9919056062746008, 0.9992145310751875, 0.9415529009837221], Precision: [0.9999936487365628, 0.6854583417063744, 0.6222510431763209]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_24.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_24.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_24.nii.gz\n",
      "Mapas de probabilidad para caso 25, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 25 - Dice: [0.9953402302657679, 0.44000558731107614, 0.8807429796386553], Sensitivity: [0.9909391904925623, 0.9459459453778102, 0.9867433886514794], Precision: [0.9997805369458374, 0.2866763741742489, 0.7953074765607046]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_25.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_25.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_25.nii.gz\n",
      "Mapas de probabilidad para caso 26, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 26 - Dice: [0.9903471999331154, 0.763816676258241, 0.5878376909805499], Sensitivity: [0.9809460989660401, 0.9061107937285995, 0.963075060498395], Precision: [0.9999302393576678, 0.6601481234367855, 0.4230191748189962]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_26.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_26.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_26.nii.gz\n",
      "Mapas de probabilidad para caso 27, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 27 - Dice: [0.9962725079720931, 0.9082341909288141, 0.9335091541454209], Sensitivity: [0.9927922533035543, 0.9193441222315186, 0.9801744965286895], Precision: [0.9997772486921839, 0.8973895721655343, 0.8910852797961873]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_27.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_27.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_27.nii.gz\n",
      "Mapas de probabilidad para caso 28, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 28 - Dice: [0.9938512029728049, 0.0, 0.4956146456813585], Sensitivity: [0.9877822975224074, 0.0, 0.9990378446921875], Precision: [0.9999951437918241, 0.0, 0.32955116505780235]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_28.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_28.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_28.nii.gz\n",
      "Mapas de probabilidad para caso 29, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 29 - Dice: [0.994433599760362, 0.876382747707539, 0.7191745778989374], Sensitivity: [0.98894457407748, 0.9938082152493878, 0.8007215417956036], Precision: [0.9999838979689805, 0.7837742752493136, 0.6527021797845298]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_29.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_29.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_29.nii.gz\n",
      "Mapas de probabilidad para caso 30, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 30 - Dice: [0.9942631810004229, 0.8673011906352472, 0.8701720281321759], Sensitivity: [0.9888556872729455, 0.9207631085783098, 0.984241980027848], Precision: [0.9997301409780925, 0.819706862989035, 0.7797965359660097]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_30.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_30.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_30.nii.gz\n",
      "Mapas de probabilidad para caso 31, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 31 - Dice: [0.9957900873398033, 0.8780301451538857, 0.9034172724984874], Sensitivity: [0.9916583006934048, 0.9885048482566271, 0.9601119751046954], Precision: [0.9999564485731084, 0.7897663375987203, 0.8530448912720887]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_31.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_31.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_31.nii.gz\n",
      "Mapas de probabilidad para caso 32, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 32 - Dice: [0.9949838032319921, 0.787273969770935, 0.8854376245951481], Sensitivity: [0.990055213519607, 0.9988989512235708, 0.8846492757798851], Precision: [0.9999617084246639, 0.6496419620363473, 0.8862273797182009]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_32.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_32.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_32.nii.gz\n",
      "Mapas de probabilidad para caso 33, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 33 - Dice: [0.994406300943672, 0.7715881053406586, 0.5694910173925275], Sensitivity: [0.989015225162142, 0.8978543363862634, 0.9519634245035408], Precision: [0.9998564718538875, 0.6764571947457975, 0.4062650344682134]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_33.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_33.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_33.nii.gz\n",
      "Mapas de probabilidad para caso 34, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 34 - Dice: [0.9968864356428548, 0.9389406779462088, 0.8636528505856866], Sensitivity: [0.9938083204253197, 0.9934543823809255, 0.9699782737267929], Precision: [0.9999836777488154, 0.8900984133002572, 0.7783346870697875]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_34.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_34.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_34.nii.gz\n",
      "Mapas de probabilidad para caso 35, shape: torch.Size([3, 128, 128, 128])\n",
      "Caso 35 - Dice: [0.9950613022889921, 0.908536251999207, 0.9322058363568367], Sensitivity: [0.9904939380767942, 0.996713288367039, 0.9698403163557271], Precision: [0.9996709836800607, 0.8346928114912465, 0.8973830477003445]\n",
      "Guardado mapa de probabilidad en trained_models/mapas/probability_maps_case_35.nii.gz\n",
      "Guardadas etiquetas en trained_models/mapas/labels_case_35.nii.gz\n",
      "Guardada segmentación en trained_models/mapas/segmentation_case_35.nii.gz\n",
      "\n",
      "Clase 0 (Fondo):\n",
      "  Dice: 0.9950 ± 0.0021\n",
      "  Sensibilidad: 0.9903 ± 0.0042\n",
      "  Precisión: 0.9998 ± 0.0003\n",
      "\n",
      "Clase 1 (Vasogénico):\n",
      "  Dice: 0.8307 ± 0.1924\n",
      "  Sensibilidad: 0.9434 ± 0.1629\n",
      "  Precisión: 0.7595 ± 0.2100\n",
      "\n",
      "Clase 2 (Infiltrado):\n",
      "  Dice: 0.7860 ± 0.1548\n",
      "  Sensibilidad: 0.9568 ± 0.0395\n",
      "  Precisión: 0.6945 ± 0.2035\n"
     ]
    }
   ],
   "source": [
    "# Función para generar mapas de probabilidad\n",
    "def generate_probability_maps(embeddings, projection_head, classifier, device):\n",
    "    with torch.no_grad():\n",
    "        embeddings = embeddings.to(device).squeeze(0).permute(1, 2, 3, 0)\n",
    "        embeddings_flat = embeddings.reshape(-1, 48)\n",
    "        \n",
    "        z = projection_head(embeddings_flat)\n",
    "        z = F.normalize(z, dim=1)\n",
    "        \n",
    "        logits = classifier(z)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        \n",
    "        probs = probs.view(128, 128, 128, 3).permute(3, 0, 1, 2)\n",
    "        return probs\n",
    "\n",
    "# Funciones para calcular métricas\n",
    "def calculate_metrics(pred, true, num_classes=3):\n",
    "    dice_scores = []\n",
    "    sensitivity_scores = []\n",
    "    precision_scores = []\n",
    "    \n",
    "    for cls in range(num_classes):\n",
    "        pred_cls = (pred == cls).astype(np.uint8)\n",
    "        true_cls = (true == cls).astype(np.uint8)\n",
    "        \n",
    "        # True Positives (TP), False Positives (FP), False Negatives (FN)\n",
    "        tp = np.sum(pred_cls * true_cls)\n",
    "        fp = np.sum(pred_cls * (1 - true_cls))\n",
    "        fn = np.sum((1 - pred_cls) * true_cls)\n",
    "        \n",
    "        # Dice\n",
    "        dice = 2 * tp / (2 * tp + fp + fn + 1e-6)  # Evitar división por 0\n",
    "        dice_scores.append(dice)\n",
    "        \n",
    "        # Sensibilidad (Recall)\n",
    "        sensitivity = tp / (tp + fn + 1e-6)\n",
    "        sensitivity_scores.append(sensitivity)\n",
    "        \n",
    "        # Precisión\n",
    "        precision = tp / (tp + fp + 1e-6)\n",
    "        precision_scores.append(precision)\n",
    "    \n",
    "    return dice_scores, sensitivity_scores, precision_scores\n",
    "# Directorio de salida\n",
    "output_dir = \"trained_models/mapas\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "# Listas para almacenar métricas por caso\n",
    "all_dice = {0: [], 1: [], 2: []}  # Fondo, Vasogénico, Infiltrado\n",
    "all_sensitivity = {0: [], 1: [], 2: []}\n",
    "all_precision = {0: [], 1: [], 2: []}\n",
    "\n",
    "# Procesar y guardar como NIfTI\n",
    "for idx, (embeddings, labels) in enumerate(loader):\n",
    "    # Generar mapas de probabilidad\n",
    "    prob_maps = generate_probability_maps(embeddings, projection_head, classifier, device)\n",
    "    print(f\"Mapas de probabilidad para caso {idx}, shape: {prob_maps.shape}\")\n",
    "    \n",
    "    # Convertir mapas de probabilidad a numpy\n",
    "    prob_maps_np = prob_maps.cpu().numpy()  # [3, 128, 128, 128]\n",
    "    prob_maps_np_nifti = np.transpose(prob_maps_np, (1, 2, 3, 0))  # [128, 128, 128, 3]\n",
    "    \n",
    "    # Generar segmentación semántica\n",
    "    segmentation = np.argmax(prob_maps_np, axis=0)  # [128, 128, 128]\n",
    "    segmentation_np = segmentation.astype(np.uint8)\n",
    "    \n",
    "    # Convertir etiquetas a numpy\n",
    "    labels = labels.squeeze(0)  # [128, 128, 128]\n",
    "    labels_np = labels.cpu().numpy().astype(np.uint8)\n",
    "\n",
    "    # hacer cero segmentation_np en donde labels_np es cero\n",
    "    # segmentation_np[labels_np == 0] = 0\n",
    "    \n",
    "    # Calcular métricas\n",
    "    dice, sensitivity, precision = calculate_metrics(segmentation_np, labels_np)\n",
    "    for cls in range(3):\n",
    "        all_dice[cls].append(dice[cls])\n",
    "        all_sensitivity[cls].append(sensitivity[cls])\n",
    "        all_precision[cls].append(precision[cls])\n",
    "    \n",
    "    print(f\"Caso {idx} - Dice: {dice}, Sensitivity: {sensitivity}, Precision: {precision}\")\n",
    "    \n",
    "    # Crear imágenes NIfTI\n",
    "    affine = np.eye(4)\n",
    "    \n",
    "    # Guardar mapas de probabilidad\n",
    "    nifti_prob_img = nib.Nifti1Image(prob_maps_np_nifti, affine)\n",
    "    prob_output_path = os.path.join(output_dir, f\"probability_maps_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_prob_img, prob_output_path)\n",
    "    print(f\"Guardado mapa de probabilidad en {prob_output_path}\")\n",
    "    \n",
    "    # Guardar etiquetas\n",
    "    nifti_label_img = nib.Nifti1Image(labels_np, affine)\n",
    "    label_output_path = os.path.join(output_dir, f\"labels_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_label_img, label_output_path)\n",
    "    print(f\"Guardadas etiquetas en {label_output_path}\")\n",
    "    \n",
    "    # Guardar segmentación semántica\n",
    "    nifti_seg_img = nib.Nifti1Image(segmentation_np, affine)\n",
    "    seg_output_path = os.path.join(output_dir, f\"segmentation_case_{idx}.nii.gz\")\n",
    "    nib.save(nifti_seg_img, seg_output_path)\n",
    "    print(f\"Guardada segmentación en {seg_output_path}\")\n",
    "\n",
    "# Calcular promedios y desviaciones estándar\n",
    "class_names = [\"Fondo\", \"Vasogénico\", \"Infiltrado\"]\n",
    "for cls in range(3):\n",
    "    dice_mean = np.mean(all_dice[cls])\n",
    "    dice_std = np.std(all_dice[cls])\n",
    "    sens_mean = np.mean(all_sensitivity[cls])\n",
    "    sens_std = np.std(all_sensitivity[cls])\n",
    "    prec_mean = np.mean(all_precision[cls])\n",
    "    prec_std = np.std(all_precision[cls])\n",
    "    \n",
    "    print(f\"\\nClase {cls} ({class_names[cls]}):\")\n",
    "    print(f\"  Dice: {dice_mean:.4f} ± {dice_std:.4f}\")\n",
    "    print(f\"  Sensibilidad: {sens_mean:.4f} ± {sens_std:.4f}\")\n",
    "    print(f\"  Precisión: {prec_mean:.4f} ± {prec_std:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
