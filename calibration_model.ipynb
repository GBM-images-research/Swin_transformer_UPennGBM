{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading functions\n",
    "import os\n",
    "from monai.networks.nets import SwinUNETR\n",
    "from functools import partial\n",
    "from monai.data import DataLoader, decollate_batch\n",
    "from src.get_data import CustomDataset\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    "    MapTransform,\n",
    ")\n",
    "from scipy import ndimage\n",
    "\n",
    "import torch\n",
    "import torch.nn.parallel\n",
    "import logging\n",
    "import matplotlib.pyplot as plt\n",
    "import nibabel as nib\n",
    "import numpy as np\n",
    "\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai import transforms\n",
    "from monai.transforms import (\n",
    "    AsDiscrete,\n",
    "    Activations,\n",
    ")\n",
    "import torch\n",
    "import wandb\n",
    "\n",
    "from src.get_data import CustomDataset\n",
    "from monai.data import DataLoader\n",
    "\n",
    "from src.custom_transforms import (\n",
    "    ConvertToMultiChannelBasedOnAnotatedInfiltration,\n",
    "    masked,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/training2/miniconda3/envs/monai_env/lib/python3.11/site-packages/monai/utils/deprecate_utils.py:221: FutureWarning: monai.networks.nets.swin_unetr SwinUNETR.__init__:img_size: Argument `img_size` has been deprecated since version 1.3. It will be removed in version 1.5. The img_size argument is not required anymore and checks on the input size are run during forward().\n",
      "  warn_deprecated(argname, msg, warning_category)\n"
     ]
    }
   ],
   "source": [
    "######################\n",
    "# Crear el modelo\n",
    "######################\n",
    "\n",
    "### Hyperparameter\n",
    "roi = (128, 128, 128)  # (128, 128, 128)\n",
    "\n",
    "# Create Swin transformer\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = SwinUNETR(\n",
    "    img_size=roi,\n",
    "    in_channels=11,\n",
    "    out_channels=2,  # mdificar con edema\n",
    "    feature_size=48,\n",
    "    drop_rate=0.0,\n",
    "    attn_drop_rate=0.0,\n",
    "    dropout_path_rate=0.0,\n",
    "    use_checkpoint=True,\n",
    ")#.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# run = wandb.init()\n",
    "# artifact = run.use_artifact('mlops-team89/Swin_UPENN_106cases/mjkearkn_best_model:v0', type='model')\n",
    "# artifact_dir = artifact.download()\n",
    "# print(artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1046570/4040136034.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_model = torch.load(model_path, map_location=torch.device(device))[\"state_dict\"]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model.load_state_dict(torch.load(os.path.join(artifact_dir, \"model.pt\"), map_location=torch.device('cpu')))\n",
    "\n",
    "# model_path = \"Dataset/model.pt\"\n",
    "model_path = \"artifacts/aek9v7g7_best_model:v0/model.pt\" #'Dataset/model_dataset_330_30_96x96x96_48f_v02.pt' # 5mm - mjkearkn_best_model-v0 / 10mm - ip0bojmx_best_model-v0\n",
    "\n",
    "# Load the model on CPU\n",
    "loaded_model = torch.load(model_path, map_location=torch.device(device))[\"state_dict\"]\n",
    "# model.load_state_dict(torch.load(model_path)[\"state_dict\"])\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "model.load_state_dict(loaded_model)\n",
    "\n",
    "# # Move the model to the desired device (e.g., GPU) if available\n",
    "# # device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# model.to(device)\n",
    "\n",
    "# # Set the model to evaluation mode\n",
    "# model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Transformaciones 240, 240, 155\n",
    "roi = (128, 128, 128) \n",
    "val_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.LoadImaged(keys=[\"image\", \"label\"]), #Leer imagenes \n",
    "        ConvertToMultiChannelBasedOnAnotatedInfiltration(keys=\"label\"),\n",
    "        # transforms.CropForegroundd(\n",
    "        #     keys=[\"image\", \"label\"],\n",
    "        #     source_key=\"label\",\n",
    "        #     k_divisible=[roi[0], roi[1], roi[2]],\n",
    "        # ),\n",
    "        transforms.RandSpatialCropd(\n",
    "            keys=[\"image\", \"label\"],\n",
    "            roi_size=[-1, -1, -1],\n",
    "            random_size=False,\n",
    "        ),   \n",
    "        transforms.NormalizeIntensityd(keys=\"image\", nonzero=True, channel_wise=True), #Normalizar intensidades\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Dado un arreglo de paths de imagenes devuelve un tensor torch.Size([canales, x, y, z])\n",
    "def get_image_data(image, transform):\n",
    "    data = transforms.apply_transform(\n",
    "                transform,\n",
    "                data= {\"image\":image},\n",
    "            )\n",
    "    return data[\"image\"]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11 images and 11 labels.\n",
      "torch.Size([11, 240, 240, 155])\n",
      "torch.Size([2, 240, 240, 155])\n"
     ]
    }
   ],
   "source": [
    "dataset_path = \"./Dataset/Dataset_10_1_casos\"\n",
    "val_set = CustomDataset(\n",
    "        dataset_path, section=\"train_all\", transform=val_transform\n",
    "    )  # v_transform\n",
    "val_loader = DataLoader(val_set, batch_size=1, shuffle=False, num_workers=0)\n",
    "\n",
    "im_v=val_set[0]\n",
    "print(im_v['image'].shape)\n",
    "print(im_v['label'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from temperature import ModelWithTemperature\n",
    "\n",
    "# scaled_model = ModelWithTemperature(model)\n",
    "# scaled_model.set_temperature(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:22<00:00, 12.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 1, Temperatura: 5.599999904632568, Loss: 0.009579157456755638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11/11 [02:24<00:00, 13.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteración: 2, Temperatura: 5.600007057189941, Loss: 0.009579156525433064\n",
      "Optimal temperature: 5.600007057189941\n"
     ]
    }
   ],
   "source": [
    "from temperature2 import find_optimal_temperature\n",
    "from monai.losses import DiceLoss\n",
    "\n",
    "\n",
    "criterion = torch.nn.BCEWithLogitsLoss() #BCEWithLogitsLoss()\n",
    "# criterion = DiceLoss(to_onehot_y=False, sigmoid=True)\n",
    "\n",
    "optimal_temperature = find_optimal_temperature(model, val_loader, criterion)\n",
    "\n",
    "print(f'Optimal temperature: {optimal_temperature}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "monai_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
